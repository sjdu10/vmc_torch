{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import ast\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "# quimb\n",
    "import quimb.tensor as qtn\n",
    "import symmray as sr\n",
    "import autoray as ar\n",
    "from autoray import do\n",
    "\n",
    "from vmc_torch.fermion_utils import *\n",
    "\n",
    "COMM = MPI.COMM_WORLD\n",
    "SIZE = COMM.Get_size()\n",
    "RANK = COMM.Get_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "n=50, tau=0.3000, energy~-0.404314: 100%|##########| 50/50 [00:09<00:00,  5.19it/s]\n"
     ]
    }
   ],
   "source": [
    "Lx = 6\n",
    "Ly = 6\n",
    "D = 4\n",
    "symmetry = 'Z2'\n",
    "N_f = int(4*4/2)-2\n",
    "# Create a random PEPS\n",
    "peps, parity_config = generate_random_fpeps(Lx, Ly, D, seed=2, symmetry=symmetry, Nf=N_f)\n",
    "\n",
    "# Create a random configuration\n",
    "random_conf = np.zeros(Lx*Ly)\n",
    "random_conf[:N_f] = 1\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(random_conf)\n",
    "\n",
    "t = 1.0\n",
    "V = 4.0\n",
    "mu = 0.0\n",
    "edges = qtn.edges_2d_square(Lx, Ly)\n",
    "site_info = sr.utils.parse_edges_to_site_info(\n",
    "    edges,\n",
    "    D,\n",
    "    phys_dim=2,\n",
    "    site_ind_id=\"k{},{}\",\n",
    "    site_tag_id=\"I{},{}\",\n",
    ")\n",
    "terms = {\n",
    "    (sitea, siteb): sr.fermi_hubbard_spinless_local_array(\n",
    "        t=t, V=V, mu=mu,\n",
    "        symmetry=symmetry,\n",
    "        coordinations=(\n",
    "            site_info[sitea]['coordination'],\n",
    "            site_info[siteb]['coordination'],\n",
    "        ),\n",
    "    ).fuse((0, 1), (2, 3))\n",
    "    for (sitea, siteb) in peps.gen_bond_coos()\n",
    "}\n",
    "ham = qtn.LocalHam2D(Lx, Ly, terms)\n",
    "su = qtn.SimpleUpdateGen(peps, ham, compute_energy_per_site=True,D=D, compute_energy_opts={\"max_distance\":1}, gate_opts={'cutoff':1e-10})\n",
    "su.evolve(50, 0.3)\n",
    "# su.evolve(50, 0.1)\n",
    "peps = su.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fTNModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, ftn, max_bond=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        # extract the raw arrays and a skeleton of the TN\n",
    "        params, self.skeleton = qtn.pack(ftn)\n",
    "\n",
    "        # Flatten the dictionary structure and assign each parameter as a part of a ModuleDict\n",
    "        self.torch_tn_params = nn.ModuleDict({\n",
    "            str(tid): nn.ParameterDict({\n",
    "                str(sector): nn.Parameter(data)\n",
    "                for sector, data in blk_array.items()\n",
    "            })\n",
    "            for tid, blk_array in params.items()\n",
    "        })\n",
    "\n",
    "        # Get symmetry\n",
    "        self.symmetry = ftn.arrays[0].symmetry\n",
    "\n",
    "        # Store the shapes of the parameters\n",
    "        self.param_shapes = [param.shape for param in self.parameters()]\n",
    "\n",
    "        self.model_structure = {\n",
    "            'fPEPS (exact contraction)':{'D': ftn.max_bond(), 'Lx': ftn.Lx, 'Ly': ftn.Ly, 'symmetry': self.symmetry},\n",
    "        }\n",
    "        self.max_bond = max_bond\n",
    "\n",
    "    def product_bra_state(self, config, peps, symmetry='Z2'):\n",
    "        \"\"\"Spinless fermion product bra state.\"\"\"\n",
    "        product_tn = qtn.TensorNetwork()\n",
    "        backend = peps.tensors[0].data.backend\n",
    "        iterable_oddpos = iter(range(2*peps.nsites+1))\n",
    "        for n, site in zip(config, peps.sites):\n",
    "            p_ind = peps.site_ind_id.format(*site)\n",
    "            p_tag = peps.site_tag_id.format(*site)\n",
    "            tid = peps.sites.index(site)\n",
    "            nsites = peps.nsites\n",
    "            # use autoray to ensure the correct backend is used\n",
    "            with ar.backend_like(backend):\n",
    "                if symmetry == 'Z2':\n",
    "                    data = [sr.Z2FermionicArray.from_blocks(blocks={(0,):do('array', [1.0,], like=backend)}, duals=(True,),symmetry='Z2', charge=0, oddpos=2*tid+1), # It doesn't matter if oddpos is None for even parity tensor.\n",
    "                            sr.Z2FermionicArray.from_blocks(blocks={(1,):do('array', [1.0,], like=backend)}, duals=(True,),symmetry='Z2',charge=1, oddpos=2*tid+1)\n",
    "                        ]\n",
    "                elif symmetry == 'U1':\n",
    "                    data = [sr.U1FermionicArray.from_blocks(blocks={(0,):do('array', [1.0,], like=backend)}, duals=(True,),symmetry='U1', charge=0, oddpos=2*tid+1),\n",
    "                            sr.U1FermionicArray.from_blocks(blocks={(1,):do('array', [1.0,], like=backend)}, duals=(True,),symmetry='U1', charge=1, oddpos=2*tid+1)\n",
    "                        ]\n",
    "            tsr_data = data[int(n)] # BUG: does not fit in jax compilation, a concrete value is needed for traced arrays\n",
    "            tsr = qtn.Tensor(data=tsr_data, inds=(p_ind,),tags=(p_tag, 'bra'))\n",
    "            product_tn |= tsr\n",
    "        return product_tn\n",
    "\n",
    "    def get_amp(self, peps, config, inplace=False, symmetry='Z2', conj=True):\n",
    "        \"\"\"Get the amplitude of a configuration in a PEPS.\"\"\"\n",
    "        if not inplace:\n",
    "            peps = peps.copy()\n",
    "        if conj:\n",
    "            amp = peps|self.product_bra_state(config, peps, symmetry).conj()\n",
    "        else:\n",
    "            amp = peps|self.product_bra_state(config, peps, symmetry)\n",
    "        for site in peps.sites:\n",
    "            site_tag = peps.site_tag_id.format(*site)\n",
    "            amp.contract_(tags=site_tag)\n",
    "\n",
    "        amp.view_as_(\n",
    "            qtn.PEPS,\n",
    "            site_ind_id=\"k{},{}\",\n",
    "            site_tag_id=\"I{},{}\",\n",
    "            x_tag_id=\"X{}\",\n",
    "            y_tag_id=\"Y{}\",\n",
    "            Lx=peps.Lx,\n",
    "            Ly=peps.Ly,\n",
    "        )\n",
    "        return amp\n",
    "        \n",
    "    \n",
    "    def from_params_to_vec(self):\n",
    "        return torch.cat([param.data.flatten() for param in self.parameters()])\n",
    "    \n",
    "    @property\n",
    "    def num_params(self):\n",
    "        return len(self.from_params_to_vec())\n",
    "    \n",
    "    def params_grad_to_vec(self):\n",
    "        param_grad_vec = torch.cat([param.grad.flatten() if param.grad is not None else torch.zeros_like(param).flatten() for param in self.parameters()])\n",
    "        return param_grad_vec\n",
    "\n",
    "    def clear_grad(self):\n",
    "        for param in self.parameters():\n",
    "            param.grad = None\n",
    "    \n",
    "    def from_vec_to_params(self, vec, quimb_format=False):\n",
    "        # Reconstruct the original parameter structure (by unpacking from the flattened dict)\n",
    "        params = {}\n",
    "        idx = 0\n",
    "        for tid, blk_array in self.torch_params.items():\n",
    "            params[tid] = {}\n",
    "            for sector, data in blk_array.items():\n",
    "                shape = data.shape\n",
    "                size = data.numel()\n",
    "                if quimb_format:\n",
    "                    params[tid][ast.literal_eval(sector)] = vec[idx:idx+size].view(shape)\n",
    "                else:\n",
    "                    params[tid][sector] = vec[idx:idx+size].view(shape)\n",
    "                idx += size\n",
    "        return params\n",
    "    \n",
    "    def load_params(self, new_params):\n",
    "        pointer = 0\n",
    "        for param, shape in zip(self.parameters(), self.param_shapes):\n",
    "            num_param = param.numel()\n",
    "            new_param_values = new_params[pointer:pointer+num_param].view(shape)\n",
    "            with torch.no_grad():\n",
    "                param.copy_(new_param_values)\n",
    "            pointer += num_param\n",
    "\n",
    "    \n",
    "    def amplitude(self, x):\n",
    "        # Reconstruct the original parameter structure (by unpacking from the flattened dict)\n",
    "        params = {\n",
    "            int(tid): {\n",
    "                ast.literal_eval(sector): data\n",
    "                for sector, data in blk_array.items()\n",
    "            }\n",
    "            for tid, blk_array in self.torch_tn_params.items()\n",
    "        }\n",
    "        # Reconstruct the TN with the new parameters\n",
    "        psi = qtn.unpack(params, self.skeleton)\n",
    "        # `x` is expected to be batched as (batch_size, input_dim)\n",
    "        # Loop through the batch and compute amplitude for each sample\n",
    "        batch_amps = []\n",
    "        for x_i in x:\n",
    "            amp = self.get_amp(psi, x_i, symmetry=self.symmetry, conj=True)\n",
    "            if self.max_bond is None:\n",
    "                batch_amps.append(amp.contract())\n",
    "            else:\n",
    "                amp = amp.contract_boundary_from_ymin(max_bond=self.max_bond, cutoff=0.0, yrange=[0, psi.Ly-2])\n",
    "                batch_amps.append(amp.contract())\n",
    "\n",
    "        # Return the batch of amplitudes stacked as a tensor\n",
    "        return torch.stack(batch_amps)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if x.ndim == 1:\n",
    "            # If input is not batched, add a batch dimension\n",
    "            x = x.unsqueeze(0)\n",
    "        return self.amplitude(x)\n",
    "\n",
    "class fTN_NNiso_Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, ftn, max_bond, nn_hidden_dim=64, nn_eta=1e-3):\n",
    "        super().__init__()\n",
    "        self.max_bond = max_bond\n",
    "        self.nn_eta = nn_eta\n",
    "        # extract the raw arrays and a skeleton of the TN\n",
    "        params, self.skeleton = qtn.pack(ftn)\n",
    "\n",
    "        # Flatten the dictionary structure and assign each parameter as a part of a ModuleDict\n",
    "        self.torch_tn_params = nn.ModuleDict({\n",
    "            str(tid): nn.ParameterDict({\n",
    "                str(sector): nn.Parameter(data)\n",
    "                for sector, data in blk_array.items()\n",
    "            })\n",
    "            for tid, blk_array in params.items()\n",
    "        })\n",
    "        \n",
    "        self.parity_config = [array.parity for array in ftn.arrays]\n",
    "        self.N_fermion = sum(self.parity_config)\n",
    "        dummy_config = torch.zeros(ftn.nsites)\n",
    "        dummy_config[:self.N_fermion] = 1\n",
    "        dummy_amp = self.get_amp(ftn, dummy_config, inplace=False)\n",
    "        dummy_amp_w_proj = insert_proj_peps(dummy_amp, max_bond=max_bond, yrange=[0, ftn.Ly-2])\n",
    "        dummy_amp_tn, dummy_proj_tn = dummy_amp_w_proj.partition(tags='proj')\n",
    "        dummy_proj_params, dummy_proj_skeleton = qtn.pack(dummy_proj_tn)\n",
    "        dummy_proj_params_vec = flatten_proj_params(dummy_proj_params)\n",
    "        self.proj_params_vec_len = len(dummy_proj_params_vec)\n",
    "\n",
    "        # Define an MLP layer (or any other neural network layers)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(ftn.nsites, nn_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nn_hidden_dim, self.proj_params_vec_len)\n",
    "        )\n",
    "\n",
    "        # Get symmetry\n",
    "        self.symmetry = ftn.arrays[0].symmetry\n",
    "        assert self.symmetry == 'Z2', \"Only Z2 symmetry fPEPS is supported for NN insertion now.\"\n",
    "        if self.symmetry == 'Z2':\n",
    "            assert self.N_fermion %2 == sum(self.parity_config) % 2, \"The number of fermions must match the parity of the Z2-TNS.\"\n",
    "\n",
    "        # Store the shapes of the parameters\n",
    "        self.param_shapes = [param.shape for param in self.parameters()]\n",
    "\n",
    "        self.model_structure = {\n",
    "            'fPEPS (proj inserted)':{'D': ftn.max_bond(), 'chi': self.max_bond, 'Lx': ftn.Lx, 'Ly': ftn.Ly, 'symmetry': self.symmetry, 'proj_yrange': [0, ftn.Ly-2]},\n",
    "            '2LayerMLP':{'hidden_dim': nn_hidden_dim, 'nn_eta': nn_eta, 'activation': 'ReLU'}\n",
    "        }\n",
    "\n",
    "    def product_bra_state(self, config, peps, symmetry='Z2'):\n",
    "        \"\"\"Spinless fermion product bra state.\"\"\"\n",
    "        product_tn = qtn.TensorNetwork()\n",
    "        backend = peps.tensors[0].data.backend\n",
    "        iterable_oddpos = iter(range(2*peps.nsites+1))\n",
    "        for n, site in zip(config, peps.sites):\n",
    "            p_ind = peps.site_ind_id.format(*site)\n",
    "            p_tag = peps.site_tag_id.format(*site)\n",
    "            tid = peps.sites.index(site)\n",
    "            nsites = peps.nsites\n",
    "            # use autoray to ensure the correct backend is used\n",
    "            with ar.backend_like(backend):\n",
    "                if symmetry == 'Z2':\n",
    "                    data = [sr.Z2FermionicArray.from_blocks(blocks={(0,):do('array', [1.0,], like=backend)}, duals=(True,),symmetry='Z2', charge=0, oddpos=2*tid+1), # It doesn't matter if oddpos is None for even parity tensor.\n",
    "                            sr.Z2FermionicArray.from_blocks(blocks={(1,):do('array', [1.0,], like=backend)}, duals=(True,),symmetry='Z2',charge=1, oddpos=2*tid+1)\n",
    "                        ]\n",
    "                elif symmetry == 'U1':\n",
    "                    data = [sr.U1FermionicArray.from_blocks(blocks={(0,):do('array', [1.0,], like=backend)}, duals=(True,),symmetry='U1', charge=0, oddpos=2*tid+1),\n",
    "                            sr.U1FermionicArray.from_blocks(blocks={(1,):do('array', [1.0,], like=backend)}, duals=(True,),symmetry='U1', charge=1, oddpos=2*tid+1)\n",
    "                        ]\n",
    "            tsr_data = data[int(n)] # BUG: does not fit in jax compilation, a concrete value is needed for traced arrays\n",
    "            tsr = qtn.Tensor(data=tsr_data, inds=(p_ind,),tags=(p_tag, 'bra'))\n",
    "            product_tn |= tsr\n",
    "        return product_tn\n",
    "\n",
    "    def get_amp(self, peps, config, inplace=False, symmetry='Z2', conj=True):\n",
    "        \"\"\"Get the amplitude of a configuration in a PEPS.\"\"\"\n",
    "        if not inplace:\n",
    "            peps = peps.copy()\n",
    "        if conj:\n",
    "            amp = peps|self.product_bra_state(config, peps, symmetry).conj()\n",
    "        else:\n",
    "            amp = peps|self.product_bra_state(config, peps, symmetry)\n",
    "        for site in peps.sites:\n",
    "            site_tag = peps.site_tag_id.format(*site)\n",
    "            amp.contract_(tags=site_tag)\n",
    "\n",
    "        amp.view_as_(\n",
    "            qtn.PEPS,\n",
    "            site_ind_id=\"k{},{}\",\n",
    "            site_tag_id=\"I{},{}\",\n",
    "            x_tag_id=\"X{}\",\n",
    "            y_tag_id=\"Y{}\",\n",
    "            Lx=peps.Lx,\n",
    "            Ly=peps.Ly,\n",
    "        )\n",
    "        return amp\n",
    "        \n",
    "    \n",
    "    def from_params_to_vec(self):\n",
    "        return torch.cat([param.data.flatten() for param in self.parameters()])\n",
    "    \n",
    "    @property\n",
    "    def num_params(self):\n",
    "        return len(self.from_params_to_vec())\n",
    "    \n",
    "    @property\n",
    "    def num_tn_params(self):\n",
    "        num=0\n",
    "        for tid, blk_array in self.torch_tn_params.items():\n",
    "            for sector, data in blk_array.items():\n",
    "                num += data.numel()\n",
    "        return num\n",
    "    \n",
    "    def params_grad_to_vec(self):\n",
    "        param_grad_vec = torch.cat([param.grad.flatten() if param.grad is not None else torch.zeros_like(param).flatten() for param in self.parameters()])\n",
    "        return param_grad_vec\n",
    "\n",
    "    def clear_grad(self):\n",
    "        for param in self.parameters():\n",
    "            param.grad = None\n",
    "    \n",
    "    def load_params(self, new_params):\n",
    "        pointer = 0\n",
    "        for param, shape in zip(self.parameters(), self.param_shapes):\n",
    "            num_param = param.numel()\n",
    "            new_param_values = new_params[pointer:pointer+num_param].view(shape)\n",
    "            with torch.no_grad():\n",
    "                param.copy_(new_param_values)\n",
    "            pointer += num_param\n",
    "\n",
    "    def amplitude(self, x):\n",
    "        # Reconstruct the original parameter structure (by unpacking from the flattened dict)\n",
    "        params = {\n",
    "            int(tid): {\n",
    "                ast.literal_eval(sector): data\n",
    "                for sector, data in blk_array.items()\n",
    "            }\n",
    "            for tid, blk_array in self.torch_tn_params.items()\n",
    "        }\n",
    "        # Reconstruct the TN with the new parameters\n",
    "        psi = qtn.unpack(params, self.skeleton)\n",
    "        # `x` is expected to be batched as (batch_size, input_dim)\n",
    "        # Loop through the batch and compute amplitude for each sample\n",
    "        batch_amps = []\n",
    "        for x_i in x:\n",
    "            amp = self.get_amp(psi, x_i, symmetry=self.symmetry, conj=True)\n",
    "\n",
    "            # Insert projectors\n",
    "            amp_w_proj = insert_proj_peps(amp, max_bond=self.max_bond, yrange=[0, psi.Ly-2])\n",
    "            amp_tn, proj_tn = amp_w_proj.partition(tags='proj')\n",
    "            proj_params, proj_skeleton = qtn.pack(proj_tn)\n",
    "            proj_params_vec = flatten_proj_params(proj_params)\n",
    "\n",
    "            # Check x_i type\n",
    "            if not type(x_i) == torch.Tensor:\n",
    "                x_i = torch.tensor(x_i, dtype=torch.float32)\n",
    "            # Add NN output\n",
    "            proj_params_vec += self.nn_eta*self.mlp(x_i)\n",
    "            # Reconstruct the proj parameters\n",
    "            new_proj_params = reconstruct_proj_params(proj_params_vec, proj_params)\n",
    "            # Load the new parameters\n",
    "            new_proj_tn = qtn.unpack(new_proj_params, proj_skeleton)\n",
    "            new_amp_w_proj = amp_tn | new_proj_tn\n",
    "\n",
    "            # contract column by column\n",
    "            \n",
    "            # batch_amps.append(torch.tensor(new_amp_w_proj.contract(), dtype=torch.float32, requires_grad=True))\n",
    "            batch_amps.append(new_amp_w_proj.contract())\n",
    "\n",
    "        # Return the batch of amplitudes stacked as a tensor\n",
    "        return torch.stack(batch_amps)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if x.ndim == 1:\n",
    "            # If input is not batched, add a batch dimension\n",
    "            x = x.unsqueeze(0)\n",
    "        return self.amplitude(x)\n",
    "\n",
    "\n",
    "class fTN_NN_Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, ftn, max_bond, nn_hidden_dim=64, nn_eta=1e-3):\n",
    "        super().__init__()\n",
    "        self.max_bond = max_bond\n",
    "        self.nn_eta = nn_eta\n",
    "        # extract the raw arrays and a skeleton of the TN\n",
    "        params, self.skeleton = qtn.pack(ftn)\n",
    "\n",
    "        # Flatten the dictionary structure and assign each parameter as a part of a ModuleDict\n",
    "        self.torch_tn_params = nn.ModuleDict({\n",
    "            str(tid): nn.ParameterDict({\n",
    "                str(sector): nn.Parameter(data)\n",
    "                for sector, data in blk_array.items()\n",
    "            })\n",
    "            for tid, blk_array in params.items()\n",
    "        })\n",
    "        \n",
    "        self.parity_config = [array.parity for array in ftn.arrays]\n",
    "        self.N_fermion = sum(self.parity_config)\n",
    "        dummy_config = torch.zeros(ftn.nsites)\n",
    "        dummy_config[:self.N_fermion] = 1\n",
    "        dummy_amp = ftn.get_amp(dummy_config, inplace=False, conj=True)\n",
    "        dummy_amp_2row = dummy_amp.contract_boundary_from_ymin(max_bond=max_bond, cutoff=0.0, yrange=[0, ftn.Ly//2-1])\n",
    "        dummy_amp_2row = dummy_amp_2row.contract_boundary_from_ymax(max_bond=max_bond, cutoff=0.0, yrange=[ftn.Ly//2, ftn.Ly-1])\n",
    "        dummy_2row_params, dummy_2row_skeleton = qtn.pack(dummy_amp_2row)\n",
    "        dummy_2row_params_vec = flatten_proj_params(dummy_2row_params)\n",
    "        self.tworow_params_vec_len = len(dummy_2row_params_vec)\n",
    "\n",
    "        # Define an MLP layer (or any other neural network layers)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(ftn.nsites, nn_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nn_hidden_dim, self.tworow_params_vec_len)\n",
    "        )\n",
    "\n",
    "        # Get symmetry\n",
    "        self.symmetry = ftn.arrays[0].symmetry\n",
    "        assert self.symmetry == 'Z2', \"Only Z2 symmetry fPEPS is supported for NN insertion now.\"\n",
    "        if self.symmetry == 'Z2':\n",
    "            assert self.N_fermion %2 == sum(self.parity_config) % 2, \"The number of fermions must match the parity of the Z2-TNS.\"\n",
    "\n",
    "        # Store the shapes of the parameters\n",
    "        self.param_shapes = [param.shape for param in self.parameters()]\n",
    "\n",
    "        self.model_structure = {\n",
    "            'fPEPS (proj inserted)':{'D': ftn.max_bond(), 'chi': self.max_bond, 'Lx': ftn.Lx, 'Ly': ftn.Ly, 'symmetry': self.symmetry},\n",
    "            '2LayerMLP':{'hidden_dim': nn_hidden_dim, 'nn_eta': nn_eta, 'activation': 'ReLU'}\n",
    "        }\n",
    "        \n",
    "    \n",
    "    def from_params_to_vec(self):\n",
    "        return torch.cat([param.data.flatten() for param in self.parameters()])\n",
    "    \n",
    "    @property\n",
    "    def num_params(self):\n",
    "        return len(self.from_params_to_vec())\n",
    "    \n",
    "    @property\n",
    "    def num_tn_params(self):\n",
    "        num=0\n",
    "        for tid, blk_array in self.torch_tn_params.items():\n",
    "            for sector, data in blk_array.items():\n",
    "                num += data.numel()\n",
    "        return num\n",
    "    \n",
    "    def params_grad_to_vec(self):\n",
    "        param_grad_vec = torch.cat([param.grad.flatten() if param.grad is not None else torch.zeros_like(param).flatten() for param in self.parameters()])\n",
    "        return param_grad_vec\n",
    "\n",
    "    def clear_grad(self):\n",
    "        for param in self.parameters():\n",
    "            param.grad = None\n",
    "    \n",
    "    def load_params(self, new_params):\n",
    "        pointer = 0\n",
    "        for param, shape in zip(self.parameters(), self.param_shapes):\n",
    "            num_param = param.numel()\n",
    "            new_param_values = new_params[pointer:pointer+num_param].view(shape)\n",
    "            with torch.no_grad():\n",
    "                param.copy_(new_param_values)\n",
    "            pointer += num_param\n",
    "\n",
    "    def amplitude(self, x):\n",
    "        # Reconstruct the original parameter structure (by unpacking from the flattened dict)\n",
    "        params = {\n",
    "            int(tid): {\n",
    "                ast.literal_eval(sector): data\n",
    "                for sector, data in blk_array.items()\n",
    "            }\n",
    "            for tid, blk_array in self.torch_tn_params.items()\n",
    "        }\n",
    "        # Reconstruct the TN with the new parameters\n",
    "        psi = qtn.unpack(params, self.skeleton)\n",
    "        # `x` is expected to be batched as (batch_size, input_dim)\n",
    "        # Loop through the batch and compute amplitude for each sample\n",
    "        batch_amps = []\n",
    "        for x_i in x:\n",
    "            # Check x_i type\n",
    "            if not type(x_i) == torch.Tensor:\n",
    "                x_i = torch.tensor(x_i, dtype=torch.float32)\n",
    "            \n",
    "            amp = psi.get_amp(x_i, conj=True)\n",
    "\n",
    "            # Contract to 2 rows\n",
    "            amp_2row = amp.contract_boundary_from_ymin(max_bond=self.max_bond, cutoff=0.0, yrange=[0, psi.Ly//2-1])\n",
    "            amp_2row = amp_2row.contract_boundary_from_ymax(max_bond=self.max_bond, cutoff=0.0, yrange=[psi.Ly//2, psi.Ly-1])\n",
    "            amp_2row_params, amp_2row_skeleton = qtn.pack(amp_2row)\n",
    "            amp_2row_params_vec = flatten_proj_params(amp_2row_params)\n",
    "            # Add NN output\n",
    "            amp_2row_params_vec = amp_2row_params_vec + self.nn_eta*self.mlp(x_i)\n",
    "            # Reconstruct the proj parameters\n",
    "            new_2row_params = reconstruct_proj_params(amp_2row_params_vec, amp_2row_params)\n",
    "            # Load the new parameters\n",
    "            new_amp_2row = qtn.unpack(new_2row_params, amp_2row_skeleton)\n",
    "\n",
    "            batch_amps.append(new_amp_2row.contract())\n",
    "\n",
    "        # Return the batch of amplitudes stacked as a tensor\n",
    "        return torch.stack(batch_amps)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if x.ndim == 1:\n",
    "            # If input is not batched, add a batch dimension\n",
    "            x = x.unsqueeze(0)\n",
    "        return self.amplitude(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27785/3024431008.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  peps.apply_to_arrays(lambda x: torch.tensor(x, dtype=torch.float32, requires_grad=True))\n",
      "\n",
      "pyinstrument ........................................\n",
      ".\n",
      ".  Block at /tmp/ipykernel_27785/3024431008.py:4\n",
      ".\n",
      ".  0.073 <module>  ../../../../../tmp/ipykernel_27785/3024431008.py:4\n",
      ".  ├─ 0.043 PEPS.contract  quimb/tensor/tensor_core.py:8396\n",
      ".  │     [8 frames hidden]  functools, quimb, cotengra, autoray, ...\n",
      ".  │        0.042 wrapper  functools.py:883\n",
      ".  │        └─ 0.042 tensordot_fermionic  symmray/fermionic_core.py:711\n",
      ".  │           ├─ 0.029 tensordot_abelian  symmray/abelian_core.py:1996\n",
      ".  │           │  └─ 0.029 _tensordot_via_fused  symmray/abelian_core.py:1941\n",
      ".  │           │     ├─ 0.016 Z2FermionicArray.fuse  symmray/abelian_core.py:1418\n",
      ".  │           │     │  ├─ 0.008 _VariableFunctionsClass.reshape  <built-in>\n",
      ".  │           │     │  ├─ 0.004 <dictcomp>  symmray/abelian_core.py:1524\n",
      ".  │           │     │  │  ├─ 0.003 _recurse_concat  symmray/abelian_core.py:1484\n",
      ".  │           │     │  │  │  ├─ 0.001 <genexpr>  symmray/abelian_core.py:1517\n",
      ".  │           │     │  │  │  │  └─ 0.001 _recurse_concat  symmray/abelian_core.py:1484\n",
      ".  │           │     │  │  │  │     └─ 0.001 translated_function  autoray/autoray.py:1310\n",
      ".  │           │     │  │  │  │           [1 frames hidden]  <built-in>\n",
      ".  │           │     │  │  │  ├─ 0.001 translated_function  autoray/autoray.py:1310\n",
      ".  │           │     │  │  │  │     [1 frames hidden]  <built-in>\n",
      ".  │           │     │  │  │  └─ 0.001 [self]  symmray/abelian_core.py\n",
      ".  │           │     │  │  └─ 0.001 [self]  symmray/abelian_core.py\n",
      ".  │           │     │  ├─ 0.003 torch_transpose  autoray/autoray.py:1974\n",
      ".  │           │     │  │     [1 frames hidden]  <built-in>\n",
      ".  │           │     │  └─ 0.001 Z2FermionicArray.copy_with  symmray/fermionic_core.py:193\n",
      ".  │           │     ├─ 0.006 Z2FermionicArray.unfuse  symmray/abelian_core.py:1536\n",
      ".  │           │     │  ├─ 0.003 [self]  symmray/abelian_core.py\n",
      ".  │           │     │  ├─ 0.001 _VariableFunctionsClass.reshape  <built-in>\n",
      ".  │           │     │  ├─ 0.001 replace_with_seq  symmray/abelian_core.py:291\n",
      ".  │           │     │  └─ 0.001 <dictcomp>  symmray/abelian_core.py:1559\n",
      ".  │           │     ├─ 0.004 drop_misaligned_sectors  symmray/abelian_core.py:1899\n",
      ".  │           │     │  ├─ 0.002 <dictcomp>  symmray/abelian_core.py:1916\n",
      ".  │           │     │  │  ├─ 0.001 <genexpr>  symmray/abelian_core.py:1917\n",
      ".  │           │     │  │  └─ 0.001 [self]  symmray/abelian_core.py\n",
      ".  │           │     │  ├─ 0.001 set.intersection  <built-in>\n",
      ".  │           │     │  └─ 0.001 [self]  symmray/abelian_core.py\n",
      ".  │           │     └─ 0.003 _tensordot_blockwise  symmray/abelian_core.py:1831\n",
      ".  │           │        └─ 0.003 <genexpr>  symmray/abelian_core.py:1885\n",
      ".  │           │           └─ 0.003 numpy_like  autoray/autoray.py:2034\n",
      ".  │           │                 [2 frames hidden]  torch, <built-in>\n",
      ".  │           ├─ 0.009 Z2FermionicArray.transpose  symmray/fermionic_core.py:232\n",
      ".  │           │  ├─ 0.004 Z2FermionicArray.transpose  symmray/abelian_core.py:1270\n",
      ".  │           │  │  └─ 0.004 <dictcomp>  symmray/abelian_core.py:1281\n",
      ".  │           │  │     ├─ 0.002 [self]  symmray/abelian_core.py\n",
      ".  │           │  │     ├─ 0.001 torch_transpose  autoray/autoray.py:1974\n",
      ".  │           │  │     │     [1 frames hidden]  <built-in>\n",
      ".  │           │  │     └─ 0.001 permuted  symmray/abelian_core.py:270\n",
      ".  │           │  ├─ 0.002 [self]  symmray/fermionic_core.py\n",
      ".  │           │  ├─ 0.001 permuted  symmray/abelian_core.py:270\n",
      ".  │           │  │  └─ 0.001 <genexpr>  symmray/abelian_core.py:281\n",
      ".  │           │  ├─ 0.001 dict.get  <built-in>\n",
      ".  │           │  └─ 0.001 <genexpr>  symmray/fermionic_core.py:262\n",
      ".  │           ├─ 0.002 [self]  symmray/fermionic_core.py\n",
      ".  │           ├─ 0.001 Z2FermionicArray.size  symmray/abelian_core.py:806\n",
      ".  │           │  └─ 0.001 Z2FermionicArray.shape  symmray/abelian_core.py:801\n",
      ".  │           │     └─ 0.001 <genexpr>  symmray/abelian_core.py:804\n",
      ".  │           │        └─ 0.001 BlockIndex.size_total  symmray/abelian_core.py:76\n",
      ".  │           └─ 0.001 Z2FermionicArray.phase_transpose  symmray/fermionic_core.py:320\n",
      ".  ├─ 0.028 fPEPS.get_amp  vmc_torch/fermion_utils.py:32\n",
      ".  │  ├─ 0.024 TensorNetwork.contract  quimb/tensor/tensor_core.py:8396\n",
      ".  │  │     [19 frames hidden]  quimb, functools, cotengra, autoray, ...\n",
      ".  │  │        0.019 wrapper  functools.py:883\n",
      ".  │  │        └─ 0.019 tensordot_fermionic  symmray/fermionic_core.py:711\n",
      ".  │  │           ├─ 0.014 tensordot_abelian  symmray/abelian_core.py:1996\n",
      ".  │  │           │  ├─ 0.013 _tensordot_via_fused  symmray/abelian_core.py:1941\n",
      ".  │  │           │  │  ├─ 0.007 Z2FermionicArray.fuse  symmray/abelian_core.py:1418\n",
      ".  │  │           │  │  │  ├─ 0.003 torch_transpose  autoray/autoray.py:1974\n",
      ".  │  │           │  │  │  │     [1 frames hidden]  <built-in>\n",
      ".  │  │           │  │  │  ├─ 0.002 <dictcomp>  symmray/abelian_core.py:1524\n",
      ".  │  │           │  │  │  │  └─ 0.002 _recurse_concat  symmray/abelian_core.py:1484\n",
      ".  │  │           │  │  │  │     └─ 0.002 <genexpr>  symmray/abelian_core.py:1517\n",
      ".  │  │           │  │  │  │        └─ 0.002 _recurse_concat  symmray/abelian_core.py:1484\n",
      ".  │  │           │  │  │  │           ├─ 0.001 translated_function  autoray/autoray.py:1310\n",
      ".  │  │           │  │  │  │           │     [1 frames hidden]  <built-in>\n",
      ".  │  │           │  │  │  │           └─ 0.001 [self]  symmray/abelian_core.py\n",
      ".  │  │           │  │  │  ├─ 0.001 [self]  symmray/abelian_core.py\n",
      ".  │  │           │  │  │  └─ 0.001 FermionicArray.cached_fuse_block_info  symmray/abelian_core.py:669\n",
      ".  │  │           │  │  │     └─ 0.001 <genexpr>  symmray/abelian_core.py:673\n",
      ".  │  │           │  │  ├─ 0.003 Z2FermionicArray.unfuse  symmray/abelian_core.py:1536\n",
      ".  │  │           │  │  │  ├─ 0.002 _VariableFunctionsClass.reshape  <built-in>\n",
      ".  │  │           │  │  │  └─ 0.001 list.append  <built-in>\n",
      ".  │  │           │  │  ├─ 0.002 _tensordot_blockwise  symmray/abelian_core.py:1831\n",
      ".  │  │           │  │  │  ├─ 0.001 <genexpr>  symmray/abelian_core.py:1885\n",
      ".  │  │           │  │  │  │  └─ 0.001 numpy_like  autoray/autoray.py:2034\n",
      ".  │  │           │  │  │  │        [1 frames hidden]  torch\n",
      ".  │  │           │  │  │  └─ 0.001 [self]  symmray/abelian_core.py\n",
      ".  │  │           │  │  └─ 0.001 [self]  symmray/abelian_core.py\n",
      ".  │  │           │  └─ 0.001 [self]  symmray/abelian_core.py\n",
      ".  │  │           ├─ 0.002 Z2FermionicArray.transpose  symmray/fermionic_core.py:232\n",
      ".  │  │           │  ├─ 0.001 [self]  symmray/fermionic_core.py\n",
      ".  │  │           │  └─ 0.001 Z2FermionicArray.transpose  symmray/abelian_core.py:1270\n",
      ".  │  │           │     └─ 0.001 <dictcomp>  symmray/abelian_core.py:1281\n",
      ".  │  │           │        └─ 0.001 permuted  symmray/abelian_core.py:270\n",
      ".  │  │           ├─ 0.001 without  symmray/abelian_core.py:284\n",
      ".  │  │           │  └─ 0.001 <genexpr>  symmray/abelian_core.py:288\n",
      ".  │  │           ├─ 0.001 isinstance  <built-in>\n",
      ".  │  │           └─ 0.001 FermionicArray.size  symmray/abelian_core.py:806\n",
      ".  │  │              └─ 0.001 FermionicArray.shape  symmray/abelian_core.py:801\n",
      ".  │  │                 └─ 0.001 <genexpr>  symmray/abelian_core.py:804\n",
      ".  │  │                    └─ 0.001 BlockIndex.size_total  symmray/abelian_core.py:76\n",
      ".  │  ├─ 0.001 fPEPS.copy  quimb/tensor/tensor_core.py:3797\n",
      ".  │  │  └─ 0.001 fPEPS.__init__  vmc_torch/fermion_utils.py:11\n",
      ".  │  │     └─ 0.001 fPEPS.__init__  quimb/tensor/tensor_2d.py:4781\n",
      ".  │  │           [4 frames hidden]  quimb\n",
      ".  │  │              0.001 asarray  quimb/tensor/array_ops.py:21\n",
      ".  │  │              └─ 0.001 Z2FermionicArray.shape  symmray/abelian_core.py:801\n",
      ".  │  │                 └─ 0.001 <genexpr>  symmray/abelian_core.py:804\n",
      ".  │  │                    └─ 0.001 BlockIndex.size_total  symmray/abelian_core.py:76\n",
      ".  │  │                       └─ 0.001 sum  <built-in>\n",
      ".  │  ├─ 0.001 fPEPS.sites  quimb/tensor/tensor_arbgeom.py:485\n",
      ".  │  ├─ 0.001 TensorNetwork.conj  quimb/tensor/tensor_core.py:4176\n",
      ".  │  │     [4 frames hidden]  quimb, autoray\n",
      ".  │  │        0.001 do  autoray/autoray.py:30\n",
      ".  │  │        └─ 0.001 conj  symmray/interface.py:8\n",
      ".  │  │           └─ 0.001 FermionicArray.conj  symmray/fermionic_core.py:424\n",
      ".  │  │              └─ 0.001 dict.get  <built-in>\n",
      ".  │  └─ 0.001 fPEPS.product_bra_state  vmc_torch/fermion_utils.py:15\n",
      ".  └─ 0.002 [self]  ../../../../../tmp/ipykernel_27785/3024431008.py\n",
      ".  \n",
      ".....................................................\n",
      "\n"
     ]
    }
   ],
   "source": [
    "peps.apply_to_arrays(lambda x: torch.tensor(x, dtype=torch.float32, requires_grad=True))\n",
    "# Get the amplitude of the configuration\n",
    "import pyinstrument\n",
    "with pyinstrument.profile():\n",
    "    amp = peps.get_amp(random_conf, conj=True)\n",
    "    amp.contract()\n",
    "    # amp.contract_boundary_from_ymin(max_bond=8, yrange=(0, amp.Ly-2), cutoff=0.0).contract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "pyinstrument ........................................\n",
      ".\n",
      ".  Block at /tmp/ipykernel_27785/829635654.py:2\n",
      ".\n",
      ".  0.137 <module>  ../../../../../tmp/ipykernel_27785/829635654.py:2\n",
      ".  └─ 0.137 fTNModel.amplitude  ../../../../../tmp/ipykernel_27785/3087146501.py:119\n",
      ".     ├─ 0.099 PEPS.contract_boundary_from_ymin  quimb/tensor/tensor_2d.py:2003\n",
      ".     │     [44 frames hidden]  quimb, functools, autoray, cotengra\n",
      ".     │        0.010 Composed.__call__  autoray/autoray.py:921\n",
      ".     │        └─ 0.010 qr_stabilized  symmray/linalg.py:118\n",
      ".     │           └─ 0.010 wrapper  functools.py:883\n",
      ".     │              └─ 0.010 qr_fermionic  symmray/linalg.py:107\n",
      ".     │                 └─ 0.010 qr  symmray/linalg.py:46\n",
      ".     │                    └─ 0.008 _qr  symmray/linalg.py:26\n",
      ".     │                       └─ 0.008 qr_stabilized  quimb/tensor/decomp.py:669\n",
      ".     │                             [4 frames hidden]  autoray, <built-in>, quimb\n",
      ".     │        0.005 do  autoray/autoray.py:30\n",
      ".     │        └─ 0.005 reshape  symmray/interface.py:58\n",
      ".     │           └─ 0.005 Z2FermionicArray.reshape  symmray/abelian_core.py:1619\n",
      ".     │              ├─ 0.003 Z2FermionicArray.unfuse  symmray/fermionic_core.py:624\n",
      ".     │              │  └─ 0.003 Z2FermionicArray.unfuse  symmray/abelian_core.py:1536\n",
      ".     │              │     └─ 0.002 [self]  symmray/abelian_core.py\n",
      ".     │              └─ 0.002 Z2FermionicArray.fuse  symmray/fermionic_core.py:556\n",
      ".     │        0.014 do  autoray/autoray.py:30\n",
      ".     │        └─ 0.014 fuse  symmray/interface.py:117\n",
      ".     │           └─ 0.014 Z2FermionicArray.fuse  symmray/fermionic_core.py:556\n",
      ".     │              ├─ 0.006 Z2FermionicArray.fuse  symmray/abelian_core.py:1418\n",
      ".     │              │  ├─ 0.003 <dictcomp>  symmray/abelian_core.py:1524\n",
      ".     │              │  │  └─ 0.003 _recurse_concat  symmray/abelian_core.py:1484\n",
      ".     │              │  │     └─ 0.002 translated_function  autoray/autoray.py:1310\n",
      ".     │              │  │           [1 frames hidden]  <built-in>\n",
      ".     │              │  └─ 0.002 _VariableFunctionsClass.reshape  <built-in>\n",
      ".     │              └─ 0.005 Z2FermionicArray.transpose  symmray/fermionic_core.py:232\n",
      ".     │                 ├─ 0.002 [self]  symmray/fermionic_core.py\n",
      ".     │                 └─ 0.002 Z2FermionicArray.transpose  symmray/abelian_core.py:1270\n",
      ".     │                    └─ 0.002 <dictcomp>  symmray/abelian_core.py:1281\n",
      ".     │                       └─ 0.002 torch_transpose  autoray/autoray.py:1974\n",
      ".     │                             [1 frames hidden]  <built-in>\n",
      ".     │        0.011 wrapper  functools.py:883\n",
      ".     │        └─ 0.011 tensordot_fermionic  symmray/fermionic_core.py:711\n",
      ".     │           ├─ 0.006 tensordot_abelian  symmray/abelian_core.py:1996\n",
      ".     │           │  └─ 0.006 _tensordot_via_fused  symmray/abelian_core.py:1941\n",
      ".     │           │     ├─ 0.004 Z2FermionicArray.unfuse  symmray/abelian_core.py:1536\n",
      ".     │           │     │  ├─ 0.003 [self]  symmray/abelian_core.py\n",
      ".     │           │     │  └─ 0.001 replace_with_seq  symmray/abelian_core.py:291\n",
      ".     │           │     └─ 0.002 Z2FermionicArray.fuse  symmray/abelian_core.py:1418\n",
      ".     │           └─ 0.004 Z2FermionicArray.transpose  symmray/fermionic_core.py:232\n",
      ".     │              └─ 0.002 [self]  symmray/fermionic_core.py\n",
      ".     │        0.004 do  autoray/autoray.py:30\n",
      ".     │        └─ 0.004 transpose  symmray/interface.py:86\n",
      ".     │           └─ 0.004 Z2FermionicArray.transpose  symmray/fermionic_core.py:232\n",
      ".     │              └─ 0.002 Z2FermionicArray.transpose  symmray/abelian_core.py:1270\n",
      ".     │                 └─ 0.002 <dictcomp>  symmray/abelian_core.py:1281\n",
      ".     │                    └─ 0.002 torch_transpose  autoray/autoray.py:1974\n",
      ".     │                          [1 frames hidden]  <built-in>\n",
      ".     │        0.007 wrapper  functools.py:883\n",
      ".     │        └─ 0.007 tensordot_fermionic  symmray/fermionic_core.py:711\n",
      ".     │           └─ 0.006 tensordot_abelian  symmray/abelian_core.py:1996\n",
      ".     │              └─ 0.006 _tensordot_via_fused  symmray/abelian_core.py:1941\n",
      ".     │                 └─ 0.002 Z2FermionicArray.unfuse  symmray/abelian_core.py:1536\n",
      ".     │        0.002 Composed.__call__  autoray/autoray.py:921\n",
      ".     │        └─ 0.002 svd_truncated  symmray/linalg.py:212\n",
      ".     │        0.003 Composed.__call__  autoray/autoray.py:921\n",
      ".     │        └─ 0.003 qr_stabilized  symmray/linalg.py:118\n",
      ".     │           └─ 0.003 wrapper  functools.py:883\n",
      ".     │              └─ 0.003 qr_fermionic  symmray/linalg.py:107\n",
      ".     │                 └─ 0.003 qr  symmray/linalg.py:46\n",
      ".     │                    └─ 0.003 _qr  symmray/linalg.py:26\n",
      ".     │                       └─ 0.003 qr_stabilized  quimb/tensor/decomp.py:669\n",
      ".     │                             [2 frames hidden]  autoray, <built-in>\n",
      ".     │        0.004 wrapper  functools.py:883\n",
      ".     │        └─ 0.004 tensordot_fermionic  symmray/fermionic_core.py:711\n",
      ".     │           └─ 0.004 tensordot_abelian  symmray/abelian_core.py:1996\n",
      ".     │              └─ 0.004 _tensordot_via_fused  symmray/abelian_core.py:1941\n",
      ".     │                 └─ 0.002 Z2FermionicArray.fuse  symmray/abelian_core.py:1418\n",
      ".     │                    └─ 0.002 <dictcomp>  symmray/abelian_core.py:1524\n",
      ".     │                       └─ 0.002 _recurse_concat  symmray/abelian_core.py:1484\n",
      ".     │                          └─ 0.002 <genexpr>  symmray/abelian_core.py:1517\n",
      ".     │                             └─ 0.002 _recurse_concat  symmray/abelian_core.py:1484\n",
      ".     │                                └─ 0.002 translated_function  autoray/autoray.py:1310\n",
      ".     │                                      [1 frames hidden]  <built-in>\n",
      ".     │        0.018 wrapper  functools.py:883\n",
      ".     │        └─ 0.018 tensordot_fermionic  symmray/fermionic_core.py:711\n",
      ".     │           ├─ 0.014 tensordot_abelian  symmray/abelian_core.py:1996\n",
      ".     │           │  └─ 0.014 _tensordot_via_fused  symmray/abelian_core.py:1941\n",
      ".     │           │     ├─ 0.006 Z2FermionicArray.fuse  symmray/abelian_core.py:1418\n",
      ".     │           │     │  └─ 0.003 <dictcomp>  symmray/abelian_core.py:1524\n",
      ".     │           │     │     └─ 0.003 _recurse_concat  symmray/abelian_core.py:1484\n",
      ".     │           │     │        └─ 0.002 <genexpr>  symmray/abelian_core.py:1517\n",
      ".     │           │     │           └─ 0.002 _recurse_concat  symmray/abelian_core.py:1484\n",
      ".     │           │     │              └─ 0.002 translated_function  autoray/autoray.py:1310\n",
      ".     │           │     │                    [1 frames hidden]  <built-in>\n",
      ".     │           │     ├─ 0.005 Z2FermionicArray.unfuse  symmray/abelian_core.py:1536\n",
      ".     │           │     │  └─ 0.004 [self]  symmray/abelian_core.py\n",
      ".     │           │     └─ 0.002 _tensordot_blockwise  symmray/abelian_core.py:1831\n",
      ".     │           │        └─ 0.002 <genexpr>  symmray/abelian_core.py:1885\n",
      ".     │           │           └─ 0.002 numpy_like  autoray/autoray.py:2034\n",
      ".     │           │                 [2 frames hidden]  torch, <built-in>\n",
      ".     │           └─ 0.004 Z2FermionicArray.transpose  symmray/fermionic_core.py:232\n",
      ".     │              └─ 0.002 Z2FermionicArray.copy  symmray/fermionic_core.py:180\n",
      ".     │                 └─ 0.002 Z2FermionicArray.copy  symmray/abelian_core.py:750\n",
      ".     ├─ 0.027 fTNModel.get_amp  ../../../../../tmp/ipykernel_27785/3087146501.py:54\n",
      ".     │  ├─ 0.020 TensorNetwork.contract  quimb/tensor/tensor_core.py:8396\n",
      ".     │  │     [6 frames hidden]  quimb, functools, cotengra\n",
      ".     │  │        0.018 wrapper  functools.py:883\n",
      ".     │  │        └─ 0.017 tensordot_fermionic  symmray/fermionic_core.py:711\n",
      ".     │  │           ├─ 0.015 tensordot_abelian  symmray/abelian_core.py:1996\n",
      ".     │  │           │  └─ 0.015 _tensordot_via_fused  symmray/abelian_core.py:1941\n",
      ".     │  │           │     ├─ 0.007 Z2FermionicArray.fuse  symmray/abelian_core.py:1418\n",
      ".     │  │           │     │  └─ 0.004 <dictcomp>  symmray/abelian_core.py:1524\n",
      ".     │  │           │     │     └─ 0.004 _recurse_concat  symmray/abelian_core.py:1484\n",
      ".     │  │           │     │        └─ 0.003 translated_function  autoray/autoray.py:1310\n",
      ".     │  │           │     │              [1 frames hidden]  <built-in>\n",
      ".     │  │           │     ├─ 0.003 _tensordot_blockwise  symmray/abelian_core.py:1831\n",
      ".     │  │           │     │  └─ 0.002 <genexpr>  symmray/abelian_core.py:1885\n",
      ".     │  │           │     │     └─ 0.002 numpy_like  autoray/autoray.py:2034\n",
      ".     │  │           │     │           [2 frames hidden]  torch, <built-in>\n",
      ".     │  │           │     └─ 0.003 [self]  symmray/abelian_core.py\n",
      ".     │  │           └─ 0.002 Z2FermionicArray.transpose  symmray/fermionic_core.py:232\n",
      ".     │  └─ 0.003 fTNModel.product_bra_state  ../../../../../tmp/ipykernel_27785/3087146501.py:29\n",
      ".     ├─ 0.006 <dictcomp>  ../../../../../tmp/ipykernel_27785/3087146501.py:121\n",
      ".     │  └─ 0.006 <dictcomp>  ../../../../../tmp/ipykernel_27785/3087146501.py:122\n",
      ".     │     ├─ 0.003 <genexpr>  torch/nn/modules/container.py:838\n",
      ".     │     │     [1 frames hidden]  torch\n",
      ".     │     └─ 0.002 literal_eval  ast.py:54\n",
      ".     │           [2 frames hidden]  ast\n",
      ".     └─ 0.005 PEPS.contract  quimb/tensor/tensor_core.py:8396\n",
      ".           [5 frames hidden]  functools, quimb, cotengra\n",
      ".              0.005 wrapper  functools.py:883\n",
      ".              └─ 0.005 tensordot_fermionic  symmray/fermionic_core.py:711\n",
      ".                 └─ 0.004 tensordot_abelian  symmray/abelian_core.py:1996\n",
      ".                    └─ 0.004 _tensordot_via_fused  symmray/abelian_core.py:1941\n",
      ".                       └─ 0.002 Z2FermionicArray.fuse  symmray/abelian_core.py:1418\n",
      ".  \n",
      ".....................................................\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ftn_model = fTNModel(peps, max_bond=8)\n",
    "with pyinstrument.profile():\n",
    "    ftn_model.amplitude([random_conf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "pyinstrument ........................................\n",
      ".\n",
      ".  Block at /tmp/ipykernel_27785/1814615920.py:2\n",
      ".\n",
      ".  0.413 <module>  ../../../../../tmp/ipykernel_27785/1814615920.py:2\n",
      ".  └─ 0.412 fTN_NNiso_Model.amplitude  ../../../../../tmp/ipykernel_27785/3087146501.py:281\n",
      ".     ├─ 0.331 insert_proj_peps  vmc_torch/fermion_utils.py:270\n",
      ".     │  ├─ 0.322 insert_compressor  vmc_torch/fermion_utils.py:204\n",
      ".     │  │  ├─ 0.196 TensorNetwork.contract  quimb/tensor/tensor_core.py:8396\n",
      ".     │  │  │     [6 frames hidden]  functools, quimb, cotengra, autoray\n",
      ".     │  │  │        0.172 wrapper  functools.py:883\n",
      ".     │  │  │        └─ 0.170 tensordot_fermionic  symmray/fermionic_core.py:711\n",
      ".     │  │  │           ├─ 0.128 tensordot_abelian  symmray/abelian_core.py:1996\n",
      ".     │  │  │           │  └─ 0.126 _tensordot_via_fused  symmray/abelian_core.py:1941\n",
      ".     │  │  │           │     ├─ 0.058 Z2FermionicArray.fuse  symmray/abelian_core.py:1418\n",
      ".     │  │  │           │     │  ├─ 0.020 <dictcomp>  symmray/abelian_core.py:1524\n",
      ".     │  │  │           │     │  │  └─ 0.020 _recurse_concat  symmray/abelian_core.py:1484\n",
      ".     │  │  │           │     │  │     ├─ 0.009 <genexpr>  symmray/abelian_core.py:1517\n",
      ".     │  │  │           │     │  │     │  └─ 0.006 _recurse_concat  symmray/abelian_core.py:1484\n",
      ".     │  │  │           │     │  │     │     └─ 0.005 translated_function  autoray/autoray.py:1310\n",
      ".     │  │  │           │     │  │     │           [1 frames hidden]  <built-in>\n",
      ".     │  │  │           │     │  │     ├─ 0.005 translated_function  autoray/autoray.py:1310\n",
      ".     │  │  │           │     │  │     └─ 0.005 [self]  symmray/abelian_core.py\n",
      ".     │  │  │           │     │  ├─ 0.011 [self]  symmray/abelian_core.py\n",
      ".     │  │  │           │     │  ├─ 0.010 torch_transpose  autoray/autoray.py:1974\n",
      ".     │  │  │           │     │  │     [1 frames hidden]  <built-in>\n",
      ".     │  │  │           │     │  └─ 0.010 _VariableFunctionsClass.reshape  <built-in>\n",
      ".     │  │  │           │     ├─ 0.041 Z2FermionicArray.unfuse  symmray/abelian_core.py:1536\n",
      ".     │  │  │           │     │  ├─ 0.020 [self]  symmray/abelian_core.py\n",
      ".     │  │  │           │     │  ├─ 0.006 _VariableFunctionsClass.reshape  <built-in>\n",
      ".     │  │  │           │     │  └─ 0.006 replace_with_seq  symmray/abelian_core.py:291\n",
      ".     │  │  │           │     ├─ 0.018 _tensordot_blockwise  symmray/abelian_core.py:1831\n",
      ".     │  │  │           │     │  └─ 0.014 <genexpr>  symmray/abelian_core.py:1885\n",
      ".     │  │  │           │     │     └─ 0.014 numpy_like  autoray/autoray.py:2034\n",
      ".     │  │  │           │     │           [2 frames hidden]  torch, <built-in>\n",
      ".     │  │  │           │     └─ 0.008 drop_misaligned_sectors  symmray/abelian_core.py:1899\n",
      ".     │  │  │           │        └─ 0.005 <dictcomp>  symmray/abelian_core.py:1916\n",
      ".     │  │  │           ├─ 0.019 Z2FermionicArray.transpose  symmray/fermionic_core.py:232\n",
      ".     │  │  │           │  └─ 0.012 Z2FermionicArray.transpose  symmray/abelian_core.py:1270\n",
      ".     │  │  │           │     └─ 0.008 <dictcomp>  symmray/abelian_core.py:1281\n",
      ".     │  │  │           │        └─ 0.005 torch_transpose  autoray/autoray.py:1974\n",
      ".     │  │  │           │              [1 frames hidden]  <built-in>\n",
      ".     │  │  │           └─ 0.006 Z2FermionicArray.phase_flip  symmray/fermionic_core.py:282\n",
      ".     │  │  │              └─ 0.005 [self]  symmray/fermionic_core.py\n",
      ".     │  │  ├─ 0.047 Tensor.split  quimb/tensor/tensor_core.py:2212\n",
      ".     │  │  │     [3 frames hidden]  functools, quimb\n",
      ".     │  │  │        0.025 Composed.__call__  autoray/autoray.py:921\n",
      ".     │  │  │        └─ 0.012 qr_stabilized  symmray/linalg.py:118\n",
      ".     │  │  │           └─ 0.012 wrapper  functools.py:883\n",
      ".     │  │  │              └─ 0.012 qr_fermionic  symmray/linalg.py:107\n",
      ".     │  │  │                 └─ 0.012 qr  symmray/linalg.py:46\n",
      ".     │  │  │                    └─ 0.010 _qr  symmray/linalg.py:26\n",
      ".     │  │  │                       └─ 0.010 qr_stabilized  quimb/tensor/decomp.py:669\n",
      ".     │  │  │           0.009 Composed.__call__  autoray/autoray.py:921\n",
      ".     │  │  │           └─ 0.009 qr_stabilized  symmray/linalg.py:118\n",
      ".     │  │  │              └─ 0.009 wrapper  functools.py:883\n",
      ".     │  │  │                 └─ 0.009 qr_fermionic  symmray/linalg.py:107\n",
      ".     │  │  │                    └─ 0.009 qr  symmray/linalg.py:46\n",
      ".     │  │  │                       └─ 0.009 _qr  symmray/linalg.py:26\n",
      ".     │  │  │                          └─ 0.009 qr_stabilized  quimb/tensor/decomp.py:669\n",
      ".     │  │  │                                [2 frames hidden]  autoray, quimb\n",
      ".     │  │  │        0.015 do  autoray/autoray.py:30\n",
      ".     │  │  │        └─ 0.015 reshape  symmray/interface.py:58\n",
      ".     │  │  │           └─ 0.015 Z2FermionicArray.reshape  symmray/abelian_core.py:1619\n",
      ".     │  │  │              ├─ 0.008 Z2FermionicArray.fuse  symmray/fermionic_core.py:556\n",
      ".     │  │  │              │  └─ 0.005 Z2FermionicArray.fuse  symmray/abelian_core.py:1418\n",
      ".     │  │  │              └─ 0.006 Z2FermionicArray.unfuse  symmray/fermionic_core.py:624\n",
      ".     │  │  │                 └─ 0.005 Z2FermionicArray.unfuse  symmray/abelian_core.py:1536\n",
      ".     │  │  ├─ 0.027 TensorNetwork.__or__  quimb/tensor/tensor_core.py:3707\n",
      ".     │  │  │     [8 frames hidden]  quimb\n",
      ".     │  │  ├─ 0.022 TensorNetwork.copy  quimb/tensor/tensor_core.py:3797\n",
      ".     │  │  │     [4 frames hidden]  quimb\n",
      ".     │  │  │        0.010 asarray  quimb/tensor/array_ops.py:21\n",
      ".     │  │  │        └─ 0.006 Z2FermionicArray.shape  symmray/abelian_core.py:801\n",
      ".     │  │  └─ 0.019 TensorNetwork.partition  quimb/tensor/tensor_core.py:4976\n",
      ".     │  │        [5 frames hidden]  quimb\n",
      ".     │  └─ 0.007 [self]  vmc_torch/fermion_utils.py\n",
      ".     ├─ 0.039 TensorNetwork.contract  quimb/tensor/tensor_core.py:8396\n",
      ".     │     [5 frames hidden]  functools, quimb, cotengra\n",
      ".     │        0.038 wrapper  functools.py:883\n",
      ".     │        └─ 0.038 tensordot_fermionic  symmray/fermionic_core.py:711\n",
      ".     │           ├─ 0.026 tensordot_abelian  symmray/abelian_core.py:1996\n",
      ".     │           │  └─ 0.026 _tensordot_via_fused  symmray/abelian_core.py:1941\n",
      ".     │           │     ├─ 0.012 Z2FermionicArray.fuse  symmray/abelian_core.py:1418\n",
      ".     │           │     └─ 0.010 Z2FermionicArray.unfuse  symmray/abelian_core.py:1536\n",
      ".     │           └─ 0.006 Z2FermionicArray.transpose  symmray/fermionic_core.py:232\n",
      ".     ├─ 0.026 fTN_NNiso_Model.get_amp  ../../../../../tmp/ipykernel_27785/3087146501.py:225\n",
      ".     │  └─ 0.021 TensorNetwork.contract  quimb/tensor/tensor_core.py:8396\n",
      ".     │        [6 frames hidden]  quimb, functools, cotengra\n",
      ".     │           0.020 wrapper  functools.py:883\n",
      ".     │           └─ 0.018 tensordot_fermionic  symmray/fermionic_core.py:711\n",
      ".     │              ├─ 0.012 tensordot_abelian  symmray/abelian_core.py:1996\n",
      ".     │              │  └─ 0.011 _tensordot_via_fused  symmray/abelian_core.py:1941\n",
      ".     │              │     └─ 0.006 Z2FermionicArray.fuse  symmray/abelian_core.py:1418\n",
      ".     │              └─ 0.006 Z2FermionicArray.transpose  symmray/fermionic_core.py:232\n",
      ".     │                 └─ 0.005 Z2FermionicArray.transpose  symmray/abelian_core.py:1270\n",
      ".     │                    └─ 0.005 <dictcomp>  symmray/abelian_core.py:1281\n",
      ".     └─ 0.007 flatten_proj_params  vmc_torch/fermion_utils.py:306\n",
      ".  \n",
      ".....................................................\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ftn_nniso_model = fTN_NNiso_Model(peps, max_bond=8, nn_hidden_dim=16, nn_eta=1e-3)\n",
    "with pyinstrument.profile():\n",
    "    ftn_nniso_model.amplitude([random_conf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "pyinstrument ........................................\n",
      ".\n",
      ".  Block at /tmp/ipykernel_27785/1036372546.py:2\n",
      ".\n",
      ".  0.140 <module>  ../../../../../tmp/ipykernel_27785/1036372546.py:2\n",
      ".  └─ 0.139 fTN_NN_Model.amplitude  ../../../../../tmp/ipykernel_27785/3087146501.py:413\n",
      ".     ├─ 0.050 PEPS.contract_boundary_from_ymin  quimb/tensor/tensor_2d.py:2003\n",
      ".     │     [44 frames hidden]  quimb, functools, autoray, cotengra\n",
      ".     │        0.004 Composed.__call__  autoray/autoray.py:921\n",
      ".     │        └─ 0.004 qr_stabilized  symmray/linalg.py:118\n",
      ".     │           └─ 0.004 wrapper  functools.py:883\n",
      ".     │              └─ 0.004 qr_fermionic  symmray/linalg.py:107\n",
      ".     │                 └─ 0.004 qr  symmray/linalg.py:46\n",
      ".     │                    └─ 0.004 _qr  symmray/linalg.py:26\n",
      ".     │                       └─ 0.004 qr_stabilized  quimb/tensor/decomp.py:669\n",
      ".     │                             [2 frames hidden]  autoray, <built-in>\n",
      ".     │        0.004 do  autoray/autoray.py:30\n",
      ".     │        └─ 0.004 reshape  symmray/interface.py:58\n",
      ".     │           └─ 0.004 Z2FermionicArray.reshape  symmray/abelian_core.py:1619\n",
      ".     │              └─ 0.003 Z2FermionicArray.unfuse  symmray/fermionic_core.py:624\n",
      ".     │                 └─ 0.003 Z2FermionicArray.unfuse  symmray/abelian_core.py:1536\n",
      ".     │                    └─ 0.002 [self]  symmray/abelian_core.py\n",
      ".     │        0.005 do  autoray/autoray.py:30\n",
      ".     │        └─ 0.005 fuse  symmray/interface.py:117\n",
      ".     │           └─ 0.005 Z2FermionicArray.fuse  symmray/fermionic_core.py:556\n",
      ".     │              └─ 0.005 Z2FermionicArray.fuse  symmray/abelian_core.py:1418\n",
      ".     │                 └─ 0.004 torch_transpose  autoray/autoray.py:1974\n",
      ".     │                       [1 frames hidden]  <built-in>\n",
      ".     │        0.005 wrapper  functools.py:883\n",
      ".     │        └─ 0.004 tensordot_fermionic  symmray/fermionic_core.py:711\n",
      ".     │           └─ 0.003 tensordot_abelian  symmray/abelian_core.py:1996\n",
      ".     │              └─ 0.003 _tensordot_via_fused  symmray/abelian_core.py:1941\n",
      ".     │                 └─ 0.002 Z2FermionicArray.fuse  symmray/abelian_core.py:1418\n",
      ".     │        0.002 do  autoray/autoray.py:30\n",
      ".     │        └─ 0.002 transpose  symmray/interface.py:86\n",
      ".     │           └─ 0.002 Z2FermionicArray.transpose  symmray/fermionic_core.py:232\n",
      ".     │        0.002 Composed.__call__  autoray/autoray.py:921\n",
      ".     │        └─ 0.002 svd_truncated  symmray/linalg.py:212\n",
      ".     │        0.002 do  autoray/autoray.py:30\n",
      ".     │        └─ 0.002 reshape  symmray/interface.py:58\n",
      ".     │           └─ 0.002 Z2FermionicArray.reshape  symmray/abelian_core.py:1619\n",
      ".     │              └─ 0.002 Z2FermionicArray.fuse  symmray/fermionic_core.py:556\n",
      ".     │        0.003 wrapper  functools.py:883\n",
      ".     │        └─ 0.003 tensordot_fermionic  symmray/fermionic_core.py:711\n",
      ".     │           └─ 0.003 tensordot_abelian  symmray/abelian_core.py:1996\n",
      ".     │              └─ 0.003 _tensordot_via_fused  symmray/abelian_core.py:1941\n",
      ".     │                 └─ 0.002 Z2FermionicArray.unfuse  symmray/abelian_core.py:1536\n",
      ".     │        0.002 wrapper  functools.py:883\n",
      ".     │        └─ 0.002 tensordot_fermionic  symmray/fermionic_core.py:711\n",
      ".     │        0.009 wrapper  functools.py:883\n",
      ".     │        └─ 0.009 tensordot_fermionic  symmray/fermionic_core.py:711\n",
      ".     │           ├─ 0.006 tensordot_abelian  symmray/abelian_core.py:1996\n",
      ".     │           │  └─ 0.006 _tensordot_via_fused  symmray/abelian_core.py:1941\n",
      ".     │           │     ├─ 0.002 Z2FermionicArray.unfuse  symmray/abelian_core.py:1536\n",
      ".     │           │     └─ 0.002 Z2FermionicArray.fuse  symmray/abelian_core.py:1418\n",
      ".     │           └─ 0.002 Z2FermionicArray.transpose  symmray/fermionic_core.py:232\n",
      ".     ├─ 0.044 PEPS.contract_boundary_from_ymax  quimb/tensor/tensor_2d.py:2137\n",
      ".     │     [34 frames hidden]  quimb, functools, autoray, cotengra\n",
      ".     │        0.008 do  autoray/autoray.py:30\n",
      ".     │        └─ 0.008 fuse  symmray/interface.py:117\n",
      ".     │           └─ 0.008 Z2FermionicArray.fuse  symmray/fermionic_core.py:556\n",
      ".     │              ├─ 0.003 Z2FermionicArray.fuse  symmray/abelian_core.py:1418\n",
      ".     │              │  └─ 0.002 _VariableFunctionsClass.reshape  <built-in>\n",
      ".     │              ├─ 0.003 Z2FermionicArray.transpose  symmray/fermionic_core.py:232\n",
      ".     │              │  └─ 0.003 <genexpr>  symmray/fermionic_core.py:262\n",
      ".     │              └─ 0.002 Z2FermionicArray.phase_sync  symmray/fermionic_core.py:395\n",
      ".     │        0.006 wrapper  functools.py:883\n",
      ".     │        └─ 0.006 tensordot_fermionic  symmray/fermionic_core.py:711\n",
      ".     │           └─ 0.005 tensordot_abelian  symmray/abelian_core.py:1996\n",
      ".     │              └─ 0.005 _tensordot_via_fused  symmray/abelian_core.py:1941\n",
      ".     │                 └─ 0.004 Z2FermionicArray.fuse  symmray/abelian_core.py:1418\n",
      ".     │                    └─ 0.002 <dictcomp>  symmray/abelian_core.py:1524\n",
      ".     │                       └─ 0.002 _recurse_concat  symmray/abelian_core.py:1484\n",
      ".     │                          └─ 0.002 <genexpr>  symmray/abelian_core.py:1517\n",
      ".     │                             └─ 0.002 _recurse_concat  symmray/abelian_core.py:1484\n",
      ".     │                                └─ 0.002 translated_function  autoray/autoray.py:1310\n",
      ".     │        0.003 do  autoray/autoray.py:30\n",
      ".     │        └─ 0.003 reshape  symmray/interface.py:58\n",
      ".     │           └─ 0.003 Z2FermionicArray.reshape  symmray/abelian_core.py:1619\n",
      ".     │        0.004 do  autoray/autoray.py:30\n",
      ".     │        └─ 0.004 reshape  symmray/interface.py:58\n",
      ".     │           └─ 0.004 Z2FermionicArray.reshape  symmray/abelian_core.py:1619\n",
      ".     │              └─ 0.004 Z2FermionicArray.fuse  symmray/fermionic_core.py:556\n",
      ".     │        0.002 Composed.__call__  autoray/autoray.py:921\n",
      ".     │        └─ 0.002 qr_stabilized  symmray/linalg.py:118\n",
      ".     │           └─ 0.002 wrapper  functools.py:883\n",
      ".     │              └─ 0.002 qr_fermionic  symmray/linalg.py:107\n",
      ".     │                 └─ 0.002 qr  symmray/linalg.py:46\n",
      ".     │                    └─ 0.002 _qr  symmray/linalg.py:26\n",
      ".     │                       └─ 0.002 qr_stabilized  quimb/tensor/decomp.py:669\n",
      ".     │        0.007 wrapper  functools.py:883\n",
      ".     │        └─ 0.007 tensordot_fermionic  symmray/fermionic_core.py:711\n",
      ".     │           └─ 0.006 tensordot_abelian  symmray/abelian_core.py:1996\n",
      ".     │              └─ 0.006 _tensordot_via_fused  symmray/abelian_core.py:1941\n",
      ".     │                 ├─ 0.003 Z2FermionicArray.unfuse  symmray/abelian_core.py:1536\n",
      ".     │                 └─ 0.002 _tensordot_blockwise  symmray/abelian_core.py:1831\n",
      ".     ├─ 0.029 fPEPS.get_amp  vmc_torch/fermion_utils.py:32\n",
      ".     │  └─ 0.025 TensorNetwork.contract  quimb/tensor/tensor_core.py:8396\n",
      ".     │        [6 frames hidden]  quimb, functools, cotengra\n",
      ".     │           0.021 wrapper  functools.py:883\n",
      ".     │           └─ 0.021 tensordot_fermionic  symmray/fermionic_core.py:711\n",
      ".     │              ├─ 0.015 tensordot_abelian  symmray/abelian_core.py:1996\n",
      ".     │              │  └─ 0.015 _tensordot_via_fused  symmray/abelian_core.py:1941\n",
      ".     │              │     ├─ 0.009 Z2FermionicArray.fuse  symmray/abelian_core.py:1418\n",
      ".     │              │     │  └─ 0.005 <dictcomp>  symmray/abelian_core.py:1524\n",
      ".     │              │     │     └─ 0.005 _recurse_concat  symmray/abelian_core.py:1484\n",
      ".     │              │     │        └─ 0.005 <genexpr>  symmray/abelian_core.py:1517\n",
      ".     │              │     │           ├─ 0.003 _recurse_concat  symmray/abelian_core.py:1484\n",
      ".     │              │     │           │  └─ 0.003 translated_function  autoray/autoray.py:1310\n",
      ".     │              │     │           │        [1 frames hidden]  <built-in>\n",
      ".     │              │     │           └─ 0.002 [self]  symmray/abelian_core.py\n",
      ".     │              │     └─ 0.003 Z2FermionicArray.unfuse  symmray/abelian_core.py:1536\n",
      ".     │              │        └─ 0.002 _VariableFunctionsClass.reshape  <built-in>\n",
      ".     │              ├─ 0.003 Z2FermionicArray.transpose  symmray/fermionic_core.py:232\n",
      ".     │              └─ 0.002 Z2FermionicArray.phase_sync  symmray/fermionic_core.py:395\n",
      ".     ├─ 0.006 <dictcomp>  ../../../../../tmp/ipykernel_27785/3087146501.py:415\n",
      ".     │  └─ 0.006 <dictcomp>  ../../../../../tmp/ipykernel_27785/3087146501.py:416\n",
      ".     │     └─ 0.006 literal_eval  ast.py:54\n",
      ".     │           [3 frames hidden]  ast, <built-in>\n",
      ".     ├─ 0.004 PEPS.contract  quimb/tensor/tensor_core.py:8396\n",
      ".     │     [5 frames hidden]  functools, quimb, cotengra\n",
      ".     │        0.004 wrapper  functools.py:883\n",
      ".     │        └─ 0.004 tensordot_fermionic  symmray/fermionic_core.py:711\n",
      ".     │           └─ 0.004 tensordot_abelian  symmray/abelian_core.py:1996\n",
      ".     │              └─ 0.003 _tensordot_via_fused  symmray/abelian_core.py:1941\n",
      ".     │                 └─ 0.002 Z2FermionicArray.fuse  symmray/abelian_core.py:1418\n",
      ".     │                    └─ 0.002 <dictcomp>  symmray/abelian_core.py:1524\n",
      ".     │                       └─ 0.002 _recurse_concat  symmray/abelian_core.py:1484\n",
      ".     └─ 0.002 unpack  quimb/tensor/interface.py:50\n",
      ".           [1 frames hidden]  quimb\n",
      ".  \n",
      ".....................................................\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ftn_nn_model = fTN_NN_Model(peps, max_bond=8, nn_hidden_dim=16, nn_eta=1e-3)\n",
    "with pyinstrument.profile():\n",
    "    ftn_nn_model.amplitude([random_conf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in fTN model: 5184\n",
      "Number of TN parameters in fTN_NNiso model: 5184, NN parameters: 54992\n",
      "Number of TN parameters in fTN_NN model: 5184, NN parameters: 14192\n"
     ]
    }
   ],
   "source": [
    "# check number of parameters in each model\n",
    "print('Number of parameters in fTN model:', ftn_model.num_params)\n",
    "print('Number of TN parameters in fTN_NNiso model: {}, NN parameters: {}'.format(ftn_nniso_model.num_tn_params, ftn_nniso_model.num_params-ftn_nniso_model.num_tn_params))\n",
    "print('Number of TN parameters in fTN_NN model: {}, NN parameters: {}'.format(ftn_nn_model.num_tn_params, ftn_nn_model.num_params-ftn_nn_model.num_tn_params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vmc_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
