{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spinful Fermi Hubbard model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "n=50, tau=0.3000, energy~-0.327219: 100%|##########| 50/50 [00:06<00:00,  7.50it/s]\n",
      "n=100, tau=0.1000, energy~-0.399066: 100%|##########| 50/50 [00:06<00:00,  7.63it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"NUMBA_NUM_THREADS\"] = \"20\"\n",
    "\n",
    "import netket as nk\n",
    "import netket.experimental as nkx\n",
    "import netket.nn as nknn\n",
    "\n",
    "from math import pi\n",
    "\n",
    "from netket.experimental.operator.fermion import destroy as c\n",
    "from netket.experimental.operator.fermion import create as cdag\n",
    "from netket.experimental.operator.fermion import number as nc\n",
    "\n",
    "from vmc_torch.fermion_utils import generate_random_fpeps\n",
    "import quimb.tensor as qtn\n",
    "import symmray as sr\n",
    "import pickle\n",
    "\n",
    "# Define the lattice shape\n",
    "L = 4  # Side of the square\n",
    "Lx = int(L)\n",
    "Ly = int(L)\n",
    "spinless = False\n",
    "# graph = nk.graph.Square(L)\n",
    "graph = nk.graph.Grid([Lx,Ly], pbc=False)\n",
    "N = graph.n_nodes\n",
    "\n",
    "# Define the fermion filling and the Hilbert space\n",
    "N_f = int(Lx*Ly)\n",
    "hi = nkx.hilbert.SpinOrbitalFermions(N, s=1/2, n_fermions=N_f)\n",
    "\n",
    "\n",
    "# Define the Hubbard Hamiltonian\n",
    "t = 1.0\n",
    "U = 8.0\n",
    "mu = 0.0\n",
    "\n",
    "H = 0.0\n",
    "for (i, j) in graph.edges(): # Definition of the Hubbard Hamiltonian\n",
    "    for spin in (1,-1):\n",
    "        H -= t * (cdag(hi,i,spin) * c(hi,j,spin) + cdag(hi,j,spin) * c(hi,i,spin))\n",
    "for i in graph.nodes():\n",
    "    H += U * nc(hi,i,+1) * nc(hi,i,-1)\n",
    "\n",
    "\n",
    "# # Exact diagonalization of the Hamiltonian for benchmark\n",
    "# sp_h = H.to_sparse() # Convert the Hamiltonian to a sparse matrix\n",
    "# from scipy.sparse.linalg import eigsh\n",
    "# eig_vals, eig_vecs = eigsh(sp_h, k=2, which=\"SA\")\n",
    "# E_gs = eig_vals[0]\n",
    "# print(\"Exact ground state energy per site:\", E_gs/N)\n",
    "\n",
    "\n",
    "# SU in quimb\n",
    "D = 4\n",
    "seed = 2\n",
    "symmetry = 'U1'\n",
    "spinless = False\n",
    "peps = generate_random_fpeps(Lx, Ly, D=4, seed=2, symmetry=symmetry, Nf=N_f, spinless=spinless)[0]\n",
    "edges = qtn.edges_2d_square(Lx, Ly, cyclic=False)\n",
    "site_info = sr.utils.parse_edges_to_site_info(\n",
    "    edges,\n",
    "    D,\n",
    "    phys_dim=4,\n",
    "    site_ind_id=\"k{},{}\",\n",
    "    site_tag_id=\"I{},{}\",\n",
    ")\n",
    "\n",
    "t = 1.0\n",
    "U = 8.0\n",
    "mu = 0.0\n",
    "\n",
    "terms = {\n",
    "    (sitea, siteb): sr.fermi_hubbard_local_array(\n",
    "        t=t, U=U, mu=mu,\n",
    "        symmetry=symmetry,\n",
    "        coordinations=(\n",
    "            site_info[sitea]['coordination'],\n",
    "            site_info[siteb]['coordination'],\n",
    "        ),\n",
    "    ).fuse((0, 1), (2, 3))\n",
    "    for (sitea, siteb) in peps.gen_bond_coos()\n",
    "}\n",
    "ham = qtn.LocalHam2D(Lx, Ly, terms)\n",
    "\n",
    "su = qtn.SimpleUpdateGen(peps, ham, compute_energy_per_site=True,D=D, compute_energy_opts={\"max_distance\":1}, gate_opts={'cutoff':1e-12})\n",
    "\n",
    "# cluster energies may not be accuracte yet\n",
    "su.evolve(50, tau=0.3)\n",
    "su.evolve(50, tau=0.1)\n",
    "# su.evolve(100, tau=0.03)\n",
    "# su.evolve(100, tau=0.01)\n",
    "# su.evolve(100, tau=0.003)\n",
    "\n",
    "peps = su.get_state()\n",
    "peps.equalize_norms_(value=1)\n",
    "\n",
    "# save the state\n",
    "params, skeleton = qtn.pack(peps)\n",
    "\n",
    "import os\n",
    "os.makedirs(f'../data/{Lx}x{Ly}/t={t}_U={U}/N={N_f}/{symmetry}/D={D}', exist_ok=True)\n",
    "\n",
    "with open(f'../data/{Lx}x{Ly}/t={t}_U={U}/N={N_f}/{symmetry}/D={D}/peps_skeleton.pkl', 'wb') as f:\n",
    "    pickle.dump(skeleton, f)\n",
    "with open(f'../data/{Lx}x{Ly}/t={t}_U={U}/N={N_f}/{symmetry}/D={D}/peps_su_params.pkl', 'wb') as f:\n",
    "    pickle.dump(params, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heisenberg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quimb.tensor as qtn\n",
    "import quimb as qu\n",
    "\n",
    "import netket as nk\n",
    "from vmc_torch.hamiltonian import spin_Heisenberg_square_lattice\n",
    "import numpy as np\n",
    "from math import pi\n",
    "from autoray import do\n",
    "\n",
    "ndim = 2\n",
    "Lx = 2\n",
    "Ly = 2\n",
    "L = 2\n",
    "pbc = False\n",
    "total_sz = 0.0\n",
    "print(f\"Total Sz = {total_sz}\")\n",
    "D = 4\n",
    "\n",
    "# Build square lattice with nearest and next-nearest neighbor edges\n",
    "# lattice = nk.graph.Square(L, max_neighbor_order=1, pbc=False)\n",
    "# g = lattice = nk.graph.Hypercube(L, ndim, pbc=pbc)\n",
    "g = lattice = nk.graph.Grid([Lx, Ly], pbc=pbc)\n",
    "# g = lattice = nk.graph.Pyrochlore([L, L, L], pbc=pbc)\n",
    "\n",
    "n = lattice.n_nodes\n",
    "hi = nk.hilbert.Spin(s=1 / 2, total_sz=0.0, N=n)\n",
    "# Heisenberg with coupling J=1.0 for nearest neighbors\n",
    "# and J=0.5 for next-nearest neighbors\n",
    "# H = nk.operator.Ising(hilbert=hi, graph=lattice, J=1.0, h=1.0)\n",
    "H = nk.operator.Heisenberg(hilbert=hi, graph=lattice, J=1.0, sign_rule=False) # In Netket, the spin operators are Pauli matrices, while in Quimb they are 1/2*Pauli matrices\n",
    "\n",
    "ham0 = spin_Heisenberg_square_lattice(Lx, Ly, J=1.0, pbc=pbc,total_sz=total_sz)\n",
    "hi0 = ham0.hilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the ground-state energy (here we only need the lowest energy, and do not need the eigenstate)\n",
    "evals = nk.exact.lanczos_ed(H, compute_eigenvectors=False)\n",
    "exact_gs_energy = evals[0]\n",
    "print('The exact ground-state energy is E0=',exact_gs_energy)\n",
    "print(exact_gs_energy/(Lx*Ly)/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PEPS tensor network\n",
    "psi = qtn.PEPS.rand(Lx=Lx, Ly=Ly, bond_dim=D, phys_dim=2) # initialization from PEPS\n",
    "J=1.0\n",
    "ham = qtn.ham_2d_heis(Lx=Lx, Ly=Ly, j=J)\n",
    "su = qtn.tensor_arbgeom_tebd.SimpleUpdateGen(\n",
    "    psi, \n",
    "    ham,\n",
    "    compute_energy_every=10,\n",
    "    compute_energy_per_site=True,\n",
    ")\n",
    "for tau in [1.0, 0.3, 0.1, 0.03, 0.01]:\n",
    "    su.evolve(100, tau=tau)\n",
    "psi_su = su.state\n",
    "\n",
    "# peps = su.get_state()\n",
    "# peps.equalize_norms_(value=1)\n",
    "\n",
    "# # save the state\n",
    "# params, skeleton = qtn.pack(peps)\n",
    "\n",
    "# import os\n",
    "# import pickle\n",
    "# os.makedirs(f'../../data/{Lx}x{Ly}/J={J}/D={D}', exist_ok=True)\n",
    "\n",
    "# with open(f'../../data/{Lx}x{Ly}/J={J}/D={D}/peps_skeleton.pkl', 'wb') as f:\n",
    "#     pickle.dump(skeleton, f)\n",
    "# with open(f'../../data/{Lx}x{Ly}/J={J}/D={D}/peps_su_params.pkl', 'wb') as f:\n",
    "#     pickle.dump(params, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J1-J2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sijingdu/anaconda3/envs/vmc_torch/lib/python3.9/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\u001b[0m\n",
      "  warnings.warn(problem)\n",
      "/home/sijingdu/anaconda3/envs/vmc_torch/lib/python3.9/site-packages/cotengra/hyperoptimizers/hyper.py:33: UserWarning: Couldn't import `kahypar` - skipping from default hyper optimizer and using basic `labels` method instead.\n",
      "  warnings.warn(\n",
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sz = 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sijingdu/anaconda3/envs/vmc_torch/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "import os\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '1'\n",
    "import quimb.tensor as qtn\n",
    "import quimb as qu\n",
    "\n",
    "import netket as nk\n",
    "from netket.graph import Lattice\n",
    "from vmc_torch.hamiltonian import spin_Heisenberg_square_lattice\n",
    "import numpy as np\n",
    "from math import pi\n",
    "from autoray import do\n",
    "\n",
    "ndim = 2\n",
    "Lx = 10\n",
    "Ly = 10\n",
    "# L = 4\n",
    "pbc = False\n",
    "total_sz = 0.0\n",
    "print(f\"Total Sz = {total_sz}\")\n",
    "D = 4\n",
    "\n",
    "basis = np.array([\n",
    "     [1.0,0.0],\n",
    "     [0.0,1.0],\n",
    " ])\n",
    "custom_edges = [\n",
    "     (0, 0, [1.0,0.0], 0),\n",
    "     (0, 0, [0.0,1.0], 0),\n",
    "     (0, 0, [1.0, 1.0], 1),\n",
    "     (0, 0, [1.0, -1.0], 1),\n",
    " ]\n",
    "\n",
    "g = Lattice(basis_vectors=basis, pbc=False, extent=[Lx, Ly],\n",
    "     custom_edges=custom_edges)\n",
    "\n",
    "n = g.n_nodes\n",
    "hi = nk.hilbert.Spin(s=1/2, total_sz=0.0, N=n)\n",
    "# Heisenberg with coupling J=1.0 for nearest neighbors\n",
    "# and J=0.5 for next-nearest neighbors\n",
    "H = nk.operator.Heisenberg(hilbert=hi, graph=g, J=(1.0,0.5)) # In Netket, the spin operators are Pauli matrices, while in Quimb they are 1/2*Pauli matrices\n",
    "# ham0 = spin_Heisenberg_square_lattice(Lx, Ly, J=1.0, pbc=pbc,total_sz=total_sz)\n",
    "# hi0 = ham0.hilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compute the ground-state energy (here we only need the lowest energy, and do not need the eigenstate)\n",
    "# evals = nk.exact.lanczos_ed(H, compute_eigenvectors=False)\n",
    "# exact_gs_energy = evals[0]\n",
    "# print('The exact ground-state energy is E0=',exact_gs_energy)\n",
    "# print(exact_gs_energy/(Lx*Ly)/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 29\u001b[0m\n\u001b[1;32m     20\u001b[0m su \u001b[38;5;241m=\u001b[39m qtn\u001b[38;5;241m.\u001b[39mtensor_2d_tebd\u001b[38;5;241m.\u001b[39mSimpleUpdate(\n\u001b[1;32m     21\u001b[0m     psi, \n\u001b[1;32m     22\u001b[0m     ham,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m     compute_energy_per_site\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tau \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.03\u001b[39m, \u001b[38;5;241m0.01\u001b[39m]:\n\u001b[0;32m---> 29\u001b[0m     \u001b[43msu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevolve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtau\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m psi_su \u001b[38;5;241m=\u001b[39m su\u001b[38;5;241m.\u001b[39mstate\n\u001b[1;32m     32\u001b[0m peps \u001b[38;5;241m=\u001b[39m su\u001b[38;5;241m.\u001b[39mget_state()\n",
      "File \u001b[0;32m~/TNVMC/VMC_code/quimb/quimb/tensor/tensor_arbgeom_tebd.py:597\u001b[0m, in \u001b[0;36mTEBDGen.evolve\u001b[0;34m(self, steps, tau, progbar)\u001b[0m\n\u001b[1;32m    593\u001b[0m should_compute_energy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_energy_every) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    594\u001b[0m     i \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_energy_every \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    595\u001b[0m )\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_compute_energy:\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_energy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_progbar(pbar)\n\u001b[1;32m    600\u001b[0m \u001b[38;5;66;03m# actually perform the gates\u001b[39;00m\n",
      "File \u001b[0;32m~/TNVMC/VMC_code/quimb/quimb/tensor/tensor_arbgeom_tebd.py:653\u001b[0m, in \u001b[0;36mTEBDGen._check_energy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    651\u001b[0m     en \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_energy_fn(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    652\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 653\u001b[0m     en \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_energy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_energy_per_site:\n\u001b[1;32m    656\u001b[0m     en \u001b[38;5;241m=\u001b[39m en \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mham\u001b[38;5;241m.\u001b[39mnsites\n",
      "File \u001b[0;32m~/TNVMC/VMC_code/quimb/quimb/tensor/tensor_2d_tebd.py:333\u001b[0m, in \u001b[0;36mTEBD2D.compute_energy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_energy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute and return the energy of the current state.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241m.\u001b[39mcompute_local_expectation(\n\u001b[1;32m    334\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mham\u001b[38;5;241m.\u001b[39mterms,\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_energy_opts\n\u001b[1;32m    336\u001b[0m     )\n",
      "File \u001b[0;32m~/TNVMC/VMC_code/quimb/quimb/tensor/tensor_arbgeom_tebd.py:623\u001b[0m, in \u001b[0;36mTEBDGen.state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    622\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a copy of the current state.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/TNVMC/VMC_code/quimb/quimb/tensor/tensor_2d_tebd.py:641\u001b[0m, in \u001b[0;36mSimpleUpdate.get_state\u001b[0;34m(self, absorb_gauges)\u001b[0m\n\u001b[1;32m    639\u001b[0m         Ta \u001b[38;5;241m=\u001b[39m psi[ija]\n\u001b[1;32m    640\u001b[0m         Tb \u001b[38;5;241m=\u001b[39m psi[ijb]\n\u001b[0;32m--> 641\u001b[0m         \u001b[43mTa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiply_index_diagonal_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbnd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTsval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    642\u001b[0m         Tb\u001b[38;5;241m.\u001b[39mmultiply_index_diagonal_(bnd, Tsval\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcondition_tensors:\n",
      "File \u001b[0;32m~/TNVMC/VMC_code/quimb/quimb/tensor/tensor_core.py:2871\u001b[0m, in \u001b[0;36mTensor.multiply_index_diagonal\u001b[0;34m(self, ind, x, inplace)\u001b[0m\n\u001b[1;32m   2869\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m   2870\u001b[0m ax \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39minds\u001b[38;5;241m.\u001b[39mindex(ind)\n\u001b[0;32m-> 2871\u001b[0m t\u001b[38;5;241m.\u001b[39mmodify(data\u001b[38;5;241m=\u001b[39m\u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmultiply_diagonal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43max\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2872\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/anaconda3/envs/vmc_torch/lib/python3.9/site-packages/autoray/autoray.py:81\u001b[0m, in \u001b[0;36mdo\u001b[0;34m(fn, like, *args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m backend \u001b[38;5;241m=\u001b[39m _choose_backend(fn, args, kwargs, like\u001b[38;5;241m=\u001b[39mlike)\n\u001b[1;32m     80\u001b[0m func \u001b[38;5;241m=\u001b[39m get_lib_fn(backend, fn)\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/TNVMC/VMC_code/quimb/quimb/tensor/array_ops.py:173\u001b[0m, in \u001b[0;36mmultiply_diagonal\u001b[0;34m(x, v, axis, backend)\u001b[0m\n\u001b[1;32m    171\u001b[0m newshape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m axis \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ndim(x)))\n\u001b[1;32m    172\u001b[0m v_broadcast \u001b[38;5;241m=\u001b[39m do(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, v, newshape, like\u001b[38;5;241m=\u001b[39mbackend)\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mv_broadcast\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "def to_backend(x):\n",
    "    return torch.tensor(x, dtype=torch.float64, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # import cupy as cp\n",
    "    # return cp.array(x)\n",
    "# PEPS tensor network\n",
    "psi = qtn.PEPS.rand(Lx=Lx, Ly=Ly, bond_dim=D, phys_dim=2) # initialization from PEPS\n",
    "J1=1.0\n",
    "J2=0.5\n",
    "ham = qtn.ham_2d_j1j2(Lx, Ly, j1=J1, j2=J2)\n",
    "\n",
    "psi.apply_to_arrays(to_backend)\n",
    "ham.apply_to_arrays(to_backend)\n",
    "# su = qtn.tensor_arbgeom_tebd.SimpleUpdateGen(\n",
    "#     psi, \n",
    "#     ham,\n",
    "#     compute_energy_every=10,\n",
    "#     compute_energy_per_site=True,\n",
    "# )\n",
    "\n",
    "su = qtn.tensor_2d_tebd.SimpleUpdate(\n",
    "    psi, \n",
    "    ham,\n",
    "    D=D,\n",
    "    compute_energy_every=100,\n",
    "    compute_energy_per_site=True,\n",
    ")\n",
    "\n",
    "for tau in [1.0, 0.3, 0.1, 0.03, 0.01]:\n",
    "    su.evolve(100, tau=tau)\n",
    "psi_su = su.state\n",
    "\n",
    "peps = su.get_state()\n",
    "peps.equalize_norms_(value=1)\n",
    "\n",
    "# save the state\n",
    "params, skeleton = qtn.pack(peps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda', index=0),\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=torch.float64),\n",
       " 'torch')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import autoray as ar\n",
    "arr = psi.arrays[0]\n",
    "arr.device, do('ones', (10,), like=arr, device='cuda'), ar.infer_backend(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "os.makedirs(f'../../data/{Lx}x{Ly}/J1={J1}_J2={J2}/D={D}', exist_ok=True)\n",
    "\n",
    "with open(f'../../data/{Lx}x{Ly}/J1={J1}_J2={J2}/D={D}/peps_skeleton.pkl', 'wb') as f:\n",
    "    pickle.dump(skeleton, f)\n",
    "with open(f'../../data/{Lx}x{Ly}/J1={J1}_J2={J2}/D={D}/peps_su_params.pkl', 'wb') as f:\n",
    "    pickle.dump(params, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vmc_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
