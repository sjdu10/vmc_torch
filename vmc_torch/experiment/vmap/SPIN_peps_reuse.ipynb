{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "110949be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.1779e-08,  9.7329e-12,  1.0413e-07, -7.5432e-09,  5.3392e-12,\n",
      "        -2.9437e-06, -5.0227e-06,  5.1558e-08, -7.5467e-07,  7.4506e-06,\n",
      "         8.1744e-09,  2.0786e-06,  6.1282e-06, -2.6822e-07,  8.2713e-13,\n",
      "        -9.7471e-09, -4.5175e-09,  4.0028e-08, -1.2476e-07, -3.8701e-07,\n",
      "        -1.0025e-06, -2.3055e-11, -4.9738e-09,  8.0886e-08, -8.8793e-10,\n",
      "         1.7545e-06, -1.1090e-07,  3.9053e-10, -1.3652e-08,  1.0510e-07,\n",
      "        -1.9913e-06, -6.0971e-06, -3.2986e-06, -1.0869e-07,  8.8661e-05,\n",
      "         1.3513e-07,  1.2099e-06, -1.6036e-06,  1.1892e-06,  3.8461e-07,\n",
      "         1.3023e-08, -2.1887e-06, -2.9337e-06, -2.3970e-07, -1.2801e-08,\n",
      "        -3.9696e-06,  2.1027e-07,  1.4887e-06,  2.2544e-06, -4.5873e-07,\n",
      "        -1.2213e-06, -2.1170e-05,  4.0730e-11,  1.9668e-07,  5.0741e-07,\n",
      "         4.0429e-09, -4.2158e-07, -4.5128e-10,  6.3252e-08,  6.5152e-07,\n",
      "         2.5725e-10, -3.9927e-07,  1.5364e-06,  1.0661e-07],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "from vmc_torch.experiment.vmap.vmap_models import PEPS_Model\n",
    "import quimb.tensor as qtn\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "Lx = 6\n",
    "Ly = 6\n",
    "D = 4\n",
    "chi = 4*D\n",
    "seed = 42\n",
    "pwd = '/home/sijingdu/TNVMC/VMC_code/vmc_torch/vmc_torch/experiment/vmap/data'\n",
    "skeleton = pickle.load(open(pwd+f'/{Lx}x{Ly}/heis/D={D}/peps_skeleton.pkl', 'rb'))\n",
    "params = pickle.load(open(pwd+f'/{Lx}x{Ly}/heis/D={D}/peps_su_params.pkl', 'rb'))\n",
    "peps = qtn.unpack(params, skeleton)\n",
    "# peps = qtn.PEPS.rand(Lx, Ly, D, seed=seed)\n",
    "\n",
    "model = PEPS_Model(tn=peps, max_bond=chi)\n",
    "\n",
    "B = 64\n",
    "random_binary_config = torch.randint(0, 2, (B, Lx*Ly)).int()\n",
    "with torch.no_grad():\n",
    "    print(model(random_binary_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71cf1149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vmc_torch.hamiltonian_torch import spin_Heisenberg_square_lattice_torch\n",
    "\n",
    "H = spin_Heisenberg_square_lattice_torch(Lx, Ly, J=1.0, total_sz=0)\n",
    "# all_states = torch.tensor(H.hilbert.all_states())\n",
    "# psi_vec = model(all_states).detach().cpu().numpy()\n",
    "# H_dense = H.to_dense()\n",
    "# E_expect = np.vdot(psi_vec, H_dense @ psi_vec) / np.vdot(psi_vec, psi_vec)\n",
    "# print(\"Energy per site:\", E_expect)\n",
    "# np.linalg.eigvals(H.to_dense())[0]/(Lx*Ly)  # ground state energy per site check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59829641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sijingdu/TNVMC/VMC_code/quimb/quimb/utils.py:170: Warning: The row_tag function is deprecated in favor of x_tag\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-4.1779e-08,  9.7329e-12,  1.0413e-07, -7.5432e-09,  5.3392e-12,\n",
       "        -2.9437e-06, -5.0227e-06,  5.1558e-08, -7.5467e-07,  7.4506e-06,\n",
       "         8.1744e-09,  2.0786e-06,  6.1282e-06, -2.6822e-07,  8.2713e-13,\n",
       "        -9.7471e-09, -4.5175e-09,  4.0028e-08, -1.2476e-07, -3.8701e-07,\n",
       "        -1.0025e-06, -2.3055e-11, -4.9738e-09,  8.0886e-08, -8.8793e-10,\n",
       "         1.7545e-06, -1.1090e-07,  3.9053e-10, -1.3652e-08,  1.0510e-07,\n",
       "        -1.9913e-06, -6.0971e-06, -3.2986e-06, -1.0869e-07,  8.8661e-05,\n",
       "         1.3513e-07,  1.2099e-06, -1.6036e-06,  1.1892e-06,  3.8461e-07,\n",
       "         1.3023e-08, -2.1887e-06, -2.9337e-06, -2.3970e-07, -1.2801e-08,\n",
       "        -3.9696e-06,  2.1027e-07,  1.4887e-06,  2.2544e-06, -4.5873e-07,\n",
       "        -1.2213e-06, -2.1170e-05,  4.0730e-11,  1.9668e-07,  5.0741e-07,\n",
       "         4.0429e-09, -4.2158e-07, -4.5128e-10,  6.3252e-08,  6.5152e-07,\n",
       "         2.5725e-10, -3.9927e-07,  1.5364e-06,  1.0661e-07],\n",
       "       dtype=torch.float64, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import quimb as qu\n",
    "class PEPS_Model_reuse(nn.Module):\n",
    "    def __init__(self, tn, max_bond, dtype=torch.float64):\n",
    "        import quimb as qu\n",
    "        import quimb.tensor as qtn\n",
    "        super().__init__()\n",
    "        \n",
    "        params, skeleton = qtn.pack(tn)\n",
    "        self.dtype = dtype\n",
    "        self.skeleton = skeleton\n",
    "        self.Lx = tn.Lx\n",
    "        self.Ly = tn.Ly\n",
    "        self.bMPS_x_skeletons = {}\n",
    "        self.bMPS_y_skeletons = {}\n",
    "        self.bMPS_params_x_in_dims = None\n",
    "        self.bMPS_params_y_in_dims = None\n",
    "        self.chi = max_bond\n",
    "\n",
    "        # for torch, further flatten pytree into a single list\n",
    "        params_flat, params_pytree = qu.utils.tree_flatten(\n",
    "            params, get_ref=True\n",
    "        )\n",
    "        self.params_pytree = params_pytree\n",
    "\n",
    "        # register the flat list parameters\n",
    "        self.params = torch.nn.ParameterList([\n",
    "            torch.as_tensor(x, dtype=self.dtype) for x in params_flat\n",
    "        ])\n",
    "    \n",
    "    def cache_bMPS_skeleton(self, x):\n",
    "        params = qu.utils.tree_unflatten(self.params, self.params_pytree)\n",
    "        tn = qtn.unpack(params, self.skeleton)\n",
    "        amp = tn.isel({tn.site_ind(site): x[i] for i, site in enumerate(tn.sites)})\n",
    "        env_x = amp.compute_x_environments(max_bond=self.chi, cutoff=0.0)\n",
    "        bMPS_params_dict = {}\n",
    "        for key, tn in env_x.items():\n",
    "            bMPS_params, skeleton = qtn.pack(tn)\n",
    "            env_x[key] = skeleton\n",
    "            bMPS_params_dict[key] = bMPS_params\n",
    "\n",
    "        self.bMPS_x_skeletons = env_x\n",
    "        bMPS_params_x_in_dims = qu.utils.tree_map(lambda _: 0, bMPS_params_dict)\n",
    "        self.bMPS_params_x_in_dims = bMPS_params_x_in_dims\n",
    "\n",
    "        env_y = amp.compute_y_environments(max_bond=self.chi, cutoff=0.0)\n",
    "        bMPS_params_dict = {}\n",
    "        for key, tn in env_y.items():\n",
    "            bMPS_params, skeleton = qtn.pack(tn)\n",
    "            env_y[key] = skeleton\n",
    "            bMPS_params_dict[key] = bMPS_params\n",
    "        self.bMPS_y_skeletons = env_y\n",
    "        bMPS_params_y_in_dims = qu.utils.tree_map(lambda _: 0, bMPS_params_dict)\n",
    "        self.bMPS_params_y_in_dims = bMPS_params_y_in_dims\n",
    "\n",
    "    \n",
    "    def cache_bMPS_params_vmap(self, x):\n",
    "        # return a pytree (dict) of bMPS params for x and y environments\n",
    "        params = qu.utils.tree_unflatten(self.params, self.params_pytree)\n",
    "        def cache_bMPS_params_single(x_single, params):\n",
    "            tn = qtn.unpack(params, self.skeleton)\n",
    "            amp = tn.isel({tn.site_ind(site): x_single[i] for i, site in enumerate(tn.sites)})\n",
    "            env_x = amp.compute_x_environments(max_bond=self.chi, cutoff=0.0)\n",
    "            bMPS_params_x_dict = {}\n",
    "            for key, btn in env_x.items():\n",
    "                bMPS_params = btn.get_params()\n",
    "                bMPS_params_x_dict[key] = bMPS_params\n",
    "            bMPS_params_y_dict = {}\n",
    "            env_y = amp.compute_y_environments(max_bond=self.chi, cutoff=0.0)\n",
    "            for key, btn in env_y.items():\n",
    "                bMPS_params = btn.get_params()\n",
    "                bMPS_params_y_dict[key] = bMPS_params\n",
    "            return bMPS_params_x_dict, bMPS_params_y_dict\n",
    "        return torch.vmap(\n",
    "            cache_bMPS_params_single,\n",
    "            in_dims=(0, None),\n",
    "        )(x, params)\n",
    "    \n",
    "    def cache_bMPS_params_any_direction_vmap(self, x, direction='x'):\n",
    "        # return a pytree (dict) of bMPS params for x or y environments\n",
    "        params = qu.utils.tree_unflatten(self.params, self.params_pytree)\n",
    "        def cache_bMPS_params_x_single(x_single, params):\n",
    "            tn = qtn.unpack(params, self.skeleton)\n",
    "            amp = tn.isel({tn.site_ind(site): x_single[i] for i, site in enumerate(tn.sites)})\n",
    "            env_x = amp.compute_x_environments(max_bond=self.chi, cutoff=0.0)\n",
    "            amp_val = (env_x[('xmin', self.Lx//2)]|env_x[('xmax', self.Lx//2-1)]).contract()\n",
    "            bMPS_params_x_dict = {}\n",
    "            for key, btn in env_x.items():\n",
    "                bMPS_params = btn.get_params()\n",
    "                bMPS_params_x_dict[key] = bMPS_params\n",
    "            return bMPS_params_x_dict, amp_val\n",
    "        def cache_bMPS_params_y_single(x_single, params):\n",
    "            tn = qtn.unpack(params, self.skeleton)\n",
    "            amp = tn.isel({tn.site_ind(site): x_single[i] for i, site in enumerate(tn.sites)})\n",
    "            env_y = amp.compute_y_environments(max_bond=self.chi, cutoff=0.0)\n",
    "            amp_val = (env_y[('ymin', self.Ly//2)]|env_y[('ymax', self.Ly//2-1)]).contract()\n",
    "            bMPS_params_y_dict = {}\n",
    "            for key, btn in env_y.items():\n",
    "                bMPS_params = btn.get_params()\n",
    "                bMPS_params_y_dict[key] = bMPS_params\n",
    "            return bMPS_params_y_dict, amp_val\n",
    "        if direction == 'x':\n",
    "            return torch.vmap(\n",
    "                cache_bMPS_params_x_single,\n",
    "                in_dims=(0, None),\n",
    "            )(x, params)\n",
    "        else:\n",
    "            return torch.vmap(\n",
    "                cache_bMPS_params_y_single,\n",
    "                in_dims=(0, None),\n",
    "            )(x, params)\n",
    "    \n",
    "    def update_bMPS_params_to_row_vmap(self, x, row_id, bMPS_params_x_batched, from_which='xmin'):\n",
    "        # update the bMPS params to a specific row_id for all samples in the batch\n",
    "        bMPS_key = (from_which, row_id)\n",
    "        params = qu.utils.tree_unflatten(self.params, self.params_pytree)\n",
    "        def update_bMPS_params_x_single(x_single, params, row_id, bMPS_params_x, from_which):\n",
    "            tn = qtn.unpack(params, self.skeleton)\n",
    "            amp = tn.isel({tn.site_ind(site): x_single[i] for i, site in enumerate(tn.sites)})\n",
    "            bMPS_to_row = qtn.unpack(bMPS_params_x[bMPS_key], self.bMPS_x_skeletons[bMPS_key])\n",
    "            row_tn = amp.select([tn.row_tag(row_id)], which='any')\n",
    "            # MPO-MPS two row TN\n",
    "            updated_bMPS = (bMPS_to_row|row_tn)\n",
    "            # contract to get the updated bMPS, row_id+1 for xmin, row_id-1 for xmax\n",
    "            if from_which == 'xmin':\n",
    "                if row_id == 0:\n",
    "                    updated_bMPS = row_tn\n",
    "                else:\n",
    "                    updated_bMPS.contract_boundary_from_xmin_(max_bond=self.chi, cutoff=0.0, xrange=[row_id-1, row_id])\n",
    "                updated_bMPS_params = updated_bMPS.get_params()\n",
    "                pytree_params, _ = qu.utils.tree_flatten(updated_bMPS_params, get_ref=True)\n",
    "                _, pytree = qu.utils.tree_flatten(bMPS_params_x[(from_which, row_id+1)], get_ref=True)\n",
    "                updated_bMPS_params = qu.utils.tree_unflatten(pytree_params, pytree)\n",
    "                bMPS_params_x[(from_which, row_id+1)] = updated_bMPS_params # inplace update\n",
    "            else:\n",
    "                if row_id == amp.Ly-1:\n",
    "                    updated_bMPS = row_tn\n",
    "                else:\n",
    "                    updated_bMPS.contract_boundary_from_xmax_(max_bond=self.chi, cutoff=0.0, xrange=[row_id, row_id+1])\n",
    "                updated_bMPS_params = updated_bMPS.get_params()\n",
    "                pytree_params, _ = qu.utils.tree_flatten(updated_bMPS_params, get_ref=True)\n",
    "                _, pytree = qu.utils.tree_flatten(bMPS_params_x[(from_which, row_id-1)], get_ref=True)\n",
    "                updated_bMPS_params = qu.utils.tree_unflatten(pytree_params, pytree)\n",
    "                bMPS_params_x[(from_which, row_id-1)] = updated_bMPS_params # inplace update\n",
    "            return bMPS_params_x\n",
    "        return torch.vmap(\n",
    "            update_bMPS_params_x_single,\n",
    "            in_dims=(0, None, None, self.bMPS_params_x_in_dims, None),\n",
    "        )(x, params, row_id, bMPS_params_x_batched, from_which)\n",
    "    \n",
    "    def update_bMPS_params_to_col_vmap(self, x, col_id, bMPS_params_y_batched, from_which='ymin'):\n",
    "        # update the bMPS params to a specific col_id for all samples in the batch\n",
    "        bMPS_key = (from_which, col_id)\n",
    "        params = qu.utils.tree_unflatten(self.params, self.params_pytree)\n",
    "        def update_bMPS_params_y_single(x_single, params, col_id, bMPS_params_y, from_which):\n",
    "            tn = qtn.unpack(params, self.skeleton)\n",
    "            amp = tn.isel({tn.site_ind(site): x_single[i] for i, site in enumerate(tn.sites)})\n",
    "            bMPS_to_col = qtn.unpack(bMPS_params_y[bMPS_key], self.bMPS_y_skeletons[bMPS_key])\n",
    "            col_tn = amp.select([tn.col_tag(col_id)], which='any')\n",
    "            # MPO-MPS two col TN\n",
    "            updated_bMPS = (bMPS_to_col|col_tn)\n",
    "            # contract to get the updated bMPS, col_id+1 for ymin, col_id-1 for ymax\n",
    "            if from_which == 'ymin':\n",
    "                if col_id == 0:\n",
    "                    updated_bMPS = col_tn\n",
    "                else:\n",
    "                    updated_bMPS.contract_boundary_from_ymin_(max_bond=self.chi, cutoff=0.0, yrange=[col_id-1, col_id])\n",
    "                updated_bMPS_params = updated_bMPS.get_params()\n",
    "                pytree_params, _ = qu.utils.tree_flatten(updated_bMPS_params, get_ref=True)\n",
    "                _, pytree = qu.utils.tree_flatten(bMPS_params_y[(from_which, col_id+1)], get_ref=True)\n",
    "                updated_bMPS_params = qu.utils.tree_unflatten(pytree_params, pytree)\n",
    "                bMPS_params_y[(from_which, col_id+1)] = updated_bMPS_params # inplace update\n",
    "            else:\n",
    "                if col_id == amp.Lx-1:\n",
    "                    updated_bMPS = col_tn\n",
    "                else:\n",
    "                    updated_bMPS.contract_boundary_from_ymax_(max_bond=self.chi, cutoff=0.0, yrange=[col_id, col_id+1])\n",
    "                updated_bMPS_params = updated_bMPS.get_params()\n",
    "                pytree_params, _ = qu.utils.tree_flatten(updated_bMPS_params, get_ref=True)\n",
    "                _, pytree = qu.utils.tree_flatten(bMPS_params_y[(from_which, col_id-1)], get_ref=True)\n",
    "                updated_bMPS_params = qu.utils.tree_unflatten(pytree_params, pytree)\n",
    "                bMPS_params_y[(from_which, col_id-1)] = updated_bMPS_params # inplace update\n",
    "            return bMPS_params_y\n",
    "        return torch.vmap(\n",
    "            update_bMPS_params_y_single,\n",
    "            in_dims=(0, None, None, self.bMPS_params_y_in_dims, None),\n",
    "        )(x, params, col_id, bMPS_params_y_batched, from_which)\n",
    "            \n",
    "        \n",
    "    def amp_tn(self, x):\n",
    "        params = qu.utils.tree_unflatten(self.params, self.params_pytree)\n",
    "        tn = qtn.unpack(params, self.skeleton)\n",
    "        # might need to specify the right site ordering here\n",
    "        amp = tn.isel({tn.site_ind(site): x[i] for i, site in enumerate(tn.sites)})\n",
    "        return amp\n",
    "    \n",
    "    def amplitude(\n",
    "        self,\n",
    "        x,\n",
    "        params,\n",
    "        bMPS_keys=None,\n",
    "        bMPS_params_xmin=None,\n",
    "        bMPS_params_xmax=None,\n",
    "        bMPS_params_ymin=None,\n",
    "        bMPS_params_ymax=None,\n",
    "        selected_rows=None,\n",
    "        selected_cols=None,\n",
    "    ):\n",
    "        tn = qtn.unpack(params, self.skeleton)\n",
    "        # might need to specify the right site ordering here\n",
    "        amp = tn.isel({tn.site_ind(site): x[i] for i, site in enumerate(tn.sites)})\n",
    "\n",
    "        # replace the x-environment with the cached one\n",
    "        if bMPS_params_xmin is not None and bMPS_params_xmax is not None and bMPS_keys is not None:\n",
    "            bMPS_min = qtn.unpack(bMPS_params_xmin, self.bMPS_x_skeletons[bMPS_keys[0]])\n",
    "            bMPS_max = qtn.unpack(bMPS_params_xmax, self.bMPS_x_skeletons[bMPS_keys[1]])\n",
    "            rows = amp.select([tn.row_tag(row) for row in selected_rows], which='any')\n",
    "            amp_reuse = (bMPS_min|rows|bMPS_max)\n",
    "            amp_reuse.view_as_(\n",
    "                qtn.PEPS,\n",
    "                site_tag_id = tn._site_tag_id,\n",
    "                x_tag_id = tn._x_tag_id,\n",
    "                y_tag_id = tn._y_tag_id,\n",
    "                Lx = tn._Lx,\n",
    "                Ly = tn._Ly,\n",
    "                site_ind_id = tn._site_ind_id,\n",
    "            )\n",
    "            if self.chi > 0:\n",
    "                amp_reuse.contract_boundary_from_xmin_(max_bond=self.chi, cutoff=0.0, xrange=[bMPS_keys[0][1], bMPS_keys[1][1]+1])\n",
    "            return amp_reuse.contract()\n",
    "        # replace the y-environment with the cached one\n",
    "        if bMPS_params_ymin is not None and bMPS_params_ymax is not None and bMPS_keys is not None:\n",
    "            bMPS_min = qtn.unpack(bMPS_params_ymin, self.bMPS_y_skeletons[bMPS_keys[0]])\n",
    "            bMPS_max = qtn.unpack(bMPS_params_ymax, self.bMPS_y_skeletons[bMPS_keys[1]])\n",
    "            cols = amp.select([tn.col_tag(col) for col in selected_cols], which='any')\n",
    "            amp_reuse = (bMPS_min|cols|bMPS_max)\n",
    "            amp_reuse.view_as_(\n",
    "                qtn.PEPS,\n",
    "                site_tag_id = tn._site_tag_id,\n",
    "                x_tag_id = tn._x_tag_id,\n",
    "                y_tag_id = tn._y_tag_id,\n",
    "                Lx = tn._Lx,\n",
    "                Ly = tn._Ly,\n",
    "                site_ind_id = tn._site_ind_id,\n",
    "            )\n",
    "            if self.chi > 0:\n",
    "                amp_reuse.contract_boundary_from_ymin_(max_bond=self.chi, cutoff=0.0, yrange=[bMPS_keys[0][1], bMPS_keys[1][1]+1])\n",
    "            return amp_reuse.contract()\n",
    "\n",
    "        if self.chi > 0:\n",
    "            amp.contract_boundary_from_ymin_(max_bond=self.chi, cutoff=0.0, yrange=[0, amp.Ly//2-1])\n",
    "            amp.contract_boundary_from_ymax_(max_bond=self.chi, cutoff=0.0, yrange=[amp.Ly//2, amp.Ly-1])\n",
    "        return amp.contract()\n",
    "    \n",
    "    def vamp(\n",
    "        self,\n",
    "        x,\n",
    "        params,\n",
    "        bMPS_keys=None,\n",
    "        bMPS_params_xmin=None,\n",
    "        bMPS_params_xmax=None,\n",
    "        bMPS_params_ymin=None,\n",
    "        bMPS_params_ymax=None,\n",
    "        selected_rows=None,\n",
    "        selected_cols=None,\n",
    "    ):\n",
    "        params = qu.utils.tree_unflatten(params, self.params_pytree)\n",
    "        if bMPS_params_xmin is not None and bMPS_params_xmax is not None:\n",
    "            return torch.vmap(\n",
    "                self.amplitude,\n",
    "                in_dims=(\n",
    "                    0,\n",
    "                    None,\n",
    "                    None,\n",
    "                    self.bMPS_params_x_in_dims[bMPS_keys[0]],\n",
    "                    self.bMPS_params_x_in_dims[bMPS_keys[1]],\n",
    "                    None,\n",
    "                    None,\n",
    "                    None,\n",
    "                    None,\n",
    "                ),\n",
    "            )(x, params, bMPS_keys, bMPS_params_xmin, bMPS_params_xmax, bMPS_params_ymin, bMPS_params_ymax, selected_rows, selected_cols)\n",
    "        \n",
    "        if bMPS_params_ymin is not None and bMPS_params_ymax is not None:\n",
    "            return torch.vmap(\n",
    "                self.amplitude,\n",
    "                in_dims=(\n",
    "                    0,\n",
    "                    None,\n",
    "                    None,\n",
    "                    None,\n",
    "                    None,\n",
    "                    self.bMPS_params_y_in_dims[bMPS_keys[0]],\n",
    "                    self.bMPS_params_y_in_dims[bMPS_keys[1]],\n",
    "                    None,\n",
    "                    None,\n",
    "                ),\n",
    "            )(x, params, bMPS_keys, bMPS_params_xmin, bMPS_params_xmax, bMPS_params_ymin, bMPS_params_ymax, selected_rows, selected_cols)\n",
    "\n",
    "        def amplitude_det(x, params):\n",
    "            tn = qtn.unpack(params, self.skeleton)\n",
    "            # might need to specify the right site ordering here\n",
    "            amp = tn.isel({tn.site_ind(site): x[i] for i, site in enumerate(tn.sites)})\n",
    "            if self.chi > 0:\n",
    "                amp.contract_boundary_from_ymin_(max_bond=self.chi, cutoff=0.0, yrange=[0, amp.Ly//2-1])\n",
    "                amp.contract_boundary_from_ymax_(max_bond=self.chi, cutoff=0.0, yrange=[amp.Ly//2, amp.Ly-1])\n",
    "            return amp.contract()\n",
    "        \n",
    "        return torch.vmap(\n",
    "            amplitude_det,\n",
    "            in_dims=(0, None),\n",
    "        )(x, params)\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        bMPS_params_x_batched=None,\n",
    "        bMPS_params_y_batched=None,\n",
    "        selected_rows=None,\n",
    "        selected_cols=None,\n",
    "    ):\n",
    "        bMPS_params_xmin = None\n",
    "        bMPS_params_xmax = None\n",
    "        bMPS_params_ymin = None\n",
    "        bMPS_params_ymax = None\n",
    "        bMPS_keys = None\n",
    "\n",
    "        if selected_rows is not None:\n",
    "            bMPS_keys = [('xmin', min(selected_rows)), ('xmax', max(selected_rows))]\n",
    "            bMPS_params_xmin = bMPS_params_x_batched[bMPS_keys[0]]\n",
    "            bMPS_params_xmax = bMPS_params_x_batched[bMPS_keys[1]]\n",
    "        if selected_cols is not None:\n",
    "            bMPS_keys = [('ymin', min(selected_cols)), ('ymax', max(selected_cols))]\n",
    "            bMPS_params_ymin = bMPS_params_y_batched[bMPS_keys[0]]\n",
    "            bMPS_params_ymax = bMPS_params_y_batched[bMPS_keys[1]]\n",
    "        \n",
    "        return self.vamp(\n",
    "            x,\n",
    "            self.params,\n",
    "            bMPS_keys=bMPS_keys,\n",
    "            bMPS_params_xmin=bMPS_params_xmin,\n",
    "            bMPS_params_xmax=bMPS_params_xmax,\n",
    "            bMPS_params_ymin=bMPS_params_ymin,\n",
    "            bMPS_params_ymax=bMPS_params_ymax,\n",
    "            selected_rows=selected_rows,\n",
    "            selected_cols=selected_cols,\n",
    "        )\n",
    "\n",
    "model_reuse = PEPS_Model_reuse(tn=peps, max_bond=chi)\n",
    "model_reuse.cache_bMPS_skeleton(random_binary_config[0])\n",
    "reuse_B = 100\n",
    "test_fxs = random_binary_config[:reuse_B]\n",
    "amp_tns = [model_reuse.amp_tn(test_fx) for test_fx in test_fxs]\n",
    "with torch.no_grad():\n",
    "    B_bMPS_params_x_dict, B_bMPS_params_y_dict = model_reuse.cache_bMPS_params_vmap(test_fxs)\n",
    "    current_amps = model_reuse(test_fxs, bMPS_params_x_batched=B_bMPS_params_x_dict, bMPS_params_y_batched=B_bMPS_params_y_dict, selected_rows=(2,), selected_cols=None)\n",
    "# current_amps\n",
    "# [amp_tns[i].contract() for i in range(reuse_B)]\n",
    "# print(test_fxs)\n",
    "# print(\"Amplitudes with reuse:\", current_amps)\n",
    "model_reuse(test_fxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "57fe9442",
   "metadata": {},
   "outputs": [],
   "source": [
    "changed_row_id = 1\n",
    "# randomly permute the row 0 of all test_fxs\n",
    "# torch.random.manual_seed(42)\n",
    "# perm = torch.randperm(Ly)\n",
    "# test_fxs[:, changed_row_id*Ly:(changed_row_id+1)*Ly] = test_fxs[:, changed_row_id*Ly:(changed_row_id+1)*Ly][:, perm]\n",
    "# print(test_fxs)\n",
    "\n",
    "with torch.no_grad():\n",
    "    new_B_bMPS_params_x_dict = model_reuse.update_bMPS_params_to_row_vmap(test_fxs, row_id=1, bMPS_params_x_batched=B_bMPS_params_x_dict, from_which='xmin')\n",
    "\n",
    "# get the pytree structure of new_B_bMPS_params_x_dict[('xmin', 2)]\n",
    "with torch.no_grad():\n",
    "    pytree = torch.utils._pytree.tree_flatten(new_B_bMPS_params_x_dict[('xmin', 2)])[1]\n",
    "    pytree_old = torch.utils._pytree.tree_flatten(B_bMPS_params_x_dict[('xmin', 2)])[1]\n",
    "    current_amps = model_reuse(test_fxs, bMPS_params_x_batched=new_B_bMPS_params_x_dict, bMPS_params_y_batched=B_bMPS_params_y_dict, selected_rows=(2,), selected_cols=None)\n",
    "# current_amps\n",
    "# print(\"Amplitudes with reuse after updating row 1:\", current_amps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3727af14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1386/881000176.py:19: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  changed_pos = torch.nonzero(fx1 - fx2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy (Reuse)    : -19.618847917040775, time: 2.1739 s\n",
      "Energy (Benchmark): -19.618848144724087, time: 6.0998 s\n",
      "mean energy std: 0.2823158582856436\n"
     ]
    }
   ],
   "source": [
    "import mpi4py.MPI as MPI\n",
    "import time\n",
    "COMM = MPI.COMM_WORLD\n",
    "RANK = COMM.Get_rank()\n",
    "\n",
    "# cache skeleton for reuse\n",
    "model_reuse.cache_bMPS_skeleton(test_fxs[0]) \n",
    "@torch.inference_mode()\n",
    "def evaluate_energy_reuse(fxs, v_model, H, current_amps, verbose=False, benchmark_model=None):\n",
    "    t0 = time.time()\n",
    "    # Label each connected config with which sample it comes from to enable reuse\n",
    "    B = fxs.shape[0]\n",
    "    # cache bMPS params for reuse\n",
    "    B_bMPS_params_x_dict, B_bMPS_params_y_dict = v_model.cache_bMPS_params_vmap(fxs)\n",
    "\n",
    "    def detect_changed_row_col_pair(fx1, fx2):\n",
    "        # currently only support nearest neighbor on square lattice\n",
    "        Ly = v_model.skeleton._Ly\n",
    "        changed_pos = torch.nonzero(fx1 - fx2)\n",
    "        changed_pos_2d = []\n",
    "        assert changed_pos.shape[0] <= 2, \"Expect at most 2 on-site config changes\"\n",
    "        for pos in changed_pos:\n",
    "            x, y = pos.item() // Ly, pos.item() % Ly\n",
    "            changed_pos_2d.append( (x, y) )\n",
    "        if len(changed_pos_2d) == 2:\n",
    "            delta_row = abs(changed_pos_2d[0][0] - changed_pos_2d[1][0])\n",
    "            delta_col = abs(changed_pos_2d[0][1] - changed_pos_2d[1][1])\n",
    "            if delta_row <= delta_col:\n",
    "                x1 = min(changed_pos_2d, key=lambda t: t[0])[0]\n",
    "                row = True\n",
    "                col = False\n",
    "                return row, col, list(x for x in range(x1, x1+delta_row+1))\n",
    "            else:\n",
    "                y1 = min(changed_pos_2d, key=lambda t: t[1])[1]\n",
    "                row = False\n",
    "                col = True\n",
    "                return row, col, list(y for y in range(y1, y1+delta_col+1))\n",
    "        else:\n",
    "            row = col = False\n",
    "            return row, col, None\n",
    "             \n",
    "    # --------------------------------------------------------------------------\n",
    "    # 2. Batched Calculation with Reuse\n",
    "    # --------------------------------------------------------------------------\n",
    "    # get connected configurations, coefficients and indices\n",
    "    conn_eta_num = []\n",
    "    conn_etas = []\n",
    "    conn_eta_coeffs = []\n",
    "    conn_eta_indices = []\n",
    "\n",
    "    fx_ind = 0\n",
    "    for fx in fxs:\n",
    "        eta, coeffs = H.get_conn(fx)\n",
    "        for i_eta in range(len(eta)):\n",
    "            r, c, pos = detect_changed_row_col_pair(fx, eta[i_eta])\n",
    "            conn_eta_indices.append( (fx_ind, i_eta, r, c, pos) )\n",
    "\n",
    "        conn_eta_num.append(len(eta))\n",
    "        conn_etas.append(torch.tensor(eta))\n",
    "        conn_eta_coeffs.append(torch.tensor(coeffs))\n",
    "        fx_ind += 1\n",
    "\n",
    "    conn_etas = torch.cat(conn_etas, dim=0)\n",
    "    conn_eta_coeffs = torch.cat(conn_eta_coeffs, dim=0)\n",
    "\n",
    "    # group connected configs by changed row/col first\n",
    "    # within row/col group, further group by position\n",
    "\n",
    "    # select the indices where r==True and c==False\n",
    "    # TODO: modify this part, form the pytree with batched leaves to input to reusbale PEPS amplitude calculation [x]\n",
    "    tasks_map = {} # Key: (mode, indices_tuple), Value: lists of (global_idx, parent_idx)\n",
    "    \n",
    "    # 记录哪些是“对角项”（x' == x），这些不需要重算，直接复用当前振幅\n",
    "    diagonal_mask = torch.zeros(conn_etas.shape[0], dtype=torch.bool, device=fxs.device)\n",
    "    diagonal_parent_indices = []\n",
    "    \n",
    "    # 遍历所有连接构型，进行归类\n",
    "    # conn_eta_indices[k] = (parent_fx_ind, i_eta, r_bool, c_bool, pos_list)\n",
    "    for k, (parent_idx, _, is_row, is_col, indices) in enumerate(conn_eta_indices):\n",
    "        if indices is None:\n",
    "            # Config 没有变化 (Diagonal term, e.g. density-density interaction)\n",
    "            diagonal_mask[k] = True\n",
    "            diagonal_parent_indices.append(parent_idx)\n",
    "            continue\n",
    "            \n",
    "        mode = 'row' if is_row else 'col'\n",
    "        # 将 list 转为 tuple 以便作为 dict key\n",
    "        indices_tuple = tuple(sorted(indices)) \n",
    "        group_key = (mode, indices_tuple)\n",
    "        \n",
    "        if group_key not in tasks_map:\n",
    "            tasks_map[group_key] = {'global_idxs': [], 'parent_idxs': []}\n",
    "        \n",
    "        tasks_map[group_key]['global_idxs'].append(k)\n",
    "        tasks_map[group_key]['parent_idxs'].append(parent_idx)\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # 2. Batched Calculation with Reuse\n",
    "    # --------------------------------------------------------------------------\n",
    "    # 预分配结果容器\n",
    "    total_conns = conn_etas.shape[0]\n",
    "    conn_amps = torch.zeros(total_conns, dtype=current_amps.dtype, device=fxs.device)\n",
    "    \n",
    "    # A. 处理对角项 (Direct Copy)\n",
    "    if len(diagonal_parent_indices) > 0:\n",
    "        # 找出所有对角项在 conn_amps 中的位置\n",
    "        diag_locs = torch.nonzero(diagonal_mask).squeeze()\n",
    "        # 找出对应的 parent index\n",
    "        parents = torch.tensor(diagonal_parent_indices, device=fxs.device)\n",
    "        # 直接赋值: <x|psi>\n",
    "        conn_amps[diag_locs] = current_amps[parents]\n",
    "\n",
    "    # B. 处理非对角项 (Grouped Vmap Contraction)\n",
    "    # Fetch the corresponding Batched Environment Dictionary in the pytree\n",
    "    def slice_env_dict(env_dict, idxs):\n",
    "        \"\"\"\n",
    "        env_dict: {key: PyTree_of_Tensors}\n",
    "        idxs: indices to slice (tensor or list)\n",
    "        \n",
    "        我们需要对 env_dict 中的每一个 value (PyTree) 进行操作，\n",
    "        利用 qu.utils.tree_map 进入 PyTree 内部，对每个叶子 Tensor 进行切片。\n",
    "        \"\"\"\n",
    "        return {\n",
    "            k: qu.utils.tree_map(lambda x: x[idxs], v) \n",
    "            for k, v in env_dict.items()\n",
    "        }\n",
    "\n",
    "    for (mode, indices), data in tasks_map.items():\n",
    "        # 获取索引\n",
    "        global_idxs = data['global_idxs']  # 在 conn_etas 中的位置\n",
    "        parent_idxs = data['parent_idxs']  # 来源于哪个 fxs[i]\n",
    "        \n",
    "        # 构造当前 Group 的 Batch\n",
    "        # 1. 目标构型 x'\n",
    "        # 注意：conn_etas 是一个大 tensor，直接切片即可\n",
    "        target_configs = conn_etas[global_idxs] # (Batch_Group, N_sites)\n",
    "        \n",
    "        # 2. 对应的父辈索引 (用于取环境)\n",
    "        subset_parents = torch.tensor(parent_idxs, device=fxs.device)\n",
    "        \n",
    "        # 3. 切片环境参数\n",
    "        subset_env_x = slice_env_dict(B_bMPS_params_x_dict, subset_parents)\n",
    "        subset_env_y = slice_env_dict(B_bMPS_params_y_dict, subset_parents)\n",
    "        \n",
    "        # 4. 调用模型 (Reuse Forward)\n",
    "        # 这里利用了 v_model.forward 的接口\n",
    "        if mode == 'row':\n",
    "            amps_group = v_model(\n",
    "                target_configs,\n",
    "                bMPS_params_x_batched=subset_env_x,\n",
    "                bMPS_params_y_batched=subset_env_y,\n",
    "                selected_rows=indices,\n",
    "                selected_cols=None\n",
    "            )\n",
    "        else: # col\n",
    "            amps_group = v_model(\n",
    "                target_configs,\n",
    "                bMPS_params_x_batched=subset_env_x,\n",
    "                bMPS_params_y_batched=subset_env_y,\n",
    "                selected_rows=None,\n",
    "                selected_cols=indices\n",
    "            )\n",
    "            \n",
    "        # 5. 填回结果 Tensor\n",
    "        locs = torch.tensor(global_idxs, device=fxs.device)\n",
    "        conn_amps[locs] = amps_group\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # 3. Compute Local Energy\n",
    "    # --------------------------------------------------------------------------\n",
    "    # E_loc(x) = \\sum_{x'} H_{x,x'} * (psi(x') / psi(x))\n",
    "    \n",
    "    # 此时 conn_amps 已经填满，且顺序与 conn_etas 一致\n",
    "    # conn_eta_num[b] 告诉我们每个样本 b 有多少个连接构型\n",
    "    \n",
    "    local_energies = []\n",
    "    offset = 0\n",
    "    \n",
    "    # 为了避免显式 Python 循环 (虽然 B=1024 时循环也不慢)，可以使用 segment_coo 或者简单的 loop\n",
    "    # 简单 loop 实现：\n",
    "    for b in range(B):\n",
    "        n_conn = conn_eta_num[b]\n",
    "        \n",
    "        # 取出当前样本相关的所有连接构型的振幅\n",
    "        # shape: (n_conn,)\n",
    "        amps_slice = conn_amps[offset : offset + n_conn]\n",
    "        coeffs_slice = conn_eta_coeffs[offset : offset + n_conn]\n",
    "        \n",
    "        # Ratio: psi(x') / psi(x)\n",
    "        # current_amps[b] 是标量\n",
    "        ratio = amps_slice / current_amps[b]\n",
    "        \n",
    "        # H_loc = \\sum H_{xx'} * Ratio\n",
    "        e_loc = torch.sum(coeffs_slice * ratio)\n",
    "        \n",
    "        local_energies.append(e_loc)\n",
    "        offset += n_conn\n",
    "        \n",
    "    local_energies = torch.stack(local_energies)\n",
    "    \n",
    "    # Global Mean Energy\n",
    "    energy_mean = torch.mean(local_energies)\n",
    "\n",
    "    # if verbose and torch.distributed.is_initialized() and torch.distributed.get_rank() == 0:\n",
    "    #     print(f\"Reuse Stats: Processed {len(tasks_map)} groups + diagonal terms.\")\n",
    "\n",
    "    if benchmark_model is not None and verbose:\n",
    "        t1 = time.time()\n",
    "        print(f'Energy (Reuse)    : {energy_mean.item()}, time: {t1 - t0:.4f} s')\n",
    "        # below is logics without reuse implemented yet\n",
    "        ################################################################################\n",
    "        current_amps_benchmark = benchmark_model(fxs)\n",
    "        t0 = time.time()\n",
    "        # calculate amplitudes for connected configs, in the future consider TN reuse to speed up calculation, TN reuse is controlled by a param that is not batched over (control flow?)\n",
    "        conn_amps_benchmark = torch.cat([benchmark_model(conn_etas[i:i+B]) for i in range(0, conn_etas.shape[0], B)])\n",
    "\n",
    "        # Local energy \\sum_{s'} H_{s,s'} <s'|psi>/<s|psi>\n",
    "\n",
    "        local_energies = []\n",
    "        offset = 0\n",
    "        for b in range(B):\n",
    "            n_conn = conn_eta_num[b]\n",
    "            amps_ratio = conn_amps_benchmark[offset:offset+n_conn] / current_amps_benchmark[b]\n",
    "            energy_b = torch.sum(conn_eta_coeffs[offset:offset+n_conn] * amps_ratio)\n",
    "            local_energies.append(energy_b)\n",
    "            offset += n_conn\n",
    "        local_energies = torch.stack(local_energies, dim=0)\n",
    "        # Energy: (1/N) * \\sum_s <s|H|psi>/<s|psi> = (1/N) * \\sum_s \\sum_{s'} H_{s,s'} <s'|psi>/<s|psi>\n",
    "        energy = torch.mean(local_energies)\n",
    "        t1 = time.time()\n",
    "        print(f'Energy (Benchmark): {energy.item()}, time: {t1 - t0:.4f} s')\n",
    "        ################################################################################\n",
    "\n",
    "    return energy_mean, local_energies\n",
    "    \n",
    "\n",
    "energy_mean, local_energies = evaluate_energy_reuse(\n",
    "    test_fxs, model_reuse, H, current_amps, verbose=True, benchmark_model=model\n",
    ")\n",
    "print(f'mean energy std: {local_energies.std().item()/np.sqrt(reuse_B)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "c42dc043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling with reuse done. Time: 3.1913 s\n",
      "Sampling benchmark done. Time: 6.3457 s\n"
     ]
    }
   ],
   "source": [
    "import mpi4py.MPI as MPI\n",
    "import time\n",
    "import random\n",
    "from vmc_torch.experiment.vmap.vmap_utils import propose_exchange_or_hopping, sample_next\n",
    "COMM = MPI.COMM_WORLD\n",
    "RANK = COMM.Get_rank()\n",
    "\n",
    "@torch.inference_mode()\n",
    "def sample_next_reuse(fxs, v_model, graph, hopping_rate=0.25, verbose=False, seed=None, benchmark_model=None):\n",
    "    B = fxs.shape[0]\n",
    "    # cache bMPS params along x direction first for reuse\n",
    "    B_bMPS_params_x_dict, current_amps = v_model.cache_bMPS_params_any_direction_vmap(fxs, direction='x')\n",
    "    for row, edges in graph.row_edges.items():\n",
    "        for edge in edges:\n",
    "            i, j = edge\n",
    "            proposed_fxs, new_flags = [], []\n",
    "            fx_id = 0\n",
    "            for fx in fxs:\n",
    "                proposed_fx, new = propose_exchange_or_hopping(\n",
    "                    i,\n",
    "                    j,\n",
    "                    fx,\n",
    "                    hopping_rate=hopping_rate,\n",
    "                    seed=seed + fx_id if seed is not None else None,\n",
    "                )\n",
    "                proposed_fxs.append(proposed_fx)\n",
    "                new_flags.append(new)\n",
    "                fx_id += 1\n",
    "            proposed_fxs = torch.stack(proposed_fxs, dim=0)\n",
    "            if not any(new_flags):\n",
    "                if verbose:\n",
    "                    print(f\"No changes proposed in this edge. (x, {row}, edge: {edge})\")\n",
    "                continue\n",
    "            # compute amplitudes for all proposed configs (because must align batchsize with reused bMPS batchsize)\n",
    "            new_proposed_fxs = proposed_fxs\n",
    "            # reuse of bMPS from xmin & xmax w.r.t. row to compute amplitudes\n",
    "            new_proposed_amps = v_model(\n",
    "                new_proposed_fxs,\n",
    "                bMPS_params_x_batched=B_bMPS_params_x_dict,\n",
    "                bMPS_params_y_batched=None,\n",
    "                selected_rows=(row,),\n",
    "                selected_cols=None,\n",
    "            )\n",
    "            proposed_amps = new_proposed_amps\n",
    "            if benchmark_model is not None and verbose:\n",
    "                benchmark_amps = benchmark_model(new_proposed_fxs)\n",
    "                print(f\"Benchmark vs Reuse amplitudes check (x, {row}):\")\n",
    "                print(torch.allclose(benchmark_amps, new_proposed_amps, atol=1e-5))\n",
    "            # Metropolis-Hastings acceptance\n",
    "            ratio = proposed_amps**2 / current_amps**2\n",
    "            accept_probs = torch.minimum(ratio, torch.ones_like(ratio))\n",
    "            for k in range(B):\n",
    "                if random.random() < accept_probs[k].item():\n",
    "                    fxs[k] = proposed_fxs[k]\n",
    "                    current_amps[k] = proposed_amps[k]\n",
    "        \n",
    "        # update bMPS params to next row for reuse\n",
    "        if row == v_model.Lx - 1:\n",
    "            # reach the bottom row, no further bMPS to be updated\n",
    "            break\n",
    "        B_bMPS_params_x_dict = v_model.update_bMPS_params_to_row_vmap(\n",
    "            fxs,\n",
    "            row_id = row,\n",
    "            bMPS_params_x_batched=B_bMPS_params_x_dict,\n",
    "            from_which='xmin',\n",
    "        )\n",
    "\n",
    "    B_bMPS_params_y_dict, current_amps = v_model.cache_bMPS_params_any_direction_vmap(fxs, direction='y')\n",
    "    for col, edges in graph.col_edges.items():\n",
    "        for edge in edges:\n",
    "            i, j = edge\n",
    "            proposed_fxs, new_flags = [], []\n",
    "            fx_id = 0\n",
    "            for fx in fxs:\n",
    "                proposed_fx, new = propose_exchange_or_hopping(\n",
    "                    i,\n",
    "                    j,\n",
    "                    fx,\n",
    "                    hopping_rate=hopping_rate,\n",
    "                    seed=seed + fx_id if seed is not None else None,\n",
    "                )\n",
    "                proposed_fxs.append(proposed_fx)\n",
    "                new_flags.append(new)\n",
    "                fx_id += 1\n",
    "            proposed_fxs = torch.stack(proposed_fxs, dim=0)\n",
    "            if not any(new_flags):\n",
    "                if verbose:\n",
    "                    print(f\"No changes proposed in this edge. (y, {col}, edge: {edge})\")\n",
    "                continue\n",
    "            # compute amplitudes for all proposed configs (because must align batchsize with reused bMPS batchsize)\n",
    "            new_proposed_fxs = proposed_fxs\n",
    "            # reuse of bMPS from ymin & ymax w.r.t. col to compute amplitudes\n",
    "            new_proposed_amps = v_model(\n",
    "                new_proposed_fxs,\n",
    "                bMPS_params_x_batched=None,\n",
    "                bMPS_params_y_batched=B_bMPS_params_y_dict,\n",
    "                selected_rows=None,\n",
    "                selected_cols=(col,),\n",
    "            )\n",
    "            if benchmark_model is not None and verbose:\n",
    "                benchmark_amps = benchmark_model(new_proposed_fxs)\n",
    "                print(f\"Benchmark vs Reuse amplitudes check (y, {col}):\")\n",
    "                print(torch.allclose(benchmark_amps, new_proposed_amps, atol=1e-5))\n",
    "            proposed_amps = new_proposed_amps\n",
    "            # Metropolis-Hastings acceptance\n",
    "            ratio = proposed_amps**2 / current_amps**2\n",
    "            accept_probs = torch.minimum(ratio, torch.ones_like(ratio))\n",
    "            for k in range(B):\n",
    "                if random.random() < accept_probs[k].item():\n",
    "                    fxs[k] = proposed_fxs[k]\n",
    "                    current_amps[k] = proposed_amps[k]\n",
    "        \n",
    "        # update bMPS params to next col for reuse\n",
    "        if col == v_model.Ly - 1:\n",
    "            # reach the rightmost col, no further bMPS to be updated\n",
    "            break\n",
    "        B_bMPS_params_y_dict = v_model.update_bMPS_params_to_col_vmap(\n",
    "            fxs,\n",
    "            col_id = col,\n",
    "            bMPS_params_y_batched=B_bMPS_params_y_dict,\n",
    "            from_which='ymin',\n",
    "        )\n",
    "\n",
    "    return fxs, current_amps\n",
    "\n",
    "t0 = time.time()\n",
    "test_fxs, current_amps = sample_next_reuse(\n",
    "    test_fxs,\n",
    "    model_reuse,\n",
    "    H.graph,\n",
    "    hopping_rate=0.0,\n",
    "    verbose=False,\n",
    "    seed=42,\n",
    "    benchmark_model=model\n",
    ")\n",
    "t1 = time.time()\n",
    "print(f\"Sampling with reuse done. Time: {t1 - t0:.4f} s\")\n",
    "\n",
    "t0 = time.time()\n",
    "test_fxs, current_amps = sample_next(\n",
    "    test_fxs,\n",
    "    model,\n",
    "    H.graph,\n",
    "    hopping_rate=0.0,\n",
    "    verbose=False,\n",
    "    seed=42,\n",
    ")\n",
    "t1 = time.time()\n",
    "print(f\"Sampling benchmark done. Time: {t1 - t0:.4f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17f69ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_site_tag_id': 'I{},{}',\n",
       " '_x_tag_id': 'X{}',\n",
       " '_y_tag_id': 'Y{}',\n",
       " '_Lx': 6,\n",
       " '_Ly': 6,\n",
       " '_site_ind_id': 'k{},{}'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_EXTRA_PROPS = ('_site_tag_id', '_x_tag_id', '_y_tag_id', '_Lx', '_Ly', '_site_ind_id')\n",
    "# get the extra properties of the tensor network\n",
    "qtn_extra_props = {prop: getattr(peps, prop) for prop in _EXTRA_PROPS}\n",
    "qtn_extra_props"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean_symmray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
