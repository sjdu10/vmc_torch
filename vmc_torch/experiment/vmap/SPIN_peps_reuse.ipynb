{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "110949be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1167.8648,  -290.4566,  -898.9068,  ...,  1102.4895,   491.9807,\n",
       "         2942.9152], dtype=torch.float64, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vmap_utils import PEPS_Model\n",
    "import quimb.tensor as qtn\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "Lx = 4\n",
    "Ly = 2\n",
    "D = 4\n",
    "chi = 4*D\n",
    "seed = 42\n",
    "# pwd = '/home/sijingdu/TNVMC/VMC_code/vmc_torch/vmc_torch/experiment/vmap'\n",
    "# skeleton = pickle.load(open(pwd+f'/{Lx}x{Ly}/heis/D={D}/peps_skeleton.pkl', 'rb'))\n",
    "# params = pickle.load(open(pwd+f'/{Lx}x{Ly}/heis/D={D}/peps_su_params.pkl', 'rb'))\n",
    "# peps = qtn.unpack(params, skeleton)\n",
    "peps = qtn.PEPS.rand(Lx, Ly, D, seed=seed)\n",
    "\n",
    "model = PEPS_Model(tn=peps, max_bond=chi)\n",
    "\n",
    "B = 1024\n",
    "random_binary_config = torch.randint(0, 2, (B, Lx*Ly)).int()\n",
    "\n",
    "model(random_binary_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cf1149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-0.5366333070821349)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from vmc_torch.hamiltonian_torch import spin_Heisenberg_square_lattice_torch\n",
    "\n",
    "H = spin_Heisenberg_square_lattice_torch(Lx, Ly, J=1.0, total_sz=0)\n",
    "\n",
    "np.linalg.eigvals(H.to_dense())[0]/(Lx*Ly)  # ground state energy per site check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "59829641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1167.8648,  -290.4566,  -898.9068,   462.7139,  -235.6403,  -131.4165,\n",
       "        -1050.1250,   -21.7044,   -74.7150,   306.4095], dtype=torch.float64,\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import quimb as qu\n",
    "class PEPS_Model_reuse(nn.Module):\n",
    "    def __init__(self, tn, max_bond, dtype=torch.float64):\n",
    "        import quimb as qu\n",
    "        import quimb.tensor as qtn\n",
    "        super().__init__()\n",
    "        \n",
    "        params, skeleton = qtn.pack(tn)\n",
    "        self.dtype = dtype\n",
    "        self.skeleton = skeleton\n",
    "        self.bMPS_x_skeletons = {}\n",
    "        self.bMPS_y_skeletons = {}\n",
    "        self.bMPS_params_x_in_dims = None\n",
    "        self.bMPS_params_y_in_dims = None\n",
    "        self.chi = max_bond\n",
    "\n",
    "        # for torch, further flatten pytree into a single list\n",
    "        params_flat, params_pytree = qu.utils.tree_flatten(\n",
    "            params, get_ref=True\n",
    "        )\n",
    "        self.params_pytree = params_pytree\n",
    "\n",
    "        # register the flat list parameters\n",
    "        self.params = torch.nn.ParameterList([\n",
    "            torch.as_tensor(x, dtype=self.dtype) for x in params_flat\n",
    "        ])\n",
    "    \n",
    "    def cache_bMPS_skeleton(self, x):\n",
    "        params = qu.utils.tree_unflatten(self.params, self.params_pytree)\n",
    "        tn = qtn.unpack(params, self.skeleton)\n",
    "        amp = tn.isel({tn.site_ind(site): x[i] for i, site in enumerate(tn.sites)})\n",
    "        env_x = amp.compute_x_environments(max_bond=self.chi, cutoff=0.0)\n",
    "        bMPS_params_dict = {}\n",
    "        for key, tn in env_x.items():\n",
    "            bMPS_params, skeleton = qtn.pack(tn)\n",
    "            env_x[key] = skeleton\n",
    "            bMPS_params_dict[key] = bMPS_params\n",
    "\n",
    "        self.bMPS_x_skeletons = env_x\n",
    "        bMPS_params_x_in_dims = qu.utils.tree_map(lambda _: 0, bMPS_params_dict)\n",
    "        self.bMPS_params_x_in_dims = bMPS_params_x_in_dims\n",
    "\n",
    "        env_y = amp.compute_y_environments(max_bond=self.chi, cutoff=0.0)\n",
    "        bMPS_params_dict = {}\n",
    "        for key, tn in env_y.items():\n",
    "            bMPS_params, skeleton = qtn.pack(tn)\n",
    "            env_y[key] = skeleton\n",
    "            bMPS_params_dict[key] = bMPS_params\n",
    "        self.bMPS_y_skeletons = env_y\n",
    "        bMPS_params_y_in_dims = qu.utils.tree_map(lambda _: 0, bMPS_params_dict)\n",
    "        self.bMPS_params_y_in_dims = bMPS_params_y_in_dims\n",
    "\n",
    "    \n",
    "    def cache_bMPS_params_vmap(self, x):\n",
    "        params = qu.utils.tree_unflatten(self.params, self.params_pytree)\n",
    "        def cache_bMPS_params_single(x_single, params):\n",
    "            tn = qtn.unpack(params, self.skeleton)\n",
    "            amp = tn.isel({tn.site_ind(site): x_single[i] for i, site in enumerate(tn.sites)})\n",
    "            env_x = amp.compute_x_environments(max_bond=self.chi, cutoff=0.0)\n",
    "            bMPS_params_x_dict = {}\n",
    "            for key, btn in env_x.items():\n",
    "                bMPS_params = btn.get_params()\n",
    "                bMPS_params_x_dict[key] = bMPS_params\n",
    "            bMPS_params_y_dict = {}\n",
    "            env_y = amp.compute_y_environments(max_bond=self.chi, cutoff=0.0)\n",
    "            for key, btn in env_y.items():\n",
    "                bMPS_params = btn.get_params()\n",
    "                bMPS_params_y_dict[key] = bMPS_params\n",
    "            return bMPS_params_x_dict, bMPS_params_y_dict\n",
    "        return torch.vmap(\n",
    "            cache_bMPS_params_single,\n",
    "            in_dims=(0, None),\n",
    "        )(x, params)\n",
    "    \n",
    "    def amp_tn(self, x):\n",
    "        params = qu.utils.tree_unflatten(self.params, self.params_pytree)\n",
    "        tn = qtn.unpack(params, self.skeleton)\n",
    "        # might need to specify the right site ordering here\n",
    "        amp = tn.isel({tn.site_ind(site): x[i] for i, site in enumerate(tn.sites)})\n",
    "        return amp\n",
    "    \n",
    "    def amplitude(\n",
    "        self,\n",
    "        x,\n",
    "        params,\n",
    "        bMPS_key=None,\n",
    "        bMPS_params_xmin=None,\n",
    "        bMPS_params_xmax=None,\n",
    "        bMPS_params_ymin=None,\n",
    "        bMPS_params_ymax=None,\n",
    "        selected_rows=None,\n",
    "        selected_cols=None,\n",
    "    ):\n",
    "        tn = qtn.unpack(params, self.skeleton)\n",
    "        # might need to specify the right site ordering here\n",
    "        amp = tn.isel({tn.site_ind(site): x[i] for i, site in enumerate(tn.sites)})\n",
    "\n",
    "        # replace the x-environment with the cached one\n",
    "        if bMPS_params_xmin is not None and bMPS_params_xmax is not None and bMPS_key is not None:\n",
    "            bMPS_min = qtn.unpack(bMPS_params_xmin, self.bMPS_x_skeletons[bMPS_key[0]])\n",
    "            bMPS_max = qtn.unpack(bMPS_params_xmax, self.bMPS_x_skeletons[bMPS_key[1]])\n",
    "            rows = amp.select([tn.row_tag(row) for row in selected_rows], which='any')\n",
    "            amp_reuse = (bMPS_min|rows|bMPS_max)\n",
    "            amp_reuse.view_as_(\n",
    "                qtn.PEPS,\n",
    "                site_tag_id = tn._site_tag_id,\n",
    "                x_tag_id = tn._x_tag_id,\n",
    "                y_tag_id = tn._y_tag_id,\n",
    "                Lx = tn._Lx,\n",
    "                Ly = tn._Ly,\n",
    "                site_ind_id = tn._site_ind_id,\n",
    "            )\n",
    "            if self.chi > 0:\n",
    "                amp_reuse.contract_boundary_from_ymin_(max_bond=self.chi, cutoff=0.0, yrange=[0, amp.Ly//2-1])\n",
    "                amp_reuse.contract_boundary_from_ymax_(max_bond=self.chi, cutoff=0.0, yrange=[amp.Ly//2, amp.Ly-1])\n",
    "            return amp_reuse.contract()\n",
    "        # replace the y-environment with the cached one\n",
    "        if bMPS_params_ymin is not None and bMPS_params_ymax is not None and bMPS_key is not None:\n",
    "            bMPS_min = qtn.unpack(bMPS_params_ymin, self.bMPS_y_skeletons[bMPS_key[0]])\n",
    "            bMPS_max = qtn.unpack(bMPS_params_ymax, self.bMPS_y_skeletons[bMPS_key[1]])\n",
    "            cols = amp.select([tn.col_tag(col) for col in selected_cols], which='any')\n",
    "            amp_reuse = (bMPS_min|cols|bMPS_max)\n",
    "            amp_reuse.view_as_(\n",
    "                qtn.PEPS,\n",
    "                site_tag_id = tn._site_tag_id,\n",
    "                x_tag_id = tn._x_tag_id,\n",
    "                y_tag_id = tn._y_tag_id,\n",
    "                Lx = tn._Lx,\n",
    "                Ly = tn._Ly,\n",
    "                site_ind_id = tn._site_ind_id,\n",
    "            )\n",
    "            if self.chi > 0:\n",
    "                amp_reuse.contract_boundary_from_xmin_(max_bond=self.chi, cutoff=0.0, xrange=[0, amp.Lx//2-1])\n",
    "                amp_reuse.contract_boundary_from_xmax_(max_bond=self.chi, cutoff=0.0, xrange=[amp.Lx//2, amp.Lx-1])\n",
    "            return amp_reuse.contract()\n",
    "\n",
    "        if self.chi > 0:\n",
    "            amp.contract_boundary_from_ymin_(max_bond=self.chi, cutoff=0.0, yrange=[0, amp.Ly//2-1])\n",
    "            amp.contract_boundary_from_ymax_(max_bond=self.chi, cutoff=0.0, yrange=[amp.Ly//2, amp.Ly-1])\n",
    "        return amp.contract()\n",
    "    \n",
    "    def vamp(\n",
    "        self,\n",
    "        x,\n",
    "        params,\n",
    "        bMPS_key=None,\n",
    "        bMPS_params_xmin=None,\n",
    "        bMPS_params_xmax=None,\n",
    "        bMPS_params_ymin=None,\n",
    "        bMPS_params_ymax=None,\n",
    "        selected_rows=None,\n",
    "        selected_cols=None,\n",
    "    ):\n",
    "        params = qu.utils.tree_unflatten(params, self.params_pytree)\n",
    "        if bMPS_params_xmin is not None and bMPS_params_xmax is not None:\n",
    "            return torch.vmap(\n",
    "                self.amplitude,\n",
    "                in_dims=(\n",
    "                    0,\n",
    "                    None,\n",
    "                    None,\n",
    "                    self.bMPS_params_x_in_dims[bMPS_key[0]],\n",
    "                    self.bMPS_params_x_in_dims[bMPS_key[1]],\n",
    "                    None,\n",
    "                    None,\n",
    "                    None,\n",
    "                    None,\n",
    "                ),\n",
    "            )(x, params, bMPS_key, bMPS_params_xmin, bMPS_params_xmax, bMPS_params_ymin, bMPS_params_ymax, selected_rows, selected_cols)\n",
    "        \n",
    "        if bMPS_params_ymin is not None and bMPS_params_ymax is not None:\n",
    "            return torch.vmap(\n",
    "                self.amplitude,\n",
    "                in_dims=(\n",
    "                    0,\n",
    "                    None,\n",
    "                    None,\n",
    "                    None,\n",
    "                    None,\n",
    "                    self.bMPS_params_y_in_dims[bMPS_key[0]],\n",
    "                    self.bMPS_params_y_in_dims[bMPS_key[1]],\n",
    "                    None,\n",
    "                    None,\n",
    "                ),\n",
    "            )(x, params, bMPS_key, bMPS_params_xmin, bMPS_params_xmax, bMPS_params_ymin, bMPS_params_ymax, selected_rows, selected_cols)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        bMPS_params_x_batched=None,\n",
    "        bMPS_params_y_batched=None,\n",
    "        selected_rows=None,\n",
    "        selected_cols=None,\n",
    "    ):\n",
    "        bMPS_params_xmin = None\n",
    "        bMPS_params_xmax = None\n",
    "        bMPS_params_ymin = None\n",
    "        bMPS_params_ymax = None\n",
    "\n",
    "        if selected_rows is not None:\n",
    "            bMPS_key = [('xmin', min(selected_rows)), ('xmax', max(selected_rows))]\n",
    "            bMPS_params_xmin = bMPS_params_x_batched[bMPS_key[0]]\n",
    "            bMPS_params_xmax = bMPS_params_x_batched[bMPS_key[1]]\n",
    "        if selected_cols is not None:\n",
    "            bMPS_key = [('ymin', min(selected_cols)), ('ymax', max(selected_cols))]\n",
    "            bMPS_params_ymin = bMPS_params_y_batched[bMPS_key[0]]\n",
    "            bMPS_params_ymax = bMPS_params_y_batched[bMPS_key[1]]\n",
    "        \n",
    "        return self.vamp(\n",
    "            x,\n",
    "            self.params,\n",
    "            bMPS_key=bMPS_key,\n",
    "            bMPS_params_xmin=bMPS_params_xmin,\n",
    "            bMPS_params_xmax=bMPS_params_xmax,\n",
    "            bMPS_params_ymin=bMPS_params_ymin,\n",
    "            bMPS_params_ymax=bMPS_params_ymax,\n",
    "            selected_rows=selected_rows,\n",
    "            selected_cols=selected_cols,\n",
    "        )\n",
    "\n",
    "model_reuse = PEPS_Model_reuse(tn=peps, max_bond=chi)\n",
    "model_reuse.cache_bMPS_skeleton(random_binary_config[0])\n",
    "reuse_B = 10\n",
    "amp_tns = [model_reuse.amp_tn(random_binary_config[i]) for i in range(reuse_B)]\n",
    "B_bMPS_params_x_dict, B_bMPS_params_y_dict = model_reuse.cache_bMPS_params_vmap(random_binary_config[:reuse_B])\n",
    "current_amps = model_reuse(random_binary_config[:reuse_B], bMPS_params_x_batched=B_bMPS_params_x_dict, bMPS_params_y_batched=B_bMPS_params_y_dict, selected_rows=(0,), selected_cols=None)\n",
    "current_amps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "57fe9442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(-1167.8648, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-290.4566, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-898.9068, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(462.7139, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-235.6403, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-131.4165, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-1050.1250, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-21.7044, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-74.7150, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(306.4095, dtype=torch.float64, grad_fn=<MulBackward0>)]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[amp_tns[i].contract() for i in range(reuse_B)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3727af14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0, True, False, [0])\n",
      "(0, 1, False, False, None)\n",
      "(0, 2, False, True, [1])\n",
      "(0, 3, False, True, [1])\n",
      "(0, 4, True, False, [2])\n",
      "(0, 5, False, True, [1])\n",
      "(1, 0, True, False, [0])\n",
      "(1, 1, False, False, None)\n",
      "(1, 2, False, True, [0])\n",
      "(1, 3, False, True, [1])\n",
      "(1, 4, True, False, [1])\n",
      "(1, 5, False, True, [0])\n",
      "(1, 6, False, True, [1])\n",
      "(1, 7, True, False, [2])\n",
      "(1, 8, False, True, [0])\n",
      "(1, 9, False, True, [1])\n",
      "(1, 10, True, False, [3])\n",
      "(2, 0, False, False, None)\n",
      "(2, 1, False, True, [0])\n",
      "(2, 2, True, False, [1])\n",
      "(2, 3, False, True, [0])\n",
      "(2, 4, False, True, [0])\n",
      "(2, 5, False, True, [1])\n",
      "(3, 0, True, False, [0])\n",
      "(3, 1, False, False, None)\n",
      "(3, 2, False, True, [1])\n",
      "(3, 3, False, True, [0])\n",
      "(3, 4, True, False, [2])\n",
      "(3, 5, False, True, [1])\n",
      "(4, 0, True, False, [0])\n",
      "(4, 1, False, False, None)\n",
      "(4, 2, False, True, [0])\n",
      "(4, 3, False, True, [1])\n",
      "(4, 4, True, False, [1])\n",
      "(4, 5, False, True, [0])\n",
      "(4, 6, False, True, [0])\n",
      "(4, 7, True, False, [3])\n",
      "(5, 0, False, False, None)\n",
      "(5, 1, False, True, [1])\n",
      "(5, 2, True, False, [1])\n",
      "(5, 3, False, True, [0])\n",
      "(5, 4, False, True, [1])\n",
      "(5, 5, True, False, [2])\n",
      "(5, 6, False, True, [0])\n",
      "(6, 0, False, False, None)\n",
      "(6, 1, False, True, [1])\n",
      "(6, 2, True, False, [1])\n",
      "(6, 3, False, True, [0])\n",
      "(6, 4, False, True, [0])\n",
      "(6, 5, True, False, [3])\n",
      "(7, 0, False, False, None)\n",
      "(7, 1, False, True, [0])\n",
      "(7, 2, True, False, [1])\n",
      "(7, 3, False, True, [1])\n",
      "(7, 4, False, True, [1])\n",
      "(7, 5, True, False, [3])\n",
      "(8, 0, False, False, None)\n",
      "(8, 1, False, True, [1])\n",
      "(8, 2, True, False, [2])\n",
      "(8, 3, False, True, [0])\n",
      "(8, 4, False, True, [1])\n",
      "(8, 5, True, False, [3])\n",
      "(9, 0, False, False, None)\n",
      "(9, 1, False, True, [1])\n",
      "(9, 2, True, False, [1])\n",
      "(9, 3, False, True, [0])\n",
      "(9, 4, False, True, [1])\n",
      "(9, 5, True, False, [2])\n",
      "(9, 6, False, True, [1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17041/2047412198.py:20: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  changed_pos = torch.nonzero(fx1 - fx2)\n"
     ]
    }
   ],
   "source": [
    "import mpi4py.MPI as MPI\n",
    "COMM = MPI.COMM_WORLD\n",
    "RANK = COMM.Get_rank()\n",
    "\n",
    "@torch.inference_mode()\n",
    "def evaluate_energy_reuse(fxs, v_model, H, current_amps, verbose=False):\n",
    "    # Label each connected config with which sample it comes from to enable reuse\n",
    "\n",
    "    B = fxs.shape[0]\n",
    "    \n",
    "\n",
    "    # cache skeleton for reuse\n",
    "    v_model.cache_bMPS_skeleton(fxs[0]) \n",
    "    # cache bMPS params for reuse\n",
    "    B_bMPS_params_x_dict, B_bMPS_params_y_dict = v_model.cache_bMPS_params_vmap(fxs)\n",
    "\n",
    "    def detect_changed_row_col_pair(fx1, fx2):\n",
    "        # currently only support nearest neighbor on square lattice\n",
    "        Ly = v_model.skeleton._Ly\n",
    "        changed_pos = torch.nonzero(fx1 - fx2)\n",
    "        changed_pos_2d = []\n",
    "        assert changed_pos.shape[0] <= 2, \"Expect at most 2 on-site config changes\"\n",
    "        for pos in changed_pos:\n",
    "            x, y = pos.item() // Ly, pos.item() % Ly\n",
    "            changed_pos_2d.append( (x, y) )\n",
    "        if len(changed_pos_2d) == 2:\n",
    "            delta_row = abs(changed_pos_2d[0][0] - changed_pos_2d[1][0])\n",
    "            delta_col = abs(changed_pos_2d[0][1] - changed_pos_2d[1][1])\n",
    "            if delta_row <= delta_col:\n",
    "                x1 = min(changed_pos_2d, key=lambda t: t[0])[0]\n",
    "                row = True\n",
    "                col = False\n",
    "                return row, col, list(x for x in range(x1, x1+delta_row+1))\n",
    "            else:\n",
    "                y1 = min(changed_pos_2d, key=lambda t: t[1])[1]\n",
    "                row = False\n",
    "                col = True\n",
    "                return row, col, list(y for y in range(y1, y1+delta_col+1))\n",
    "        else:\n",
    "            row = col = False\n",
    "            return row, col, None\n",
    "             \n",
    "            \n",
    "    # get connected configurations, coefficients and indices\n",
    "    conn_eta_num = []\n",
    "    conn_etas = []\n",
    "    conn_eta_coeffs = []\n",
    "    conn_eta_indices = []\n",
    "\n",
    "    fx_ind = 0\n",
    "    for fx in fxs:\n",
    "        eta, coeffs = H.get_conn(fx)\n",
    "        for i_eta in range(len(eta)):\n",
    "            r, c, pos = detect_changed_row_col_pair(fx, eta[i_eta])\n",
    "            conn_eta_indices.append( (fx_ind, i_eta, r, c, pos) )\n",
    "\n",
    "        conn_eta_num.append(len(eta))\n",
    "        conn_etas.append(torch.tensor(eta))\n",
    "        conn_eta_coeffs.append(torch.tensor(coeffs))\n",
    "        fx_ind += 1\n",
    "\n",
    "    conn_etas = torch.cat(conn_etas, dim=0)\n",
    "    conn_eta_coeffs = torch.cat(conn_eta_coeffs, dim=0)\n",
    "\n",
    "    # group connected configs by changed row/col first\n",
    "    # within row/col group, further group by position\n",
    "\n",
    "    # select the indices where r==True and c==False\n",
    "    # TODO: complete this part, form the pytree with batched leaves to input to reusbale PEPS amplitude calculation\n",
    "    qu.utils.tree_map_list(lambda x: print(x), conn_eta_indices, is_leaf=lambda x: isinstance(x, tuple))\n",
    "    # print(conn_eta_num)\n",
    "\n",
    "    # if verbose:\n",
    "    #     if RANK == 1:\n",
    "    #         print(f'Prepared batched conn_etas and coeffs: {conn_etas.shape}, {conn_eta_coeffs.shape} (batch size {B})')\n",
    "\n",
    "    # # calculate amplitudes for connected configs, in the future consider TN reuse to speed up calculation, TN reuse is controlled by a param that is not batched over (control flow?)\n",
    "    # conn_amps = torch.cat([v_model(conn_etas[i:i+B]) for i in range(0, conn_etas.shape[0], B)])\n",
    "\n",
    "    # # Local energy \\sum_{s'} H_{s,s'} <s'|psi>/<s|psi>\n",
    "\n",
    "    # local_energies = []\n",
    "    # offset = 0\n",
    "    # for b in range(B):\n",
    "    #     n_conn = conn_eta_num[b]\n",
    "    #     amps_ratio = conn_amps[offset:offset+n_conn] / current_amps[b]\n",
    "    #     energy_b = torch.sum(conn_eta_coeffs[offset:offset+n_conn] * amps_ratio)\n",
    "    #     local_energies.append(energy_b)\n",
    "    #     offset += n_conn\n",
    "    # local_energies = torch.stack(local_energies, dim=0)\n",
    "    # if verbose:\n",
    "    #     if RANK == 1:\n",
    "    #         print(f'Batched local energies: {local_energies.shape}')\n",
    "\n",
    "    # # Energy: (1/N) * \\sum_s <s|H|psi>/<s|psi> = (1/N) * \\sum_s \\sum_{s'} H_{s,s'} <s'|psi>/<s|psi>\n",
    "    # energy = torch.mean(local_energies)\n",
    "    # if verbose:\n",
    "    #     if RANK == 1:\n",
    "    #         print(f'Energy: {energy.item()}')\n",
    "\n",
    "    # return energy, local_energies\n",
    "\n",
    "evaluate_energy_reuse(random_binary_config[:reuse_B], model_reuse, H, current_amps, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "17f69ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_site_tag_id': 'I{},{}',\n",
       " '_x_tag_id': 'X{}',\n",
       " '_y_tag_id': 'Y{}',\n",
       " '_Lx': 4,\n",
       " '_Ly': 2,\n",
       " '_site_ind_id': 'k{},{}'}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_EXTRA_PROPS = ('_site_tag_id', '_x_tag_id', '_y_tag_id', '_Lx', '_Ly', '_site_ind_id')\n",
    "# get the extra properties of the tensor network\n",
    "qtn_extra_props = {prop: getattr(peps, prop) for prop in _EXTRA_PROPS}\n",
    "qtn_extra_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "deea6419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('xmax', 3): TensorNetwork(tensors=0, indices=0),\n",
       " ('xmax', 2): PEPS(tensors=2, indices=3, Lx=4, Ly=2, max_bond=4),\n",
       " ('xmax', 1): PEPS(tensors=2, indices=3, Lx=4, Ly=2, max_bond=4),\n",
       " ('xmax', 0): PEPS(tensors=2, indices=3, Lx=4, Ly=2, max_bond=4),\n",
       " ('xmin', 0): TensorNetwork(tensors=0, indices=0),\n",
       " ('xmin', 1): PEPS(tensors=2, indices=3, Lx=4, Ly=2, max_bond=4),\n",
       " ('xmin', 2): PEPS(tensors=2, indices=3, Lx=4, Ly=2, max_bond=4),\n",
       " ('xmin', 3): PEPS(tensors=2, indices=3, Lx=4, Ly=2, max_bond=4)}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_reuse.bMPS_skeletons"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean_symmray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
