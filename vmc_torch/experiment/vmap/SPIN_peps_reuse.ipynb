{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "110949be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-5.2270e-07, -2.3488e-07,  7.5670e-07, -2.8627e-06,  1.1997e-09,\n",
       "        -1.4775e-07, -5.4349e-10,  1.0196e-07,  5.2956e-08, -2.1654e-11,\n",
       "         2.9276e-09,  1.1316e-08, -7.2889e-08, -4.4269e-09, -1.1928e-07,\n",
       "         2.6389e-05,  8.5087e-06,  1.2870e-06,  3.8876e-07,  1.3132e-07,\n",
       "        -2.1634e-06, -2.2202e-07,  6.1483e-07,  5.9468e-06, -2.0304e-09,\n",
       "        -6.3694e-08, -5.6379e-07, -3.9348e-07,  2.2326e-05, -2.8754e-09,\n",
       "         1.3719e-06, -1.7981e-07,  8.2702e-09, -2.2169e-08, -8.2397e-12,\n",
       "         1.4675e-05,  1.3273e-07,  7.2418e-07, -6.3289e-09,  2.5211e-07,\n",
       "        -5.8691e-08,  1.2220e-06, -3.5667e-11,  2.2029e-08, -5.6043e-06,\n",
       "        -2.2771e-06, -9.8052e-09, -2.3988e-06,  1.3588e-06, -4.6616e-07,\n",
       "        -2.9891e-09,  1.3293e-06,  4.1962e-07,  7.0591e-08, -3.6060e-05,\n",
       "        -4.5269e-07, -1.9019e-09,  7.1047e-10,  2.1764e-08, -7.0980e-08,\n",
       "         5.1081e-11, -5.0716e-07, -6.8659e-06,  3.4188e-07],\n",
       "       dtype=torch.float64, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vmc_torch.experiment.vmap.vmap_models import PEPS_Model\n",
    "import quimb.tensor as qtn\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "Lx = 6\n",
    "Ly = 6\n",
    "D = 4\n",
    "chi = 4*D\n",
    "seed = 42\n",
    "pwd = '/home/sijingdu/TNVMC/VMC_code/vmc_torch/vmc_torch/experiment/vmap'\n",
    "skeleton = pickle.load(open(pwd+f'/{Lx}x{Ly}/heis/D={D}/peps_skeleton.pkl', 'rb'))\n",
    "params = pickle.load(open(pwd+f'/{Lx}x{Ly}/heis/D={D}/peps_su_params.pkl', 'rb'))\n",
    "peps = qtn.unpack(params, skeleton)\n",
    "# peps = qtn.PEPS.rand(Lx, Ly, D, seed=seed)\n",
    "\n",
    "model = PEPS_Model(tn=peps, max_bond=chi)\n",
    "\n",
    "B = 64\n",
    "random_binary_config = torch.randint(0, 2, (B, Lx*Ly)).int()\n",
    "model(random_binary_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "71cf1149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vmc_torch.hamiltonian_torch import spin_Heisenberg_square_lattice_torch\n",
    "\n",
    "H = spin_Heisenberg_square_lattice_torch(Lx, Ly, J=1.0, total_sz=0)\n",
    "# all_states = torch.tensor(H.hilbert.all_states())\n",
    "# psi_vec = model(all_states).detach().cpu().numpy()\n",
    "# H_dense = H.to_dense()\n",
    "# E_expect = np.vdot(psi_vec, H_dense @ psi_vec) / np.vdot(psi_vec, psi_vec)\n",
    "# print(\"Energy per site:\", E_expect)\n",
    "# np.linalg.eigvals(H.to_dense())[0]/(Lx*Ly)  # ground state energy per site check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "59829641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-5.2270e-07, -2.3488e-07,  7.5670e-07, -2.8627e-06,  1.1996e-09,\n",
       "        -1.4775e-07, -5.4349e-10,  1.0196e-07,  5.2956e-08, -2.1655e-11,\n",
       "         2.9276e-09,  1.1316e-08, -7.2889e-08, -4.4269e-09, -1.1928e-07,\n",
       "         2.6389e-05,  8.5087e-06,  1.2870e-06,  3.8876e-07,  1.3132e-07,\n",
       "        -2.1634e-06, -2.2202e-07,  6.1483e-07,  5.9468e-06, -2.0304e-09,\n",
       "        -6.3694e-08, -5.6379e-07, -3.9348e-07,  2.2326e-05, -2.8754e-09,\n",
       "         1.3719e-06, -1.7981e-07,  8.2702e-09, -2.2169e-08, -8.2393e-12,\n",
       "         1.4675e-05,  1.3273e-07,  7.2418e-07, -6.3289e-09,  2.5211e-07,\n",
       "        -5.8690e-08,  1.2220e-06, -3.5668e-11,  2.2029e-08, -5.6043e-06,\n",
       "        -2.2771e-06, -9.8051e-09, -2.3988e-06,  1.3588e-06, -4.6616e-07,\n",
       "        -2.9891e-09,  1.3293e-06,  4.1962e-07,  7.0591e-08, -3.6060e-05,\n",
       "        -4.5269e-07, -1.9019e-09,  7.1046e-10,  2.1764e-08, -7.0980e-08,\n",
       "         5.1081e-11, -5.0716e-07, -6.8659e-06,  3.4188e-07],\n",
       "       dtype=torch.float64, grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import quimb as qu\n",
    "class PEPS_Model_reuse(nn.Module):\n",
    "    def __init__(self, tn, max_bond, dtype=torch.float64):\n",
    "        import quimb as qu\n",
    "        import quimb.tensor as qtn\n",
    "        super().__init__()\n",
    "        \n",
    "        params, skeleton = qtn.pack(tn)\n",
    "        self.dtype = dtype\n",
    "        self.skeleton = skeleton\n",
    "        self.bMPS_x_skeletons = {}\n",
    "        self.bMPS_y_skeletons = {}\n",
    "        self.bMPS_params_x_in_dims = None\n",
    "        self.bMPS_params_y_in_dims = None\n",
    "        self.chi = max_bond\n",
    "\n",
    "        # for torch, further flatten pytree into a single list\n",
    "        params_flat, params_pytree = qu.utils.tree_flatten(\n",
    "            params, get_ref=True\n",
    "        )\n",
    "        self.params_pytree = params_pytree\n",
    "\n",
    "        # register the flat list parameters\n",
    "        self.params = torch.nn.ParameterList([\n",
    "            torch.as_tensor(x, dtype=self.dtype) for x in params_flat\n",
    "        ])\n",
    "    \n",
    "    def cache_bMPS_skeleton(self, x):\n",
    "        params = qu.utils.tree_unflatten(self.params, self.params_pytree)\n",
    "        tn = qtn.unpack(params, self.skeleton)\n",
    "        amp = tn.isel({tn.site_ind(site): x[i] for i, site in enumerate(tn.sites)})\n",
    "        env_x = amp.compute_x_environments(max_bond=self.chi, cutoff=0.0)\n",
    "        bMPS_params_dict = {}\n",
    "        for key, tn in env_x.items():\n",
    "            bMPS_params, skeleton = qtn.pack(tn)\n",
    "            env_x[key] = skeleton\n",
    "            bMPS_params_dict[key] = bMPS_params\n",
    "\n",
    "        self.bMPS_x_skeletons = env_x\n",
    "        bMPS_params_x_in_dims = qu.utils.tree_map(lambda _: 0, bMPS_params_dict)\n",
    "        self.bMPS_params_x_in_dims = bMPS_params_x_in_dims\n",
    "\n",
    "        env_y = amp.compute_y_environments(max_bond=self.chi, cutoff=0.0)\n",
    "        bMPS_params_dict = {}\n",
    "        for key, tn in env_y.items():\n",
    "            bMPS_params, skeleton = qtn.pack(tn)\n",
    "            env_y[key] = skeleton\n",
    "            bMPS_params_dict[key] = bMPS_params\n",
    "        self.bMPS_y_skeletons = env_y\n",
    "        bMPS_params_y_in_dims = qu.utils.tree_map(lambda _: 0, bMPS_params_dict)\n",
    "        self.bMPS_params_y_in_dims = bMPS_params_y_in_dims\n",
    "\n",
    "    \n",
    "    def cache_bMPS_params_vmap(self, x):\n",
    "        # return a pytree (dict) of bMPS params for x and y environments\n",
    "        params = qu.utils.tree_unflatten(self.params, self.params_pytree)\n",
    "        def cache_bMPS_params_single(x_single, params):\n",
    "            tn = qtn.unpack(params, self.skeleton)\n",
    "            amp = tn.isel({tn.site_ind(site): x_single[i] for i, site in enumerate(tn.sites)})\n",
    "            env_x = amp.compute_x_environments(max_bond=self.chi, cutoff=0.0)\n",
    "            bMPS_params_x_dict = {}\n",
    "            for key, btn in env_x.items():\n",
    "                bMPS_params = btn.get_params()\n",
    "                bMPS_params_x_dict[key] = bMPS_params\n",
    "            bMPS_params_y_dict = {}\n",
    "            env_y = amp.compute_y_environments(max_bond=self.chi, cutoff=0.0)\n",
    "            for key, btn in env_y.items():\n",
    "                bMPS_params = btn.get_params()\n",
    "                bMPS_params_y_dict[key] = bMPS_params\n",
    "            return bMPS_params_x_dict, bMPS_params_y_dict\n",
    "        return torch.vmap(\n",
    "            cache_bMPS_params_single,\n",
    "            in_dims=(0, None),\n",
    "        )(x, params)\n",
    "    \n",
    "    def amp_tn(self, x):\n",
    "        params = qu.utils.tree_unflatten(self.params, self.params_pytree)\n",
    "        tn = qtn.unpack(params, self.skeleton)\n",
    "        # might need to specify the right site ordering here\n",
    "        amp = tn.isel({tn.site_ind(site): x[i] for i, site in enumerate(tn.sites)})\n",
    "        return amp\n",
    "    \n",
    "    def amplitude(\n",
    "        self,\n",
    "        x,\n",
    "        params,\n",
    "        bMPS_key=None,\n",
    "        bMPS_params_xmin=None,\n",
    "        bMPS_params_xmax=None,\n",
    "        bMPS_params_ymin=None,\n",
    "        bMPS_params_ymax=None,\n",
    "        selected_rows=None,\n",
    "        selected_cols=None,\n",
    "    ):\n",
    "        tn = qtn.unpack(params, self.skeleton)\n",
    "        # might need to specify the right site ordering here\n",
    "        amp = tn.isel({tn.site_ind(site): x[i] for i, site in enumerate(tn.sites)})\n",
    "\n",
    "        # replace the x-environment with the cached one\n",
    "        if bMPS_params_xmin is not None and bMPS_params_xmax is not None and bMPS_key is not None:\n",
    "            bMPS_min = qtn.unpack(bMPS_params_xmin, self.bMPS_x_skeletons[bMPS_key[0]])\n",
    "            bMPS_max = qtn.unpack(bMPS_params_xmax, self.bMPS_x_skeletons[bMPS_key[1]])\n",
    "            rows = amp.select([tn.row_tag(row) for row in selected_rows], which='any')\n",
    "            amp_reuse = (bMPS_min|rows|bMPS_max)\n",
    "            amp_reuse.view_as_(\n",
    "                qtn.PEPS,\n",
    "                site_tag_id = tn._site_tag_id,\n",
    "                x_tag_id = tn._x_tag_id,\n",
    "                y_tag_id = tn._y_tag_id,\n",
    "                Lx = tn._Lx,\n",
    "                Ly = tn._Ly,\n",
    "                site_ind_id = tn._site_ind_id,\n",
    "            )\n",
    "            if self.chi > 0:\n",
    "                amp_reuse.contract_boundary_from_xmin_(max_bond=self.chi, cutoff=0.0, xrange=[bMPS_key[0][1], bMPS_key[1][1]+1])\n",
    "            return amp_reuse.contract()\n",
    "        # replace the y-environment with the cached one\n",
    "        if bMPS_params_ymin is not None and bMPS_params_ymax is not None and bMPS_key is not None:\n",
    "            bMPS_min = qtn.unpack(bMPS_params_ymin, self.bMPS_y_skeletons[bMPS_key[0]])\n",
    "            bMPS_max = qtn.unpack(bMPS_params_ymax, self.bMPS_y_skeletons[bMPS_key[1]])\n",
    "            cols = amp.select([tn.col_tag(col) for col in selected_cols], which='any')\n",
    "            amp_reuse = (bMPS_min|cols|bMPS_max)\n",
    "            amp_reuse.view_as_(\n",
    "                qtn.PEPS,\n",
    "                site_tag_id = tn._site_tag_id,\n",
    "                x_tag_id = tn._x_tag_id,\n",
    "                y_tag_id = tn._y_tag_id,\n",
    "                Lx = tn._Lx,\n",
    "                Ly = tn._Ly,\n",
    "                site_ind_id = tn._site_ind_id,\n",
    "            )\n",
    "            if self.chi > 0:\n",
    "                amp_reuse.contract_boundary_from_ymin_(max_bond=self.chi, cutoff=0.0, yrange=[bMPS_key[0][1], bMPS_key[1][1]+1])\n",
    "            return amp_reuse.contract()\n",
    "\n",
    "        if self.chi > 0:\n",
    "            amp.contract_boundary_from_ymin_(max_bond=self.chi, cutoff=0.0, yrange=[0, amp.Ly//2-1])\n",
    "            amp.contract_boundary_from_ymax_(max_bond=self.chi, cutoff=0.0, yrange=[amp.Ly//2, amp.Ly-1])\n",
    "        return amp.contract()\n",
    "    \n",
    "    def vamp(\n",
    "        self,\n",
    "        x,\n",
    "        params,\n",
    "        bMPS_key=None,\n",
    "        bMPS_params_xmin=None,\n",
    "        bMPS_params_xmax=None,\n",
    "        bMPS_params_ymin=None,\n",
    "        bMPS_params_ymax=None,\n",
    "        selected_rows=None,\n",
    "        selected_cols=None,\n",
    "    ):\n",
    "        params = qu.utils.tree_unflatten(params, self.params_pytree)\n",
    "        if bMPS_params_xmin is not None and bMPS_params_xmax is not None:\n",
    "            return torch.vmap(\n",
    "                self.amplitude,\n",
    "                in_dims=(\n",
    "                    0,\n",
    "                    None,\n",
    "                    None,\n",
    "                    self.bMPS_params_x_in_dims[bMPS_key[0]],\n",
    "                    self.bMPS_params_x_in_dims[bMPS_key[1]],\n",
    "                    None,\n",
    "                    None,\n",
    "                    None,\n",
    "                    None,\n",
    "                ),\n",
    "            )(x, params, bMPS_key, bMPS_params_xmin, bMPS_params_xmax, bMPS_params_ymin, bMPS_params_ymax, selected_rows, selected_cols)\n",
    "        \n",
    "        if bMPS_params_ymin is not None and bMPS_params_ymax is not None:\n",
    "            return torch.vmap(\n",
    "                self.amplitude,\n",
    "                in_dims=(\n",
    "                    0,\n",
    "                    None,\n",
    "                    None,\n",
    "                    None,\n",
    "                    None,\n",
    "                    self.bMPS_params_y_in_dims[bMPS_key[0]],\n",
    "                    self.bMPS_params_y_in_dims[bMPS_key[1]],\n",
    "                    None,\n",
    "                    None,\n",
    "                ),\n",
    "            )(x, params, bMPS_key, bMPS_params_xmin, bMPS_params_xmax, bMPS_params_ymin, bMPS_params_ymax, selected_rows, selected_cols)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        bMPS_params_x_batched=None,\n",
    "        bMPS_params_y_batched=None,\n",
    "        selected_rows=None,\n",
    "        selected_cols=None,\n",
    "    ):\n",
    "        bMPS_params_xmin = None\n",
    "        bMPS_params_xmax = None\n",
    "        bMPS_params_ymin = None\n",
    "        bMPS_params_ymax = None\n",
    "\n",
    "        if selected_rows is not None:\n",
    "            bMPS_key = [('xmin', min(selected_rows)), ('xmax', max(selected_rows))]\n",
    "            bMPS_params_xmin = bMPS_params_x_batched[bMPS_key[0]]\n",
    "            bMPS_params_xmax = bMPS_params_x_batched[bMPS_key[1]]\n",
    "        if selected_cols is not None:\n",
    "            bMPS_key = [('ymin', min(selected_cols)), ('ymax', max(selected_cols))]\n",
    "            bMPS_params_ymin = bMPS_params_y_batched[bMPS_key[0]]\n",
    "            bMPS_params_ymax = bMPS_params_y_batched[bMPS_key[1]]\n",
    "        \n",
    "        return self.vamp(\n",
    "            x,\n",
    "            self.params,\n",
    "            bMPS_key=bMPS_key,\n",
    "            bMPS_params_xmin=bMPS_params_xmin,\n",
    "            bMPS_params_xmax=bMPS_params_xmax,\n",
    "            bMPS_params_ymin=bMPS_params_ymin,\n",
    "            bMPS_params_ymax=bMPS_params_ymax,\n",
    "            selected_rows=selected_rows,\n",
    "            selected_cols=selected_cols,\n",
    "        )\n",
    "\n",
    "model_reuse = PEPS_Model_reuse(tn=peps, max_bond=chi)\n",
    "model_reuse.cache_bMPS_skeleton(random_binary_config[0])\n",
    "reuse_B = len(random_binary_config)\n",
    "amp_tns = [model_reuse.amp_tn(random_binary_config[i]) for i in range(reuse_B)]\n",
    "B_bMPS_params_x_dict, B_bMPS_params_y_dict = model_reuse.cache_bMPS_params_vmap(random_binary_config[:reuse_B])\n",
    "current_amps = model_reuse(random_binary_config[:reuse_B], bMPS_params_x_batched=B_bMPS_params_x_dict, bMPS_params_y_batched=B_bMPS_params_y_dict, selected_rows=(2,), selected_cols=None)\n",
    "current_amps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fe9442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(6.8545e-08, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(5.9077e-05, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(2.0995e-05, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(1.8227e-07, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(0.0003, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(2.4208e-05, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(6.0399e-08, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(0.0001, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-0.0002, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-2.1589e-07, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-3.6815e-06, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(2.5518e-06, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-1.2380e-05, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(2.0664e-06, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(2.9636e-06, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-0.0002, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(4.6009e-05, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(5.8018e-05, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(7.2033e-06, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(1.7766e-05, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(0.0005, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(0.0001, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(1.5803e-05, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(1.5558e-06, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-3.7971e-08, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(3.2689e-05, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-7.1469e-05, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(1.8659e-05, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(6.8763e-05, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-9.8607e-05, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(1.1701e-05, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-8.1883e-07, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-1.0110e-08, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-5.8009e-05, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(3.2804e-06, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(7.6966e-07, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-8.1438e-06, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-8.9914e-07, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-0.0001, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(0.0001, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(1.9825e-05, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(9.8721e-08, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-5.4036e-06, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-0.0004, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(1.7627e-08, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(4.5398e-05, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(2.3444e-05, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(1.7254e-05, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(0.0002, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(4.6028e-05, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(4.6644e-08, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(4.2271e-05, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-6.4802e-11, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(0.0001, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-8.1565e-07, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-0.0007, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(4.8053e-05, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-1.9282e-08, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(5.4913e-05, dtype=torch.float64, grad_fn=<MulBackward0>),\n",
       " tensor(-3.5458e-07, dtype=torch.float64, grad_fn=<MulBackward0>)]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [amp_tns[i].contract() for i in range(reuse_B)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3727af14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5633/3122922436.py:19: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  changed_pos = torch.nonzero(fx1 - fx2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy (Reuse)    : -18.40289441533151, time: 1.8377 s\n",
      "Energy (Benchmark): -18.402906635608915, time: 3.3315 s\n"
     ]
    }
   ],
   "source": [
    "import mpi4py.MPI as MPI\n",
    "import time\n",
    "COMM = MPI.COMM_WORLD\n",
    "RANK = COMM.Get_rank()\n",
    "\n",
    "@torch.inference_mode()\n",
    "def evaluate_energy_reuse(fxs, v_model, H, current_amps, verbose=False, benchmark_model=None):\n",
    "    t0 = time.time()\n",
    "    # Label each connected config with which sample it comes from to enable reuse\n",
    "    B = fxs.shape[0]\n",
    "    # cache skeleton for reuse\n",
    "    v_model.cache_bMPS_skeleton(fxs[0]) \n",
    "    # cache bMPS params for reuse\n",
    "    B_bMPS_params_x_dict, B_bMPS_params_y_dict = v_model.cache_bMPS_params_vmap(fxs)\n",
    "\n",
    "    def detect_changed_row_col_pair(fx1, fx2):\n",
    "        # currently only support nearest neighbor on square lattice\n",
    "        Ly = v_model.skeleton._Ly\n",
    "        changed_pos = torch.nonzero(fx1 - fx2)\n",
    "        changed_pos_2d = []\n",
    "        assert changed_pos.shape[0] <= 2, \"Expect at most 2 on-site config changes\"\n",
    "        for pos in changed_pos:\n",
    "            x, y = pos.item() // Ly, pos.item() % Ly\n",
    "            changed_pos_2d.append( (x, y) )\n",
    "        if len(changed_pos_2d) == 2:\n",
    "            delta_row = abs(changed_pos_2d[0][0] - changed_pos_2d[1][0])\n",
    "            delta_col = abs(changed_pos_2d[0][1] - changed_pos_2d[1][1])\n",
    "            if delta_row <= delta_col:\n",
    "                x1 = min(changed_pos_2d, key=lambda t: t[0])[0]\n",
    "                row = True\n",
    "                col = False\n",
    "                return row, col, list(x for x in range(x1, x1+delta_row+1))\n",
    "            else:\n",
    "                y1 = min(changed_pos_2d, key=lambda t: t[1])[1]\n",
    "                row = False\n",
    "                col = True\n",
    "                return row, col, list(y for y in range(y1, y1+delta_col+1))\n",
    "        else:\n",
    "            row = col = False\n",
    "            return row, col, None\n",
    "             \n",
    "    # --------------------------------------------------------------------------\n",
    "    # 2. Batched Calculation with Reuse\n",
    "    # --------------------------------------------------------------------------\n",
    "    # get connected configurations, coefficients and indices\n",
    "    conn_eta_num = []\n",
    "    conn_etas = []\n",
    "    conn_eta_coeffs = []\n",
    "    conn_eta_indices = []\n",
    "\n",
    "    fx_ind = 0\n",
    "    for fx in fxs:\n",
    "        eta, coeffs = H.get_conn(fx)\n",
    "        for i_eta in range(len(eta)):\n",
    "            r, c, pos = detect_changed_row_col_pair(fx, eta[i_eta])\n",
    "            conn_eta_indices.append( (fx_ind, i_eta, r, c, pos) )\n",
    "\n",
    "        conn_eta_num.append(len(eta))\n",
    "        conn_etas.append(torch.tensor(eta))\n",
    "        conn_eta_coeffs.append(torch.tensor(coeffs))\n",
    "        fx_ind += 1\n",
    "\n",
    "    conn_etas = torch.cat(conn_etas, dim=0)\n",
    "    conn_eta_coeffs = torch.cat(conn_eta_coeffs, dim=0)\n",
    "\n",
    "    # group connected configs by changed row/col first\n",
    "    # within row/col group, further group by position\n",
    "\n",
    "    # select the indices where r==True and c==False\n",
    "    # TODO: modify this part, form the pytree with batched leaves to input to reusbale PEPS amplitude calculation\n",
    "    tasks_map = {} # Key: (mode, indices_tuple), Value: lists of (global_idx, parent_idx)\n",
    "    \n",
    "    # 记录哪些是“对角项”（x' == x），这些不需要重算，直接复用当前振幅\n",
    "    diagonal_mask = torch.zeros(conn_etas.shape[0], dtype=torch.bool, device=fxs.device)\n",
    "    diagonal_parent_indices = []\n",
    "    \n",
    "    # 遍历所有连接构型，进行归类\n",
    "    # conn_eta_indices[k] = (parent_fx_ind, i_eta, r_bool, c_bool, pos_list)\n",
    "    for k, (parent_idx, _, is_row, is_col, indices) in enumerate(conn_eta_indices):\n",
    "        if indices is None:\n",
    "            # Config 没有变化 (Diagonal term, e.g. density-density interaction)\n",
    "            diagonal_mask[k] = True\n",
    "            diagonal_parent_indices.append(parent_idx)\n",
    "            continue\n",
    "            \n",
    "        mode = 'row' if is_row else 'col'\n",
    "        # 将 list 转为 tuple 以便作为 dict key\n",
    "        indices_tuple = tuple(sorted(indices)) \n",
    "        group_key = (mode, indices_tuple)\n",
    "        \n",
    "        if group_key not in tasks_map:\n",
    "            tasks_map[group_key] = {'global_idxs': [], 'parent_idxs': []}\n",
    "        \n",
    "        tasks_map[group_key]['global_idxs'].append(k)\n",
    "        tasks_map[group_key]['parent_idxs'].append(parent_idx)\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # 2. Batched Calculation with Reuse\n",
    "    # --------------------------------------------------------------------------\n",
    "    # 预分配结果容器\n",
    "    total_conns = conn_etas.shape[0]\n",
    "    conn_amps = torch.zeros(total_conns, dtype=current_amps.dtype, device=fxs.device)\n",
    "    \n",
    "    # A. 处理对角项 (Direct Copy)\n",
    "    if len(diagonal_parent_indices) > 0:\n",
    "        # 找出所有对角项在 conn_amps 中的位置\n",
    "        diag_locs = torch.nonzero(diagonal_mask).squeeze()\n",
    "        # 找出对应的 parent index\n",
    "        parents = torch.tensor(diagonal_parent_indices, device=fxs.device)\n",
    "        # 直接赋值: <x|psi>\n",
    "        conn_amps[diag_locs] = current_amps[parents]\n",
    "\n",
    "    # B. 处理非对角项 (Grouped Vmap Contraction)\n",
    "    # Fetch the corresponding Batched Environment Dictionary in the pytree\n",
    "    def slice_env_dict(env_dict, idxs):\n",
    "        \"\"\"\n",
    "        env_dict: {key: PyTree_of_Tensors}\n",
    "        idxs: indices to slice (tensor or list)\n",
    "        \n",
    "        我们需要对 env_dict 中的每一个 value (PyTree) 进行操作，\n",
    "        利用 qu.utils.tree_map 进入 PyTree 内部，对每个叶子 Tensor 进行切片。\n",
    "        \"\"\"\n",
    "        return {\n",
    "            k: qu.utils.tree_map(lambda x: x[idxs], v) \n",
    "            for k, v in env_dict.items()\n",
    "        }\n",
    "\n",
    "    for (mode, indices), data in tasks_map.items():\n",
    "        # 获取索引\n",
    "        global_idxs = data['global_idxs']  # 在 conn_etas 中的位置\n",
    "        parent_idxs = data['parent_idxs']  # 来源于哪个 fxs[i]\n",
    "        \n",
    "        # 构造当前 Group 的 Batch\n",
    "        # 1. 目标构型 x'\n",
    "        # 注意：conn_etas 是一个大 tensor，直接切片即可\n",
    "        target_configs = conn_etas[global_idxs] # (Batch_Group, N_sites)\n",
    "        \n",
    "        # 2. 对应的父辈索引 (用于取环境)\n",
    "        subset_parents = torch.tensor(parent_idxs, device=fxs.device)\n",
    "        \n",
    "        # 3. 切片环境参数\n",
    "        subset_env_x = slice_env_dict(B_bMPS_params_x_dict, subset_parents)\n",
    "        subset_env_y = slice_env_dict(B_bMPS_params_y_dict, subset_parents)\n",
    "        \n",
    "        # 4. 调用模型 (Reuse Forward)\n",
    "        # 这里利用了 v_model.forward 的接口\n",
    "        if mode == 'row':\n",
    "            amps_group = v_model(\n",
    "                target_configs,\n",
    "                bMPS_params_x_batched=subset_env_x,\n",
    "                bMPS_params_y_batched=subset_env_y,\n",
    "                selected_rows=indices,\n",
    "                selected_cols=None\n",
    "            )\n",
    "        else: # col\n",
    "            amps_group = v_model(\n",
    "                target_configs,\n",
    "                bMPS_params_x_batched=subset_env_x,\n",
    "                bMPS_params_y_batched=subset_env_y,\n",
    "                selected_rows=None,\n",
    "                selected_cols=indices\n",
    "            )\n",
    "            \n",
    "        # 5. 填回结果 Tensor\n",
    "        locs = torch.tensor(global_idxs, device=fxs.device)\n",
    "        conn_amps[locs] = amps_group\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # 3. Compute Local Energy\n",
    "    # --------------------------------------------------------------------------\n",
    "    # E_loc(x) = \\sum_{x'} H_{x,x'} * (psi(x') / psi(x))\n",
    "    \n",
    "    # 此时 conn_amps 已经填满，且顺序与 conn_etas 一致\n",
    "    # conn_eta_num[b] 告诉我们每个样本 b 有多少个连接构型\n",
    "    \n",
    "    local_energies = []\n",
    "    offset = 0\n",
    "    \n",
    "    # 为了避免显式 Python 循环 (虽然 B=1024 时循环也不慢)，可以使用 segment_coo 或者简单的 loop\n",
    "    # 简单 loop 实现：\n",
    "    for b in range(B):\n",
    "        n_conn = conn_eta_num[b]\n",
    "        \n",
    "        # 取出当前样本相关的所有连接构型的振幅\n",
    "        # shape: (n_conn,)\n",
    "        amps_slice = conn_amps[offset : offset + n_conn]\n",
    "        coeffs_slice = conn_eta_coeffs[offset : offset + n_conn]\n",
    "        \n",
    "        # Ratio: psi(x') / psi(x)\n",
    "        # current_amps[b] 是标量\n",
    "        ratio = amps_slice / current_amps[b]\n",
    "        \n",
    "        # H_loc = \\sum H_{xx'} * Ratio\n",
    "        e_loc = torch.sum(coeffs_slice * ratio)\n",
    "        \n",
    "        local_energies.append(e_loc)\n",
    "        offset += n_conn\n",
    "        \n",
    "    local_energies = torch.stack(local_energies)\n",
    "    \n",
    "    # Global Mean Energy\n",
    "    energy_mean = torch.mean(local_energies)\n",
    "\n",
    "    if verbose and torch.distributed.is_initialized() and torch.distributed.get_rank() == 0:\n",
    "        print(f\"Reuse Stats: Processed {len(tasks_map)} groups + diagonal terms.\")\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(f'Energy (Reuse)    : {energy_mean.item()}, time: {t1 - t0:.4f} s')\n",
    "    # below is logics without reuse implemented yet\n",
    "    ################################################################################\n",
    "\n",
    "    # conn_etas = []\n",
    "    # conn_eta_coeffs = []\n",
    "\n",
    "    # fx_ind = 0\n",
    "    # for fx in fxs:\n",
    "    #     eta, coeffs = H.get_conn(fx)\n",
    "    #     conn_etas.append(torch.tensor(eta))\n",
    "    #     conn_eta_coeffs.append(torch.tensor(coeffs))\n",
    "    #     fx_ind += 1\n",
    "\n",
    "    # conn_etas = torch.cat(conn_etas, dim=0)\n",
    "    # conn_eta_coeffs = torch.cat(conn_eta_coeffs, dim=0)\n",
    "    t0 = time.time()\n",
    "    # calculate amplitudes for connected configs, in the future consider TN reuse to speed up calculation, TN reuse is controlled by a param that is not batched over (control flow?)\n",
    "    conn_amps_benchmark = torch.cat([benchmark_model(conn_etas[i:i+B]) for i in range(0, conn_etas.shape[0], B)])\n",
    "\n",
    "    # Local energy \\sum_{s'} H_{s,s'} <s'|psi>/<s|psi>\n",
    "\n",
    "    local_energies = []\n",
    "    offset = 0\n",
    "    for b in range(B):\n",
    "        n_conn = conn_eta_num[b]\n",
    "        amps_ratio = conn_amps_benchmark[offset:offset+n_conn] / current_amps[b]\n",
    "        energy_b = torch.sum(conn_eta_coeffs[offset:offset+n_conn] * amps_ratio)\n",
    "        local_energies.append(energy_b)\n",
    "        offset += n_conn\n",
    "    local_energies = torch.stack(local_energies, dim=0)\n",
    "    # Energy: (1/N) * \\sum_s <s|H|psi>/<s|psi> = (1/N) * \\sum_s \\sum_{s'} H_{s,s'} <s'|psi>/<s|psi>\n",
    "    energy = torch.mean(local_energies)\n",
    "    t1 = time.time()\n",
    "    print(f'Energy (Benchmark): {energy.item()}, time: {t1 - t0:.4f} s')\n",
    "\n",
    "    return energy_mean, local_energies\n",
    "    ################################################################################\n",
    "\n",
    "energy_mean, local_energies = evaluate_energy_reuse(random_binary_config[:reuse_B], model_reuse, H, current_amps, verbose=True, benchmark_model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "17f69ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_site_tag_id': 'I{},{}',\n",
       " '_x_tag_id': 'X{}',\n",
       " '_y_tag_id': 'Y{}',\n",
       " '_Lx': 4,\n",
       " '_Ly': 2,\n",
       " '_site_ind_id': 'k{},{}'}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_EXTRA_PROPS = ('_site_tag_id', '_x_tag_id', '_y_tag_id', '_Lx', '_Ly', '_site_ind_id')\n",
    "# get the extra properties of the tensor network\n",
    "qtn_extra_props = {prop: getattr(peps, prop) for prop in _EXTRA_PROPS}\n",
    "qtn_extra_props"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean_symmray",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
