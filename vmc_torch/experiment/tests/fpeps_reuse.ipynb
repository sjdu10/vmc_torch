{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cd0c6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "from mpi4py import MPI\n",
    "import pickle\n",
    "\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# quimb\n",
    "import quimb.tensor as qtn\n",
    "import autoray as ar\n",
    "\n",
    "from vmc_torch.experiment.tn_model import *\n",
    "from vmc_torch.variational_state import Variational_State\n",
    "# from vmc_torch.hamiltonian import spinful_Fermi_Hubbard_square_lattice\n",
    "from vmc_torch.hamiltonian_torch import spinful_Fermi_Hubbard_square_lattice_torch\n",
    "from vmc_torch.torch_utils import SVD,QR\n",
    "from vmc_torch.fermion_utils import generate_random_fpeps\n",
    "from vmc_torch.utils import closest_divisible\n",
    "\n",
    "# Register safe SVD and QR functions to torch\n",
    "ar.register_function('torch','linalg.svd',SVD.apply)\n",
    "ar.register_function('torch','linalg.qr',QR.apply)\n",
    "\n",
    "from vmc_torch.global_var import DEBUG\n",
    "\n",
    "\n",
    "COMM = MPI.COMM_WORLD\n",
    "SIZE = COMM.Get_size()\n",
    "RANK = COMM.Get_rank()\n",
    "\n",
    "# Hamiltonian parameters\n",
    "Lx = int(8)\n",
    "Ly = int(8)\n",
    "symmetry = 'Z2'\n",
    "t = 1.0\n",
    "U = 8.0\n",
    "N_f = int(Lx*Ly)\n",
    "n_fermions_per_spin = (N_f//2, N_f//2)\n",
    "H = spinful_Fermi_Hubbard_square_lattice_torch(Lx, Ly, t, U, N_f, pbc=False, n_fermions_per_spin=n_fermions_per_spin)\n",
    "graph = H.graph\n",
    "# TN parameters\n",
    "D = 4\n",
    "chi = 1024\n",
    "dtype=torch.float64\n",
    "\n",
    "# Load PEPS\n",
    "pwd = '/home/sijingdu/TNVMC/VMC_code/vmc_torch/data'\n",
    "try:\n",
    "    skeleton = pickle.load(open(f\"{pwd}/{Lx}x{Ly}/t={t}_U={U}/N={N_f}/{symmetry}/D={D}/peps_skeleton.pkl\", \"rb\"))\n",
    "    peps_params = pickle.load(open(f\"{pwd}/{Lx}x{Ly}/t={t}_U={U}/N={N_f}/{symmetry}/D={D}/peps_su_params.pkl\", \"rb\"))\n",
    "    peps = qtn.unpack(peps_params, skeleton)\n",
    "except:\n",
    "    peps = generate_random_fpeps(Lx, Ly, D=D, seed=42, symmetry=symmetry, Nf=N_f, spinless=False)[0]\n",
    "peps.exponent = 0\n",
    "peps.apply_to_arrays(lambda x: torch.tensor(8*x, dtype=dtype))\n",
    "for ts in peps.tensors:\n",
    "    ts.data.phase_sync(inplace=True)\n",
    "\n",
    "# VMC sample size\n",
    "N_samples = 2\n",
    "N_samples = closest_divisible(N_samples, SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76b3ba1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from vmc_torch.experiment.tn_model import wavefunctionModel\n",
    "# import ast\n",
    "# import cotengra as ctg\n",
    "# class fTNModel_reuse(wavefunctionModel):\n",
    "#     def __init__(self, ftn, max_bond=None, dtype=torch.float32, functional=False, debug=False):\n",
    "#         super().__init__()\n",
    "#         self.param_dtype = dtype\n",
    "#         self.functional = functional\n",
    "#         self.debug = debug\n",
    "#         # extract the raw arrays and a skeleton of the TN\n",
    "#         params, self.skeleton = qtn.pack(ftn)\n",
    "#         self.skeleton.exponent = 0\n",
    "\n",
    "#         # Flatten the dictionary structure and assign each parameter as a part of a ModuleDict\n",
    "#         self.torch_tn_params = nn.ModuleDict({\n",
    "#             str(tid): nn.ParameterDict({\n",
    "#                 str(sector): nn.Parameter(data)\n",
    "#                 for sector, data in blk_array.items()\n",
    "#             })\n",
    "#             for tid, blk_array in params.items()\n",
    "#         })\n",
    "\n",
    "#         # Get symmetry\n",
    "#         self.symmetry = ftn.arrays[0].symmetry\n",
    "\n",
    "#         # Store the shapes of the parameters\n",
    "#         self.param_shapes = [param.shape for param in self.parameters()]\n",
    "\n",
    "#         self.model_structure = {\n",
    "#             f'fPEPS (chi={max_bond})':{'D': ftn.max_bond(), 'Lx': ftn.Lx, 'Ly': ftn.Ly, 'symmetry': self.symmetry},\n",
    "#         }\n",
    "#         if max_bond is None or max_bond <= 0:\n",
    "#             max_bond = None\n",
    "#         self.max_bond = max_bond\n",
    "#         self.tree = None\n",
    "#         self.Lx = ftn.Lx\n",
    "#         self.Ly = ftn.Ly\n",
    "#         self._env_x_cache = None\n",
    "#         self._env_y_cache = None\n",
    "#         self.config_ref = None\n",
    "#         self.amp_ref = None\n",
    "    \n",
    "#     def from_1d_to_2d(self, config, ordering='snake'):\n",
    "#         if ordering == 'snake':\n",
    "#             config_2d = config.reshape((self.Lx, self.Ly))\n",
    "#             return config_2d\n",
    "#         else:\n",
    "#             raise NotImplementedError(f'Ordering {ordering} is not implemented.')\n",
    "        \n",
    "#     def from_1dsite_to_2dsite(self, site, ordering='snake'):\n",
    "#         \"\"\"\n",
    "#             Convert a 1d site index to a 2d site index.\n",
    "#             site: 1d site index\n",
    "#         \"\"\"\n",
    "#         if ordering == 'snake':\n",
    "#             return (site // self.Ly, site % self.Ly)\n",
    "#         else:\n",
    "#             raise ValueError(f\"Unsupported ordering: {ordering}\")\n",
    "    \n",
    "#     def transform_quimb_env_x_key_to_config_key(self, env_x, config):\n",
    "#         \"\"\"\n",
    "#             Return a dictionary with the keys of of the config rows\n",
    "#         \"\"\"\n",
    "#         config_2d = self.from_1d_to_2d(config)\n",
    "#         env_x_row_config = {}\n",
    "#         for key in env_x.keys():\n",
    "#             if key[0] == 'xmax': # from bottom to top\n",
    "#                 row_n = key[1]\n",
    "#                 if row_n != self.Lx-1:\n",
    "#                     rows_config = tuple(torch.cat(tuple(config_2d[row_n+1:].to(torch.int))).tolist())\n",
    "#                     env_x_row_config[('xmax', rows_config)] = env_x[key]\n",
    "#             elif key[0] == 'xmin': # from top to bottom\n",
    "#                 row_n = key[1]\n",
    "#                 if row_n != 0:\n",
    "#                     rows_config = tuple(torch.cat(tuple(config_2d[:row_n].to(torch.int))).tolist())\n",
    "#                     env_x_row_config[('xmin', rows_config)] = env_x[key]\n",
    "#         return env_x_row_config\n",
    "    \n",
    "#     def transform_quimb_env_y_key_to_config_key(self, env_y, config):\n",
    "#         \"\"\"\n",
    "#             Return a dictionary with the keys of of the config rows\n",
    "#         \"\"\"\n",
    "#         config_2d = self.from_1d_to_2d(config)\n",
    "#         env_y_row_config = {}\n",
    "#         for key in env_y.keys():\n",
    "#             if key[0] == 'ymax':\n",
    "#                 col_n = key[1]\n",
    "#                 if col_n != self.Ly-1:\n",
    "#                     cols_config = tuple(torch.cat(tuple(config_2d[:, col_n+1:].to(torch.int))).tolist())\n",
    "#                     env_y_row_config[('ymax', cols_config)] = env_y[key]\n",
    "#             elif key[0] == 'ymin':\n",
    "#                 col_n = key[1]\n",
    "#                 if col_n != 0:\n",
    "#                     cols_config = tuple(torch.cat(tuple(config_2d[:, :col_n].to(torch.int))).tolist())\n",
    "#                     env_y_row_config[('ymin', cols_config)] = env_y[key]\n",
    "#         return env_y_row_config\n",
    "\n",
    "#     def cache_env_x(self, amp, config):\n",
    "#         \"\"\"\n",
    "#             Cache the environment x for the given configuration\n",
    "#         \"\"\"\n",
    "#         env_x = amp.compute_x_environments(max_bond=self.max_bond, cutoff=0.0)\n",
    "#         env_x_cache = self.transform_quimb_env_x_key_to_config_key(env_x, config)\n",
    "#         self._env_x_cache = env_x_cache\n",
    "#         self.config_ref = config\n",
    "#         self.amp_ref = amp\n",
    "    \n",
    "#     def cache_env_y(self, amp, config):\n",
    "#         env_y = amp.compute_y_environments(max_bond=self.max_bond, cutoff=0.0)\n",
    "#         env_y_cache = self.transform_quimb_env_y_key_to_config_key(env_y, config)\n",
    "#         self._env_y_cache = env_y_cache\n",
    "#         self.config_ref = config\n",
    "#         self.amp_ref = amp\n",
    "    \n",
    "#     def cache_env(self, amp, config):\n",
    "#         \"\"\"\n",
    "#             Cache the environment x and y for the given configuration\n",
    "#         \"\"\"\n",
    "#         self.cache_env_x(amp, config)\n",
    "#         self.cache_env_y(amp, config)\n",
    "        \n",
    "#     @property\n",
    "#     def env_x_cache(self):\n",
    "#         \"\"\"\n",
    "#             Return the cached environment x\n",
    "#         \"\"\"\n",
    "#         if hasattr(self, '_env_x_cache'):\n",
    "#             return self._env_x_cache\n",
    "#         else:\n",
    "#             return None\n",
    "        \n",
    "#     @property\n",
    "#     def env_y_cache(self):\n",
    "#         \"\"\"\n",
    "#             Return the cached environment y\n",
    "#         \"\"\"\n",
    "#         if hasattr(self, '_env_y_cache'):\n",
    "#             return self._env_y_cache\n",
    "#         else:\n",
    "#             return None\n",
    "    \n",
    "#     def clear_env_x_cache(self):\n",
    "#         \"\"\"\n",
    "#             Clear the cached environment x\n",
    "#         \"\"\"\n",
    "#         self._env_x_cache = None\n",
    "\n",
    "#     def clear_env_y_cache(self):\n",
    "#         \"\"\"\n",
    "#             Clear the cached environment y\n",
    "#         \"\"\"\n",
    "#         self._env_y_cache = None\n",
    "    \n",
    "#     def clear_wavefunction_env_cache(self):\n",
    "#         self.clear_env_x_cache()\n",
    "#         self.clear_env_y_cache()\n",
    "#         self.config_ref = None\n",
    "#         self.amp_ref = None\n",
    "    \n",
    "#     def detect_changed_sites(self, config_ref, new_config):\n",
    "#         \"\"\"\n",
    "#             Detect the sites that have changed in the new configuration,\n",
    "#             written in 1d coordinate format.\n",
    "#         \"\"\"\n",
    "#         changed_sites = set()\n",
    "#         unchanged_sites = set()\n",
    "#         for i in range(self.Lx * self.Ly):\n",
    "#             if config_ref[i] != new_config[i]:\n",
    "#                 changed_sites.add(i)\n",
    "#             else:\n",
    "#                 unchanged_sites.add(i)\n",
    "#         changed_sites = sorted(changed_sites)\n",
    "#         unchanged_sites = sorted(unchanged_sites)\n",
    "#         if len(changed_sites) == 0:\n",
    "#             return [], []\n",
    "#         return changed_sites, unchanged_sites\n",
    "\n",
    "#     def from_1d_sites_to_tids(self, sites):\n",
    "#         \"\"\"\n",
    "#             Convert a list of 1d site indices to a list of tensor ids.\n",
    "#         \"\"\"\n",
    "#         tids_list = list(self.skeleton.tensor_map.keys())\n",
    "#         return [tids_list[site] for site in sites]\n",
    "    \n",
    "#     def detect_changed_rows(self, config_ref, new_config):\n",
    "#         \"\"\"\n",
    "#             Detect the rows that have changed in the new configuration\n",
    "#         \"\"\"\n",
    "#         config_ref_2d = self.from_1d_to_2d(config_ref)\n",
    "#         new_config_2d = self.from_1d_to_2d(new_config)\n",
    "#         changed_rows = []\n",
    "#         for i in range(self.Lx):\n",
    "#             if not torch.equal(config_ref_2d[i], new_config_2d[i]):\n",
    "#                 changed_rows.append(i)\n",
    "#         if len(changed_rows) == 0:\n",
    "#             return [], [], []\n",
    "#         unchanged_rows_above = list(range(changed_rows[0]))\n",
    "#         unchanged_rows_below = list(range(changed_rows[-1]+1, self.Lx))\n",
    "#         return changed_rows, unchanged_rows_above, unchanged_rows_below\n",
    "    \n",
    "#     def detect_changed_cols(self, config_ref, new_config):\n",
    "#         \"\"\"\n",
    "#             Detect the columns that have changed in the new configuration\n",
    "#         \"\"\"\n",
    "#         config_ref_2d = self.from_1d_to_2d(config_ref)\n",
    "#         new_config_2d = self.from_1d_to_2d(new_config)\n",
    "#         changed_cols = []\n",
    "#         for i in range(self.Ly):\n",
    "#             if not torch.equal(config_ref_2d[:, i], new_config_2d[:, i]):\n",
    "#                 changed_cols.append(i)\n",
    "#         if len(changed_cols) == 0:\n",
    "#             return [], [], []\n",
    "#         unchanged_cols_left = list(range(changed_cols[0]))\n",
    "#         unchanged_cols_right = list(range(changed_cols[-1]+1, self.Ly))\n",
    "#         return changed_cols, unchanged_cols_left, unchanged_cols_right\n",
    "    \n",
    "#     def update_env_x_cache(self, config):\n",
    "#         \"\"\"\n",
    "#             Update the cached environment x for the given configuration\n",
    "#         \"\"\"\n",
    "#         if self.env_x_cache is not None:\n",
    "#             self.clear_env_x_cache()\n",
    "#         amp_tn = self.get_amp_tn(config)\n",
    "#         self.cache_env_x(amp_tn, config)\n",
    "#         self.config_ref = config\n",
    "#         self.amp_ref = amp_tn\n",
    "    \n",
    "#     def update_env_x_cache_to_row(self, config, row_id, from_which='xmin'):\n",
    "#         amp_tn = self.get_amp_tn(config)\n",
    "#         new_env_x = amp_tn.compute_environments(max_bond=self.max_bond, cutoff=0.0, xrange=(0, row_id+1) if from_which=='xmin' else (row_id-1, self.Lx-1), from_which=from_which)\n",
    "#         new_env_x_cache = self.transform_quimb_env_x_key_to_config_key(new_env_x, config)\n",
    "#         # add the new env_x to the cache\n",
    "#         if self.env_x_cache is None:\n",
    "#             self._env_x_cache = new_env_x_cache\n",
    "#         else:\n",
    "#             self._env_x_cache.update(new_env_x_cache)\n",
    "#         self.config_ref = config\n",
    "#         self.amp_ref = amp_tn\n",
    "    \n",
    "#     def update_env_y_cache(self, config):\n",
    "#         \"\"\"\n",
    "#             Update the cached environment y for the given configuration\n",
    "#         \"\"\"\n",
    "#         if self.env_y_cache is not None:\n",
    "#             self.clear_env_y_cache()\n",
    "#         amp_tn = self.get_amp_tn(config)\n",
    "#         self.cache_env_y(amp_tn, config)\n",
    "#         self.config_ref = config\n",
    "#         self.amp_ref = amp_tn\n",
    "    \n",
    "#     def update_env_y_cache_to_col(self, config, col_id, from_which='ymin'):\n",
    "#         amp_tn = self.get_amp_tn(config)\n",
    "#         new_env_y = amp_tn.compute_environments(max_bond=self.max_bond, cutoff=0.0, yrange=(0, col_id+1) if from_which=='ymin' else (col_id-1, self.Ly-1), from_which=from_which)\n",
    "#         new_env_y_cache = self.transform_quimb_env_y_key_to_config_key(new_env_y, config)\n",
    "#         # add the new env_y to the cache\n",
    "#         if self.env_y_cache is None:\n",
    "#             self._env_y_cache = new_env_y_cache\n",
    "#         else:\n",
    "#             self._env_y_cache.update(new_env_y_cache)\n",
    "#         self.config_ref = config\n",
    "#         self.amp_ref = amp_tn\n",
    "    \n",
    "#     def psi(self):\n",
    "#         \"\"\"\n",
    "#             Return the wavefunction (fPEPS)\n",
    "#         \"\"\"\n",
    "#         # Reconstruct the original parameter structure (by unpacking from the flattened dict)\n",
    "#         params = {\n",
    "#             int(tid): {\n",
    "#                 ast.literal_eval(sector): data\n",
    "#                 for sector, data in blk_array.items()\n",
    "#             }\n",
    "#             for tid, blk_array in self.torch_tn_params.items()\n",
    "#         }\n",
    "#         # Reconstruct the TN with the new parameters\n",
    "#         psi = qtn.unpack(params, self.skeleton)\n",
    "#         return psi\n",
    "\n",
    "#     def get_local_amp_tensors(self, sites:list, config:torch.Tensor):\n",
    "#         \"\"\"\n",
    "#             Get the local tensors for the given tensor ids and configuration.\n",
    "#             tids: a list of tensor ids. list of int.\n",
    "#             config: the input configuration.\n",
    "#         \"\"\"\n",
    "#         # first pick out the tensor parameters and form the local tn parameters vector\n",
    "#         local_ts_params = {}\n",
    "#         tids = self.from_1d_sites_to_tids(sites)\n",
    "#         for tid in tids:\n",
    "#             local_ts_params[tid] = {\n",
    "#                 ast.literal_eval(sector): data\n",
    "#                 for sector, data in self.torch_tn_params[str(tid)].items()\n",
    "#             }\n",
    "        \n",
    "#         # Get sites corresponding to the tids\n",
    "#         sites_2d = [self.from_1dsite_to_2dsite(site) for site in sites]\n",
    "\n",
    "#         # Select the corresponding tensor skeleton\n",
    "#         local_ts_skeleton = self.skeleton.select([self.skeleton.site_tag_id.format(*site) for site in sites_2d], which='any')\n",
    "\n",
    "#         # Reconstruct the TN with the new parameters\n",
    "#         local_ftn = qtn.unpack(local_ts_params, local_ts_skeleton)\n",
    "\n",
    "#         # Fix the physical indices\n",
    "#         return local_ftn.fix_phys_inds(sites_2d, config[sites])\n",
    "    \n",
    "#     def get_amp_tn(self, config, reconstruct=False):\n",
    "\n",
    "#         if self.amp_ref is None or reconstruct:\n",
    "#             psi = self.psi()\n",
    "#             # Check config type\n",
    "#             if not type(config) == torch.Tensor:\n",
    "#                 config = torch.tensor(config, dtype=torch.int if self.functional else self.param_dtype)\n",
    "#             else:\n",
    "#                 if config.dtype != self.param_dtype:\n",
    "#                     config = config.to(torch.int if self.functional else self.param_dtype)\n",
    "#             # Get the amplitude\n",
    "#             amp_tn = psi.get_amp(config, conj=True, functional=self.functional)\n",
    "#             return amp_tn\n",
    "        \n",
    "#         else:\n",
    "#             # detect the sites that have changed\n",
    "#             changed_sites, unchanged_sites = self.detect_changed_sites(self.config_ref, config)\n",
    "\n",
    "#             if len(changed_sites) == 0:\n",
    "#                 return self.amp_ref\n",
    "#             else:\n",
    "#                 # substitute the changed sites tensors\n",
    "#                 local_amp_tn = self.get_local_amp_tensors(changed_sites, config)\n",
    "#                 unchanged_sites_2d = [self.from_1dsite_to_2dsite(site) for site in unchanged_sites]\n",
    "#                 unchanged_sites_tags = [self.skeleton.site_tag_id.format(*site) for site in unchanged_sites_2d]\n",
    "#                 unchanged_amp_tn = self.amp_ref.select(unchanged_sites_tags, which='any')\n",
    "#                 # merge the local_amp_tn and unchanged_amp_tn\n",
    "#                 amp_tn = local_amp_tn | unchanged_amp_tn\n",
    "#                 return amp_tn\n",
    "    \n",
    "#     def amplitude(self, x):\n",
    "#         # Reconstruct the original parameter structure (by unpacking from the flattened dict)\n",
    "#         params = {\n",
    "#             int(tid): {\n",
    "#                 ast.literal_eval(sector): data\n",
    "#                 for sector, data in blk_array.items()\n",
    "#             }\n",
    "#             for tid, blk_array in self.torch_tn_params.items()\n",
    "#         }\n",
    "#         # Reconstruct the TN with the new parameters\n",
    "#         psi = qtn.unpack(params, self.skeleton)\n",
    "#         # `x` is expected to be batched as (batch_size, input_dim)\n",
    "#         # Loop through the batch and compute amplitude for each sample\n",
    "#         batch_amps = []\n",
    "#         for x_i in x:\n",
    "#             # Check x_i type\n",
    "#             if not type(x_i) == torch.Tensor:\n",
    "#                 x_i = torch.tensor(x_i, dtype=torch.int if self.functional else self.param_dtype)\n",
    "#             else:\n",
    "#                 if x_i.dtype != self.param_dtype:\n",
    "#                     x_i = x_i.to(torch.int if self.functional else self.param_dtype)\n",
    "#             # Get the amplitude\n",
    "#             # amp = psi.get_amp(x_i, conj=True, functional=self.functional)\n",
    "#             amp = self.get_amp_tn(x_i)\n",
    "\n",
    "#             if self.max_bond is None:\n",
    "#                 amp = amp\n",
    "#                 if self.tree is None:\n",
    "#                     opt = ctg.HyperOptimizer(progbar=True, max_repeats=10, parallel=True)\n",
    "#                     self.tree = amp.contraction_tree(optimize=opt)\n",
    "#                 amp_val = amp.contract(optimize=self.tree)\n",
    "\n",
    "#             else:\n",
    "#                 if self.cache_env_mode:\n",
    "#                     self.cache_env_x(amp, x_i)\n",
    "#                     # self.cache_env_y(amp, x_i)\n",
    "#                     self.config_ref = x_i\n",
    "#                     config_2d = self.from_1d_to_2d(x_i)\n",
    "#                     key_bot = ('xmax', tuple(torch.cat(tuple(config_2d[self.Lx//2:].to(torch.int))).tolist()))\n",
    "#                     key_top = ('xmin', tuple(torch.cat(tuple(config_2d[:self.Lx//2].to(torch.int))).tolist()))\n",
    "#                     amp_bot = self.env_x_cache[key_bot]\n",
    "#                     amp_top = self.env_x_cache[key_top]\n",
    "#                     amp_val = (amp_bot|amp_top).contract()\n",
    "                    \n",
    "\n",
    "#                 else:\n",
    "#                     if self.env_x_cache is None and self.env_y_cache is None:\n",
    "#                         # check whether we can reuse the cached environment\n",
    "#                         amp = amp.contract_boundary_from_ymin(max_bond=self.max_bond, cutoff=0.0, yrange=[0, psi.Ly//2-1])\n",
    "#                         amp = amp.contract_boundary_from_ymax(max_bond=self.max_bond, cutoff=0.0, yrange=[psi.Ly//2, psi.Ly-1])\n",
    "#                         amp_val = amp.contract()\n",
    "#                     else:\n",
    "#                         config_2d = self.from_1d_to_2d(x_i)\n",
    "#                         # detect the rows that have changed\n",
    "#                         changed_rows, unchanged_rows_above, unchanged_rows_below = self.detect_changed_rows(self.config_ref, x_i)\n",
    "#                         # detect the columns that have changed\n",
    "#                         changed_cols, unchanged_cols_left, unchanged_cols_right = self.detect_changed_cols(self.config_ref, x_i)\n",
    "#                         if len(changed_rows) == 0:\n",
    "#                             key_bot = ('xmax', tuple(torch.cat(tuple(config_2d[self.Lx//2:].to(torch.int))).tolist()))\n",
    "#                             key_top = ('xmin', tuple(torch.cat(tuple(config_2d[:self.Lx//2].to(torch.int))).tolist()))\n",
    "#                             amp_bot = self.env_x_cache[key_bot]\n",
    "#                             amp_top = self.env_x_cache[key_top]\n",
    "#                             amp_val = (amp_bot|amp_top).contract()\n",
    "#                         else:\n",
    "#                             if len(changed_rows) <= len(changed_cols):\n",
    "#                                 # for bottom envs, until the last row in the changed rows, we can reuse the env\n",
    "#                                 # for top envs, until the first row in the changed rows, we can reuse the env\n",
    "#                                 amp_changed_rows = qtn.TensorNetwork([amp.select(amp.x_tag_id.format(row_n)) for row_n in changed_rows])\n",
    "#                                 amp_unchanged_bottom_env = qtn.TensorNetwork()\n",
    "#                                 amp_unchanged_top_env = qtn.TensorNetwork()\n",
    "#                                 if len(unchanged_rows_below) != 0:\n",
    "#                                     amp_unchanged_bottom_env = self.env_x_cache[('xmax', tuple(torch.cat(tuple(config_2d[unchanged_rows_below].to(torch.int))).tolist()))]\n",
    "#                                 if len(unchanged_rows_above) != 0:\n",
    "#                                     amp_unchanged_top_env = self.env_x_cache[('xmin', tuple(torch.cat(tuple(config_2d[unchanged_rows_above].to(torch.int))).tolist()))]\n",
    "#                                 amp_val = (amp_unchanged_bottom_env|amp_unchanged_top_env|amp_changed_rows).contract()\n",
    "#                                 # print(f'changed rows: {changed_rows}', self.from_1d_to_2d(x_i), self.from_1d_to_2d(self.config_ref))\n",
    "#                             else:\n",
    "#                                 # for left envs, until the first column in the changed columns, we can reuse the env\n",
    "#                                 # for right envs, until the last column in the changed columns, we can reuse the env\n",
    "#                                 amp_changed_cols = qtn.TensorNetwork([amp.select(amp.y_tag_id.format(col_n)) for col_n in changed_cols])\n",
    "#                                 amp_unchanged_left_env = qtn.TensorNetwork()\n",
    "#                                 amp_unchanged_right_env = qtn.TensorNetwork()\n",
    "#                                 if len(unchanged_cols_left) != 0:\n",
    "#                                     amp_unchanged_left_env = self.env_y_cache[('ymin', tuple(torch.cat(tuple(config_2d[:, unchanged_cols_left].to(torch.int))).tolist()))]\n",
    "#                                 if len(unchanged_cols_right) != 0:\n",
    "#                                     amp_unchanged_right_env = self.env_y_cache[('ymax', tuple(torch.cat(tuple(config_2d[:, unchanged_cols_right].to(torch.int))).tolist()))]\n",
    "#                                 amp_val = (amp_unchanged_left_env|amp_unchanged_right_env|amp_changed_cols).contract()\n",
    "                                \n",
    "#             if amp_val==0.0:\n",
    "#                 amp_val = torch.tensor(0.0)\n",
    "            \n",
    "#             if self.debug:\n",
    "#                 print(f'Reused Amp val: {amp_val}, Exact Amp val: {self.get_amp_tn(x_i).contract()}')\n",
    "            \n",
    "#             batch_amps.append(amp_val)\n",
    "\n",
    "#         # Return the batch of amplitudes stacked as a tensor\n",
    "#         return torch.stack(batch_amps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f2eb416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 3, 3, 1, 2, 0, 3, 0, 2, 0, 2, 2, 0, 3, 0, 1, 3, 2, 1, 1, 1, 0, 3, 1,\n",
      "        1, 3, 1, 1, 3, 3, 3, 2, 2, 2, 0, 1, 0, 2, 1, 0, 1, 0, 2, 1, 2, 1, 2, 1,\n",
      "        1, 2, 2, 0, 3, 3, 2, 2, 1, 0, 2, 1, 2, 1, 2, 3])\n",
      "Reused Amp val: -15864435787.480804, Exact Amp val: -15864435787.544909, Rel error: 4.040741256649235e-12\n",
      "Reused Amp val: 107415504489.87418, Exact Amp val: 107415504489.87875, Rel error: 4.2616163658025076e-14\n",
      "Reused Amp val: -72370525972.30078, Exact Amp val: -72370525972.30498, Rel error: 5.79817119719885e-14\n",
      "Reused Amp val: -11231692254.0059, Exact Amp val: -11231692254.007483, Rel error: 1.4094931818217535e-13\n",
      "Reused Amp val: 68366055836.32291, Exact Amp val: 68366055836.31947, Rel error: 5.0218306395826883e-14\n",
      "Reused Amp val: -14480462517.648745, Exact Amp val: -14480462517.649925, Rel error: 8.153391525110955e-14\n",
      "Reused Amp val: -286545156412.25214, Exact Amp val: -286545156412.2915, Rel error: 1.3738733634222163e-13\n",
      "Reused Amp val: -18777926557.78307, Exact Amp val: -18777926557.799805, Rel error: 8.912100520142683e-13\n",
      "Reused Amp val: 80172198289.6112, Exact Amp val: 80172198289.61902, Rel error: 9.744649849537168e-14\n",
      "Reused Amp val: 26465211405.02061, Exact Amp val: 26465211405.013187, Rel error: 2.804965645390638e-13\n",
      "Reused Amp val: 46494579353.49939, Exact Amp val: 46494579353.506516, Rel error: 1.5326204885107934e-13\n",
      "Reused Amp val: 1024133798401.7119, Exact Amp val: 1024133798401.8154, Rel error: 1.010762706606681e-13\n",
      "Reused Amp val: 2129523402608.934, Exact Amp val: 2129523402609.1643, Rel error: 1.081108613753298e-13\n",
      "Reused Amp val: 10422371108773.111, Exact Amp val: 10422371108772.568, Rel error: 5.209647059515854e-14\n",
      "Reused Amp val: -36087764213726.63, Exact Amp val: -36087764213729.28, Rel error: 7.338879417174934e-14\n",
      "Reused Amp val: -18696364766470.9, Exact Amp val: -18696364766472.043, Rel error: 6.121678006905778e-14\n",
      "Reused Amp val: 148433292524493.38, Exact Amp val: 148433292524504.9, Rel error: 7.768641255529855e-14\n",
      "Reused Amp val: 142037625943803.78, Exact Amp val: 142037625943816.88, Rel error: 9.21850806291232e-14\n",
      "Reused Amp val: -64279779434879.36, Exact Amp val: -64279779434890.84, Rel error: 1.7866232742183804e-13\n",
      "Reused Amp val: 16370384928301.03, Exact Amp val: 16370384928308.45, Rel error: 4.532527431391743e-13\n",
      "Reused Amp val: -282671820524387.8, Exact Amp val: -282671820524384.9, Rel error: 1.0391909581049288e-14\n",
      "Reused Amp val: 1033688674528456.9, Exact Amp val: 1033688674528436.8, Rel error: 1.9469111441296304e-14\n",
      "Reused Amp val: -357425789504316.5, Exact Amp val: -357425789504173.1, Rel error: 4.0113221879957833e-13\n",
      "Reused Amp val: 335921878341907.06, Exact Amp val: 335921878341854.9, Rel error: 1.5535606152717083e-13\n",
      "Reused Amp val: -611546751473148.5, Exact Amp val: -611546751473134.4, Rel error: 2.309717117452552e-14\n",
      "Reused Amp val: -1086534592860848.5, Exact Amp val: -1086534592860826.2, Rel error: 2.04779490190148e-14\n",
      "Reused Amp val: 633773192460963.8, Exact Amp val: 633773192460953.5, Rel error: 1.6172978159898264e-14\n",
      "Reused Amp val: -74471345448737.38, Exact Amp val: -74471345448734.77, Rel error: 3.503864451859896e-14\n",
      "Reused Amp val: 7879082578839.219, Exact Amp val: 7879082578843.425, Rel error: 5.338254353106944e-13\n",
      "Reused Amp val: -40253637565816.66, Exact Amp val: -40253637565819.45, Rel error: 6.94812983156312e-14\n",
      "Reused Amp val: 2695209278040402.0, Exact Amp val: 2695209278040329.0, Rel error: 2.7085095244654943e-14\n",
      "Reused Amp val: -206372928550137.8, Exact Amp val: -206372928550164.6, Rel error: 1.2977113901589123e-13\n",
      "Reused Amp val: -3575582728704035.5, Exact Amp val: -3575582728704005.5, Rel error: 8.390240773669276e-15\n",
      "Reused Amp val: 1.026049625502108e+16, Exact Amp val: 1.0260496255021068e+16, Rel error: 1.16953407532581e-15\n",
      "Reused Amp val: 1.0599353946300642e+16, Exact Amp val: 1.0599353946300724e+16, Rel error: 7.73632057344578e-15\n",
      "Reused Amp val: 1.11778261945462e+17, Exact Amp val: 1.1177826194546198e+17, Rel error: 1.4314053306542377e-16\n",
      "Reused Amp val: 2680768353802650.5, Exact Amp val: 2680768353802671.0, Rel error: 7.647061325131185e-15\n",
      "Reused Amp val: 1.279892556612002e+17, Exact Amp val: 1.2798925566120059e+17, Rel error: 3.1252623349794066e-15\n",
      "Reused Amp val: 5.610153207107205e+17, Exact Amp val: 5.610153207107209e+17, Rel error: 6.844732858873276e-16\n",
      "Reused Amp val: 1.3030093942349238e+17, Exact Amp val: 1.3030093942349277e+17, Rel error: 2.9470240329730597e-15\n",
      "Reused Amp val: 2.6090081657403136e+18, Exact Amp val: 2.6090081657403233e+18, Rel error: 3.728619989673208e-15\n",
      "Reused Amp val: -1.0871201951650994e+19, Exact Amp val: -1.087120195165106e+19, Rel error: 6.028404245590042e-15\n",
      "Reused Amp val: 6.418933899541588e+19, Exact Amp val: 6.418933899541618e+19, Rel error: 4.594407803779689e-15\n",
      "Reused Amp val: 1.4917034511157922e+19, Exact Amp val: 1.491703451115803e+19, Rel error: 7.276513298860336e-15\n",
      "Reused Amp val: 5.857314245668562e+19, Exact Amp val: 5.8573142456685986e+19, Rel error: 6.293669496605959e-15\n",
      "Reused Amp val: -2.79273445723612e+19, Exact Amp val: -2.7927344572360974e+19, Rel error: 8.066645914590614e-15\n",
      "Reused Amp val: -2.5053811629622975e+20, Exact Amp val: -2.5053811629623086e+20, Rel error: 4.446876253682286e-15\n",
      "Reused Amp val: 5.927474256799333e+19, Exact Amp val: 5.927474256799358e+19, Rel error: 4.284320589139526e-15\n",
      "Reused Amp val: 9.301319540885473e+19, Exact Amp val: 9.30131954088538e+19, Rel error: 1.0040381860820412e-14\n",
      "Reused Amp val: -2.8176362416031377e+20, Exact Amp val: -2.8176362416031446e+20, Rel error: 2.4422173091033114e-15\n",
      "Reused Amp val: 6.382754944102872e+20, Exact Amp val: 6.382754944102863e+20, Rel error: 1.437473329361795e-15\n",
      "Reused Amp val: 1.5695743890399445e+20, Exact Amp val: 1.5695743890399288e+20, Rel error: 1.0020958617718548e-14\n",
      "Reused Amp val: 1.4380134843477483e+21, Exact Amp val: 1.4380134843477375e+21, Rel error: 7.47413297370789e-15\n",
      "Reused Amp val: 3.578413581164332e+20, Exact Amp val: 3.578413581164316e+20, Rel error: 4.578565229642658e-15\n",
      "Reused Amp val: 3.080465702835183e+20, Exact Amp val: 3.0804657028351636e+20, Rel error: 6.382411588580525e-15\n",
      "Reused Amp val: -3.007887785849369e+20, Exact Amp val: -3.0078877858493864e+20, Rel error: 5.882772649712812e-15\n",
      "Reused Amp val: 1.4738004419052763e+21, Exact Amp val: 1.4738004419052687e+21, Rel error: 5.158212593675314e-15\n",
      "Reused Amp val: -1.5519912615749555e+21, Exact Amp val: -1.5519912615749516e+21, Rel error: 2.5336225128031114e-15\n",
      "Reused Amp val: -1.2081268565425952e+20, Exact Amp val: -1.2081268565426078e+20, Rel error: 1.0442347119162048e-14\n",
      "Reused Amp val: 2.1406375422996765e+20, Exact Amp val: 2.140637542299672e+20, Rel error: 2.1430624799150536e-15\n",
      "Reused Amp val: -3.59617532340997e+20, Exact Amp val: -3.5961753234099483e+20, Rel error: 6.0138558482440905e-15\n",
      "Reused Amp val: -7.814243879124787e+19, Exact Amp val: -7.814243879124197e+19, Rel error: 7.548062347730388e-14\n",
      "Reused Amp val: 1.512653784431325e+20, Exact Amp val: 1.51265378443132e+20, Rel error: 3.249388624540983e-15\n",
      "Reused Amp val: 3.2646298366045317e+20, Exact Amp val: 3.2646298366045513e+20, Rel error: 6.022367307789063e-15\n",
      "Reused Amp val: 1.74632069988665e+20, Exact Amp val: 1.7463206998866316e+20, Rel error: 1.05078523098256e-14\n",
      "Reused Amp val: -5.25975185818651e+19, Exact Amp val: -5.2597518581864735e+19, Rel error: 7.008695655979188e-15\n",
      "Reused Amp val: -1.4551684347243727e+21, Exact Amp val: -1.4551684347243644e+21, Rel error: 5.764698985921143e-15\n",
      "Reused Amp val: 4.462317160378805e+20, Exact Amp val: 4.462317160378804e+20, Rel error: 2.9373080238176833e-16\n",
      "Reused Amp val: 3.1981711728760816e+20, Exact Amp val: 3.198171172876056e+20, Rel error: 7.991767362787912e-15\n",
      "Reused Amp val: -1.347031793978388e+21, Exact Amp val: -1.3470317939783765e+21, Rel error: 8.562779328269632e-15\n",
      "Reused Amp val: 3.170359723679991e+20, Exact Amp val: 3.170359723679969e+20, Rel error: 7.028300237846851e-15\n",
      "Reused Amp val: -2.565260416560927e+20, Exact Amp val: -2.5652604165609148e+20, Rel error: 4.726288185686079e-15\n",
      "Reused Amp val: 2.435105541436206e+19, Exact Amp val: 2.4351055414362595e+19, Rel error: 2.2035020284316707e-14\n",
      "Reused Amp val: 3.151150025706863e+20, Exact Amp val: 3.1511500257068365e+20, Rel error: 8.318994584880112e-15\n",
      "Reused Amp val: -1.3372490888165276e+19, Exact Amp val: -1.3372490888164727e+19, Rel error: 4.104426053382246e-14\n",
      "Reused Amp val: -1.584462447777054e+21, Exact Amp val: -1.5844624477770547e+21, Rel error: 4.963399423592125e-16\n",
      "Reused Amp val: -2.1656959180311737e+20, Exact Amp val: -2.1656959180311642e+20, Rel error: 4.387836686065756e-15\n",
      "Reused Amp val: 5.531634937199779e+19, Exact Amp val: 5.531634937200153e+19, Rel error: 6.767879736284445e-14\n",
      "Reused Amp val: -1.53897999271241e+21, Exact Amp val: -1.5389799927124134e+21, Rel error: 2.2143705676080373e-15\n",
      "Reused Amp val: -8.32604046990915e+19, Exact Amp val: -8.32604046990939e+19, Rel error: 2.872991079787572e-14\n",
      "Reused Amp val: -1.0750211370642238e+22, Exact Amp val: -1.0750211370642198e+22, Rel error: 3.706521353507087e-15\n",
      "Reused Amp val: 2.5681512485906844e+22, Exact Amp val: 2.5681512485906924e+22, Rel error: 3.1030795418973836e-15\n",
      "Reused Amp val: -2.4116999484005134e+21, Exact Amp val: -2.4116999484004903e+21, Rel error: 9.565315957028492e-15\n",
      "Reused Amp val: 3.6118311796950857e+22, Exact Amp val: 3.611831179695093e+22, Rel error: 1.9741556139403876e-15\n",
      "Reused Amp val: 3.267476256616792e+22, Exact Amp val: 3.2674762566167876e+22, Rel error: 1.4120177279504262e-15\n",
      "Reused Amp val: 1.903308859772437e+22, Exact Amp val: 1.903308859772437e+22, Rel error: 0.0\n",
      "Reused Amp val: -6.105069312504711e+21, Exact Amp val: -6.105069312504825e+21, Rel error: 1.8721291790396798e-14\n",
      "Reused Amp val: -1.0534287957064984e+22, Exact Amp val: -1.0534287957064933e+22, Rel error: 4.777887998233857e-15\n",
      "Reused Amp val: 1.1628535093836937e+23, Exact Amp val: 1.1628535093837162e+23, Rel error: 1.9333019386005576e-14\n",
      "Reused Amp val: -1.4396503436196814e+23, Exact Amp val: -1.4396503436197005e+23, Rel error: 1.328518853537144e-14\n",
      "Reused Amp val: -6.077216771498667e+23, Exact Amp val: -6.077216771498737e+23, Rel error: 1.1484404980799772e-14\n",
      "Reused Amp val: -6.077216771498784e+23, Exact Amp val: -6.077216771498737e+23, Rel error: 7.729887967846e-15\n"
     ]
    }
   ],
   "source": [
    "# reusable fPEPS model\n",
    "random_x = torch.tensor(H.hilbert.random_state())\n",
    "random_x1 = random_x.clone()\n",
    "print(random_x)\n",
    "random_x1[2] = 1\n",
    "random_x1[3] = 2\n",
    "\n",
    "# print((peps.product_bra_state(random_x).conj()|peps).contract(), (peps|peps.product_bra_state(random_x, reverse=1)).contract())\n",
    "\n",
    "# permute_list = []\n",
    "# for tensor in peps.product_bra_state(random_x).conj().tensors:\n",
    "#     # print(tensor.data.charge, tensor.data.oddpos)\n",
    "#     if len(tensor.data.oddpos)>0:\n",
    "#         # print(tensor.data.oddpos[0].label, tensor.data.oddpos[0].dual)\n",
    "#         permute_list.append(tensor.data.oddpos[0].label)\n",
    "\n",
    "# # sort the list and note down the parity of the permutation\n",
    "# print(len(permute_list))\n",
    "# # sum from len(permute_list) to 1\n",
    "# N = 0\n",
    "# for i in range(len(permute_list)):\n",
    "#     N += i\n",
    "# print('phase correction from reversing the ordering:', (-1)**(N%2))\n",
    "\n",
    "from vmc_torch.sampler import *\n",
    "\n",
    "model = fTNModel_reuse(peps, max_bond=chi, dtype=dtype, debug=True)\n",
    "# model = fTNModel(peps, max_bond=chi, dtype=dtype)\n",
    "\n",
    "sampled_x = torch.tensor([3, 1, 1, 0, 1, 2, 2, 0, 2, 3, 1, 1, 2, 2, 3, 2, 2, 3, 2, 0, 1, 3, 3, 2,\n",
    "        2, 1, 1, 1, 0, 3, 0, 2, 3, 1, 1, 3, 0, 2, 1, 3, 1, 0, 0, 0, 2, 3, 0, 0,\n",
    "        0, 1, 1, 0, 3, 3, 2, 2, 3, 3, 3, 0, 0, 2, 1, 0])\n",
    "\n",
    "sampler = MetropolisExchangeSamplerSpinful_2D_reusable(H.hilbert, graph, N_samples=N_samples, burn_in_steps=1, reset_chain=False, random_edge=False, equal_partition=False, dtype=dtype)\n",
    "# sampler = MetropolisExchangeSamplerSpinful(H.hilbert, graph, N_samples=N_samples, burn_in_steps=10, reset_chain=False, random_edge=False, equal_partition=False, dtype=dtype)\n",
    "vstate = Variational_State(model, hi=H.hilbert, sampler=sampler, dtype=dtype)\n",
    "# t0 = time.time()\n",
    "sampled_x, sampled_amp = sampler._sample_next(vstate, burn_in=False)\n",
    "vstate.set_cache_env_mode(on=True)\n",
    "amp, grad = vstate.amplitude_grad(sampled_x, retain_graph=True)\n",
    "vstate.set_cache_env_mode(on=False)\n",
    "# t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8a1ccab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from vmc_torch.fermion_utils import flatten_fts_params\n",
    "from vmc_torch.fermion_utils import reconstruct_fts_params\n",
    "amp_tn = model.get_amp_tn(sampled_x)\n",
    "ts0 = amp_tn.select('I0,0').contract()\n",
    "ts0.draw()\n",
    "ts_params = flatten_fts_params(ts0.get_params())\n",
    "\n",
    "ts_left = [ts for ts in amp_tn.tensors if 'I0,0' not in ts.tags]\n",
    "tn_left = qtn.TensorNetwork(ts_left)\n",
    "grad_ts = tn_left.contract()\n",
    "grad_ts.data.phase_sync(inplace=True) # BUG: should take into account the fermion signs generated in the final contraction!!\n",
    "\n",
    "grad_ts_params = flatten_fts_params(grad_ts.get_params())\n",
    "# ts0.data.blocks, grad_ts.data.blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4df1c2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9.2773e-03, -5.8453e-17, -1.6371e-16, -3.4835e-03, -2.2166e-01,\n",
       "         6.7281e-02, -7.5713e-02,  2.1937e-02], dtype=torch.float64,\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_ts_params/amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8c835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.clear_grad()\n",
    "amp_val = model.get_amp_tn(sampled_x).contract()\n",
    "amp_val.backward(retain_graph=True)\n",
    "grad_vec0 = []\n",
    "for param in model.parameters():\n",
    "    if param.grad is None:\n",
    "        # print(None)\n",
    "        ...\n",
    "    else:\n",
    "        # print(param.grad/amp_val)\n",
    "        grad_vec0.append(param.grad/amp_val)\n",
    "model.clear_grad()\n",
    "# grad_vec0\n",
    "# print(model.get_amp_tn(sampled_x).contract())\n",
    "max_g = 0\n",
    "for grad_ts in grad_vec0:\n",
    "    if grad_ts is not None:\n",
    "        max_g = max(max_g, torch.max(torch.abs(grad_ts)))\n",
    "print('Max grad:', max_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b7ca0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reused Amp val: -6.077216771498784e+23, Exact Amp val: -6.077216771498737e+23, Rel error: 7.729887967846e-15\n",
      "Max grad: tensor(2.0198, dtype=torch.float64, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "model.clear_grad()\n",
    "# config_2d = model.from_1d_to_2d(sampled_x)\n",
    "# model._env_x_cache = None\n",
    "# model._env_y_cache = None\n",
    "model.cache_env_mode = True\n",
    "amp0 = model(sampled_x)\n",
    "# key_bot = ('xmax', tuple(torch.cat(tuple(config_2d[model.Lx//2:].to(torch.int))).tolist()))\n",
    "# key_top = ('xmin', tuple(torch.cat(tuple(config_2d[:model.Lx//2].to(torch.int))).tolist()))\n",
    "# amp_bot = model.env_x_cache[key_bot]\n",
    "# amp_top = model.env_x_cache[key_top]\n",
    "# amp_val = (amp_bot|amp_top).contract()*10**(model.skeleton.exponent)\n",
    "# amp_val.backward(retain_graph=True)\n",
    "amp0.backward(retain_graph=True)\n",
    "\n",
    "# amp_tn = model.get_amp_tn(sampled_x)\n",
    "# amp = amp_tn.contract_boundary_from_xmin(max_bond=model.max_bond, cutoff=0.0, xrange=[0, model.Lx//2-1])\n",
    "# amp = amp.contract_boundary_from_xmax(max_bond=model.max_bond, cutoff=0.0, xrange=[model.Lx//2, model.Lx-1])\n",
    "# amp_val1 = amp.contract()\n",
    "# amp_val1.backward(retain_graph=True)\n",
    "\n",
    "grad_vec1 = []\n",
    "for param in model.parameters():\n",
    "    if param.grad is None:\n",
    "        # print(None)\n",
    "        ...\n",
    "    else:\n",
    "        # print(param.grad/amp0)\n",
    "        grad_vec1.append(param.grad/amp0)\n",
    "\n",
    "model.clear_grad()\n",
    "max_g = 0\n",
    "for grad_ts in grad_vec1:\n",
    "    if grad_ts is not None:\n",
    "        max_g = max(max_g, torch.max(torch.abs(grad_ts)))\n",
    "print('Max grad:', max_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ecb8ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "grad_vec0[0]-grad_vec1[0]: 0.00%\n",
      "grad_vec0[1]-grad_vec1[1]: 0.00%\n",
      "grad_vec0[2]-grad_vec1[2]: 0.00%\n",
      "grad_vec0[3]-grad_vec1[3]: 0.00%\n",
      "grad_vec0[4]-grad_vec1[4]: 0.00%\n",
      "grad_vec0[5]-grad_vec1[5]: 0.00%\n",
      "grad_vec0[6]-grad_vec1[6]: 0.00%\n",
      "grad_vec0[7]-grad_vec1[7]: 0.00%\n",
      "grad_vec0[8]-grad_vec1[8]: 0.00%\n",
      "grad_vec0[9]-grad_vec1[9]: 0.00%\n",
      "grad_vec0[10]-grad_vec1[10]: 0.00%\n",
      "grad_vec0[11]-grad_vec1[11]: 0.00%\n",
      "grad_vec0[12]-grad_vec1[12]: 0.00%\n",
      "grad_vec0[13]-grad_vec1[13]: 0.00%\n",
      "grad_vec0[14]-grad_vec1[14]: 0.00%\n",
      "grad_vec0[15]-grad_vec1[15]: 0.00%\n",
      "grad_vec0[16]-grad_vec1[16]: 0.00%\n",
      "grad_vec0[17]-grad_vec1[17]: 0.00%\n",
      "grad_vec0[18]-grad_vec1[18]: 0.00%\n",
      "grad_vec0[19]-grad_vec1[19]: 0.00%\n",
      "grad_vec0[20]-grad_vec1[20]: 0.00%\n",
      "grad_vec0[21]-grad_vec1[21]: 0.00%\n",
      "grad_vec0[22]-grad_vec1[22]: 0.00%\n",
      "grad_vec0[23]-grad_vec1[23]: 0.00%\n",
      "grad_vec0[24]-grad_vec1[24]: 0.00%\n",
      "grad_vec0[25]-grad_vec1[25]: 0.00%\n",
      "grad_vec0[26]-grad_vec1[26]: 0.00%\n",
      "grad_vec0[27]-grad_vec1[27]: 0.00%\n",
      "grad_vec0[28]-grad_vec1[28]: 0.00%\n",
      "grad_vec0[29]-grad_vec1[29]: 0.00%\n",
      "grad_vec0[30]-grad_vec1[30]: 0.00%\n",
      "grad_vec0[31]-grad_vec1[31]: 0.00%\n",
      "grad_vec0[32]-grad_vec1[32]: 0.00%\n",
      "grad_vec0[33]-grad_vec1[33]: 0.00%\n",
      "grad_vec0[34]-grad_vec1[34]: 0.00%\n",
      "grad_vec0[35]-grad_vec1[35]: 0.00%\n",
      "grad_vec0[36]-grad_vec1[36]: 0.00%\n",
      "grad_vec0[37]-grad_vec1[37]: 0.00%\n",
      "grad_vec0[38]-grad_vec1[38]: 0.00%\n",
      "grad_vec0[39]-grad_vec1[39]: 0.00%\n",
      "grad_vec0[40]-grad_vec1[40]: 0.00%\n",
      "grad_vec0[41]-grad_vec1[41]: 0.00%\n",
      "grad_vec0[42]-grad_vec1[42]: 0.00%\n",
      "grad_vec0[43]-grad_vec1[43]: 0.00%\n",
      "grad_vec0[44]-grad_vec1[44]: 0.00%\n",
      "grad_vec0[45]-grad_vec1[45]: 0.00%\n",
      "grad_vec0[46]-grad_vec1[46]: 0.00%\n",
      "grad_vec0[47]-grad_vec1[47]: 0.00%\n",
      "grad_vec0[48]-grad_vec1[48]: 0.00%\n",
      "grad_vec0[49]-grad_vec1[49]: 0.00%\n",
      "grad_vec0[50]-grad_vec1[50]: 0.00%\n",
      "grad_vec0[51]-grad_vec1[51]: 0.00%\n",
      "grad_vec0[52]-grad_vec1[52]: 0.00%\n",
      "grad_vec0[53]-grad_vec1[53]: 0.00%\n",
      "grad_vec0[54]-grad_vec1[54]: 0.00%\n",
      "grad_vec0[55]-grad_vec1[55]: 0.00%\n",
      "grad_vec0[56]-grad_vec1[56]: 0.00%\n",
      "grad_vec0[57]-grad_vec1[57]: 0.00%\n",
      "grad_vec0[58]-grad_vec1[58]: 0.00%\n",
      "grad_vec0[59]-grad_vec1[59]: 0.00%\n",
      "grad_vec0[60]-grad_vec1[60]: 0.00%\n",
      "grad_vec0[61]-grad_vec1[61]: 0.00%\n",
      "grad_vec0[62]-grad_vec1[62]: 0.00%\n",
      "grad_vec0[63]-grad_vec1[63]: 0.00%\n",
      "grad_vec0[64]-grad_vec1[64]: 0.00%\n",
      "grad_vec0[65]-grad_vec1[65]: 0.00%\n",
      "grad_vec0[66]-grad_vec1[66]: 0.00%\n",
      "grad_vec0[67]-grad_vec1[67]: 0.00%\n",
      "grad_vec0[68]-grad_vec1[68]: 0.00%\n",
      "grad_vec0[69]-grad_vec1[69]: 0.00%\n",
      "grad_vec0[70]-grad_vec1[70]: 0.00%\n",
      "grad_vec0[71]-grad_vec1[71]: 0.00%\n",
      "grad_vec0[72]-grad_vec1[72]: 0.00%\n",
      "grad_vec0[73]-grad_vec1[73]: 0.00%\n",
      "grad_vec0[74]-grad_vec1[74]: 0.00%\n",
      "grad_vec0[75]-grad_vec1[75]: 0.00%\n",
      "grad_vec0[76]-grad_vec1[76]: 0.00%\n",
      "grad_vec0[77]-grad_vec1[77]: 0.00%\n",
      "grad_vec0[78]-grad_vec1[78]: 0.00%\n",
      "grad_vec0[79]-grad_vec1[79]: 0.00%\n",
      "grad_vec0[80]-grad_vec1[80]: 0.00%\n",
      "grad_vec0[81]-grad_vec1[81]: 0.00%\n",
      "grad_vec0[82]-grad_vec1[82]: 0.00%\n",
      "grad_vec0[83]-grad_vec1[83]: 0.00%\n",
      "grad_vec0[84]-grad_vec1[84]: 0.00%\n",
      "grad_vec0[85]-grad_vec1[85]: 0.00%\n",
      "grad_vec0[86]-grad_vec1[86]: 0.00%\n",
      "grad_vec0[87]-grad_vec1[87]: 0.00%\n",
      "grad_vec0[88]-grad_vec1[88]: 0.00%\n",
      "grad_vec0[89]-grad_vec1[89]: 0.00%\n",
      "grad_vec0[90]-grad_vec1[90]: 0.00%\n",
      "grad_vec0[91]-grad_vec1[91]: 0.00%\n",
      "grad_vec0[92]-grad_vec1[92]: 0.00%\n",
      "grad_vec0[93]-grad_vec1[93]: 0.00%\n",
      "grad_vec0[94]-grad_vec1[94]: 0.00%\n",
      "grad_vec0[95]-grad_vec1[95]: 0.00%\n",
      "grad_vec0[96]-grad_vec1[96]: 0.00%\n",
      "grad_vec0[97]-grad_vec1[97]: 0.00%\n",
      "grad_vec0[98]-grad_vec1[98]: 0.00%\n",
      "grad_vec0[99]-grad_vec1[99]: 0.00%\n",
      "grad_vec0[100]-grad_vec1[100]: 0.00%\n",
      "grad_vec0[101]-grad_vec1[101]: 0.00%\n",
      "grad_vec0[102]-grad_vec1[102]: 0.00%\n",
      "grad_vec0[103]-grad_vec1[103]: 0.00%\n",
      "grad_vec0[104]-grad_vec1[104]: 0.00%\n",
      "grad_vec0[105]-grad_vec1[105]: 0.00%\n",
      "grad_vec0[106]-grad_vec1[106]: 0.00%\n",
      "grad_vec0[107]-grad_vec1[107]: 0.00%\n",
      "grad_vec0[108]-grad_vec1[108]: 0.00%\n",
      "grad_vec0[109]-grad_vec1[109]: 0.00%\n",
      "grad_vec0[110]-grad_vec1[110]: 0.00%\n",
      "grad_vec0[111]-grad_vec1[111]: 0.00%\n",
      "grad_vec0[112]-grad_vec1[112]: 0.00%\n",
      "grad_vec0[113]-grad_vec1[113]: 0.00%\n",
      "grad_vec0[114]-grad_vec1[114]: 0.00%\n",
      "grad_vec0[115]-grad_vec1[115]: 0.00%\n",
      "grad_vec0[116]-grad_vec1[116]: 0.00%\n",
      "grad_vec0[117]-grad_vec1[117]: 0.00%\n",
      "grad_vec0[118]-grad_vec1[118]: 0.00%\n",
      "grad_vec0[119]-grad_vec1[119]: 0.00%\n",
      "grad_vec0[120]-grad_vec1[120]: 0.00%\n",
      "grad_vec0[121]-grad_vec1[121]: 0.00%\n",
      "grad_vec0[122]-grad_vec1[122]: 0.00%\n",
      "grad_vec0[123]-grad_vec1[123]: 0.00%\n",
      "grad_vec0[124]-grad_vec1[124]: 0.00%\n",
      "grad_vec0[125]-grad_vec1[125]: 0.00%\n",
      "grad_vec0[126]-grad_vec1[126]: 0.00%\n",
      "grad_vec0[127]-grad_vec1[127]: 0.00%\n",
      "grad_vec0[128]-grad_vec1[128]: 0.00%\n",
      "grad_vec0[129]-grad_vec1[129]: 0.00%\n",
      "grad_vec0[130]-grad_vec1[130]: 0.00%\n",
      "grad_vec0[131]-grad_vec1[131]: 0.00%\n",
      "grad_vec0[132]-grad_vec1[132]: 0.00%\n",
      "grad_vec0[133]-grad_vec1[133]: 0.00%\n",
      "grad_vec0[134]-grad_vec1[134]: 0.00%\n",
      "grad_vec0[135]-grad_vec1[135]: 0.00%\n",
      "grad_vec0[136]-grad_vec1[136]: 0.00%\n",
      "grad_vec0[137]-grad_vec1[137]: 0.00%\n",
      "grad_vec0[138]-grad_vec1[138]: 0.00%\n",
      "grad_vec0[139]-grad_vec1[139]: 0.00%\n",
      "grad_vec0[140]-grad_vec1[140]: 0.00%\n",
      "grad_vec0[141]-grad_vec1[141]: 0.00%\n",
      "grad_vec0[142]-grad_vec1[142]: 0.00%\n",
      "grad_vec0[143]-grad_vec1[143]: 0.00%\n",
      "grad_vec0[144]-grad_vec1[144]: 0.00%\n",
      "grad_vec0[145]-grad_vec1[145]: 0.00%\n",
      "grad_vec0[146]-grad_vec1[146]: 0.00%\n",
      "grad_vec0[147]-grad_vec1[147]: 0.00%\n",
      "grad_vec0[148]-grad_vec1[148]: 0.00%\n",
      "grad_vec0[149]-grad_vec1[149]: 0.00%\n",
      "grad_vec0[150]-grad_vec1[150]: 0.00%\n",
      "grad_vec0[151]-grad_vec1[151]: 0.00%\n",
      "grad_vec0[152]-grad_vec1[152]: 0.00%\n",
      "grad_vec0[153]-grad_vec1[153]: 0.00%\n",
      "grad_vec0[154]-grad_vec1[154]: 0.00%\n",
      "grad_vec0[155]-grad_vec1[155]: 0.00%\n",
      "grad_vec0[156]-grad_vec1[156]: 0.00%\n",
      "grad_vec0[157]-grad_vec1[157]: 0.00%\n",
      "grad_vec0[158]-grad_vec1[158]: 0.00%\n",
      "grad_vec0[159]-grad_vec1[159]: 0.00%\n",
      "grad_vec0[160]-grad_vec1[160]: 0.00%\n",
      "grad_vec0[161]-grad_vec1[161]: 0.00%\n",
      "grad_vec0[162]-grad_vec1[162]: 0.00%\n",
      "grad_vec0[163]-grad_vec1[163]: 0.00%\n",
      "grad_vec0[164]-grad_vec1[164]: 0.00%\n",
      "grad_vec0[165]-grad_vec1[165]: 0.00%\n",
      "grad_vec0[166]-grad_vec1[166]: 0.00%\n",
      "grad_vec0[167]-grad_vec1[167]: 0.00%\n",
      "grad_vec0[168]-grad_vec1[168]: 0.00%\n",
      "grad_vec0[169]-grad_vec1[169]: 0.00%\n",
      "grad_vec0[170]-grad_vec1[170]: 0.00%\n",
      "grad_vec0[171]-grad_vec1[171]: 0.00%\n",
      "grad_vec0[172]-grad_vec1[172]: 0.00%\n",
      "grad_vec0[173]-grad_vec1[173]: 0.00%\n",
      "grad_vec0[174]-grad_vec1[174]: 0.00%\n",
      "grad_vec0[175]-grad_vec1[175]: 0.00%\n",
      "grad_vec0[176]-grad_vec1[176]: 0.00%\n",
      "grad_vec0[177]-grad_vec1[177]: 0.00%\n",
      "grad_vec0[178]-grad_vec1[178]: 0.00%\n",
      "grad_vec0[179]-grad_vec1[179]: 0.00%\n",
      "grad_vec0[180]-grad_vec1[180]: 0.00%\n",
      "grad_vec0[181]-grad_vec1[181]: 0.00%\n",
      "grad_vec0[182]-grad_vec1[182]: 0.00%\n",
      "grad_vec0[183]-grad_vec1[183]: 0.00%\n",
      "grad_vec0[184]-grad_vec1[184]: 0.00%\n",
      "grad_vec0[185]-grad_vec1[185]: 0.00%\n",
      "grad_vec0[186]-grad_vec1[186]: 0.00%\n",
      "grad_vec0[187]-grad_vec1[187]: 0.00%\n",
      "grad_vec0[188]-grad_vec1[188]: 0.00%\n",
      "grad_vec0[189]-grad_vec1[189]: 0.00%\n",
      "grad_vec0[190]-grad_vec1[190]: 0.00%\n",
      "grad_vec0[191]-grad_vec1[191]: 0.00%\n",
      "grad_vec0[192]-grad_vec1[192]: 0.00%\n",
      "grad_vec0[193]-grad_vec1[193]: 0.00%\n",
      "grad_vec0[194]-grad_vec1[194]: 0.00%\n",
      "grad_vec0[195]-grad_vec1[195]: 0.00%\n",
      "grad_vec0[196]-grad_vec1[196]: 0.00%\n",
      "grad_vec0[197]-grad_vec1[197]: 0.00%\n",
      "grad_vec0[198]-grad_vec1[198]: 0.00%\n",
      "grad_vec0[199]-grad_vec1[199]: 0.00%\n",
      "grad_vec0[200]-grad_vec1[200]: 0.00%\n",
      "grad_vec0[201]-grad_vec1[201]: 0.00%\n",
      "grad_vec0[202]-grad_vec1[202]: 0.00%\n",
      "grad_vec0[203]-grad_vec1[203]: 0.00%\n",
      "grad_vec0[204]-grad_vec1[204]: 0.00%\n",
      "grad_vec0[205]-grad_vec1[205]: 0.00%\n",
      "grad_vec0[206]-grad_vec1[206]: 0.00%\n",
      "grad_vec0[207]-grad_vec1[207]: 0.00%\n",
      "grad_vec0[208]-grad_vec1[208]: 0.00%\n",
      "grad_vec0[209]-grad_vec1[209]: 0.00%\n",
      "grad_vec0[210]-grad_vec1[210]: 0.00%\n",
      "grad_vec0[211]-grad_vec1[211]: 0.00%\n",
      "grad_vec0[212]-grad_vec1[212]: 0.00%\n",
      "grad_vec0[213]-grad_vec1[213]: 0.00%\n",
      "grad_vec0[214]-grad_vec1[214]: 0.00%\n",
      "grad_vec0[215]-grad_vec1[215]: 0.00%\n",
      "grad_vec0[216]-grad_vec1[216]: 0.00%\n",
      "grad_vec0[217]-grad_vec1[217]: 0.00%\n",
      "grad_vec0[218]-grad_vec1[218]: 0.00%\n",
      "grad_vec0[219]-grad_vec1[219]: 0.00%\n",
      "grad_vec0[220]-grad_vec1[220]: 0.00%\n",
      "grad_vec0[221]-grad_vec1[221]: 0.00%\n",
      "grad_vec0[222]-grad_vec1[222]: 0.00%\n",
      "grad_vec0[223]-grad_vec1[223]: 0.00%\n",
      "grad_vec0[224]-grad_vec1[224]: 0.00%\n",
      "grad_vec0[225]-grad_vec1[225]: 0.00%\n",
      "grad_vec0[226]-grad_vec1[226]: 0.00%\n",
      "grad_vec0[227]-grad_vec1[227]: 0.00%\n",
      "grad_vec0[228]-grad_vec1[228]: 0.00%\n",
      "grad_vec0[229]-grad_vec1[229]: 0.00%\n",
      "grad_vec0[230]-grad_vec1[230]: 0.00%\n",
      "grad_vec0[231]-grad_vec1[231]: 0.00%\n",
      "grad_vec0[232]-grad_vec1[232]: 0.00%\n",
      "grad_vec0[233]-grad_vec1[233]: 0.00%\n",
      "grad_vec0[234]-grad_vec1[234]: 0.00%\n",
      "grad_vec0[235]-grad_vec1[235]: 0.00%\n",
      "grad_vec0[236]-grad_vec1[236]: 0.00%\n",
      "grad_vec0[237]-grad_vec1[237]: 0.00%\n",
      "grad_vec0[238]-grad_vec1[238]: 0.00%\n",
      "grad_vec0[239]-grad_vec1[239]: 0.00%\n",
      "grad_vec0[240]-grad_vec1[240]: 0.00%\n",
      "grad_vec0[241]-grad_vec1[241]: 0.00%\n",
      "grad_vec0[242]-grad_vec1[242]: 0.00%\n",
      "grad_vec0[243]-grad_vec1[243]: 0.00%\n",
      "grad_vec0[244]-grad_vec1[244]: 0.00%\n",
      "grad_vec0[245]-grad_vec1[245]: 0.00%\n",
      "grad_vec0[246]-grad_vec1[246]: 0.00%\n",
      "grad_vec0[247]-grad_vec1[247]: 0.00%\n",
      "grad_vec0[248]-grad_vec1[248]: 0.00%\n",
      "grad_vec0[249]-grad_vec1[249]: 0.00%\n",
      "grad_vec0[250]-grad_vec1[250]: 0.00%\n",
      "grad_vec0[251]-grad_vec1[251]: 0.00%\n",
      "grad_vec0[252]-grad_vec1[252]: 0.00%\n",
      "grad_vec0[253]-grad_vec1[253]: 0.00%\n",
      "grad_vec0[254]-grad_vec1[254]: 0.00%\n",
      "grad_vec0[255]-grad_vec1[255]: 0.00%\n",
      "grad_vec0[256]-grad_vec1[256]: 0.00%\n",
      "grad_vec0[257]-grad_vec1[257]: 0.00%\n",
      "grad_vec0[258]-grad_vec1[258]: 0.00%\n",
      "grad_vec0[259]-grad_vec1[259]: 0.00%\n",
      "grad_vec0[260]-grad_vec1[260]: 0.00%\n",
      "grad_vec0[261]-grad_vec1[261]: 0.00%\n",
      "grad_vec0[262]-grad_vec1[262]: 0.00%\n",
      "grad_vec0[263]-grad_vec1[263]: 0.00%\n",
      "grad_vec0[264]-grad_vec1[264]: 0.00%\n",
      "grad_vec0[265]-grad_vec1[265]: 0.00%\n",
      "grad_vec0[266]-grad_vec1[266]: 0.00%\n",
      "grad_vec0[267]-grad_vec1[267]: 0.00%\n",
      "grad_vec0[268]-grad_vec1[268]: 0.00%\n",
      "grad_vec0[269]-grad_vec1[269]: 0.00%\n",
      "grad_vec0[270]-grad_vec1[270]: 0.00%\n",
      "grad_vec0[271]-grad_vec1[271]: 0.00%\n",
      "grad_vec0[272]-grad_vec1[272]: 0.00%\n",
      "grad_vec0[273]-grad_vec1[273]: 0.00%\n",
      "grad_vec0[274]-grad_vec1[274]: 0.00%\n",
      "grad_vec0[275]-grad_vec1[275]: 0.00%\n",
      "grad_vec0[276]-grad_vec1[276]: 0.00%\n",
      "grad_vec0[277]-grad_vec1[277]: 0.00%\n",
      "grad_vec0[278]-grad_vec1[278]: 0.00%\n",
      "grad_vec0[279]-grad_vec1[279]: 0.00%\n",
      "grad_vec0[280]-grad_vec1[280]: 0.00%\n",
      "grad_vec0[281]-grad_vec1[281]: 0.00%\n",
      "grad_vec0[282]-grad_vec1[282]: 0.00%\n",
      "grad_vec0[283]-grad_vec1[283]: 0.00%\n",
      "grad_vec0[284]-grad_vec1[284]: 0.00%\n",
      "grad_vec0[285]-grad_vec1[285]: 0.00%\n",
      "grad_vec0[286]-grad_vec1[286]: 0.00%\n",
      "grad_vec0[287]-grad_vec1[287]: 0.00%\n",
      "grad_vec0[288]-grad_vec1[288]: 0.00%\n",
      "grad_vec0[289]-grad_vec1[289]: 0.00%\n",
      "grad_vec0[290]-grad_vec1[290]: 0.00%\n",
      "grad_vec0[291]-grad_vec1[291]: 0.00%\n",
      "grad_vec0[292]-grad_vec1[292]: 0.00%\n",
      "grad_vec0[293]-grad_vec1[293]: 0.00%\n",
      "grad_vec0[294]-grad_vec1[294]: 0.00%\n",
      "grad_vec0[295]-grad_vec1[295]: 0.00%\n",
      "grad_vec0[296]-grad_vec1[296]: 0.00%\n",
      "grad_vec0[297]-grad_vec1[297]: 0.00%\n",
      "grad_vec0[298]-grad_vec1[298]: 0.00%\n",
      "grad_vec0[299]-grad_vec1[299]: 0.00%\n",
      "grad_vec0[300]-grad_vec1[300]: 0.00%\n",
      "grad_vec0[301]-grad_vec1[301]: 0.00%\n",
      "grad_vec0[302]-grad_vec1[302]: 0.00%\n",
      "grad_vec0[303]-grad_vec1[303]: 0.00%\n",
      "grad_vec0[304]-grad_vec1[304]: 0.00%\n",
      "grad_vec0[305]-grad_vec1[305]: 0.00%\n",
      "grad_vec0[306]-grad_vec1[306]: 0.00%\n",
      "grad_vec0[307]-grad_vec1[307]: 0.00%\n",
      "grad_vec0[308]-grad_vec1[308]: 0.00%\n",
      "grad_vec0[309]-grad_vec1[309]: 0.00%\n",
      "grad_vec0[310]-grad_vec1[310]: 0.00%\n",
      "grad_vec0[311]-grad_vec1[311]: 0.00%\n",
      "grad_vec0[312]-grad_vec1[312]: 0.00%\n",
      "grad_vec0[313]-grad_vec1[313]: 0.00%\n",
      "grad_vec0[314]-grad_vec1[314]: 0.00%\n",
      "grad_vec0[315]-grad_vec1[315]: 0.00%\n",
      "grad_vec0[316]-grad_vec1[316]: 0.00%\n",
      "grad_vec0[317]-grad_vec1[317]: 0.00%\n",
      "grad_vec0[318]-grad_vec1[318]: 0.00%\n",
      "grad_vec0[319]-grad_vec1[319]: 0.00%\n",
      "grad_vec0[320]-grad_vec1[320]: 0.00%\n",
      "grad_vec0[321]-grad_vec1[321]: 0.00%\n",
      "grad_vec0[322]-grad_vec1[322]: 0.00%\n",
      "grad_vec0[323]-grad_vec1[323]: 0.00%\n",
      "grad_vec0[324]-grad_vec1[324]: 0.00%\n",
      "grad_vec0[325]-grad_vec1[325]: 0.00%\n",
      "grad_vec0[326]-grad_vec1[326]: 0.00%\n",
      "grad_vec0[327]-grad_vec1[327]: 0.00%\n",
      "grad_vec0[328]-grad_vec1[328]: 0.00%\n",
      "grad_vec0[329]-grad_vec1[329]: 0.00%\n",
      "grad_vec0[330]-grad_vec1[330]: 0.00%\n",
      "grad_vec0[331]-grad_vec1[331]: 0.00%\n",
      "grad_vec0[332]-grad_vec1[332]: 0.00%\n",
      "grad_vec0[333]-grad_vec1[333]: 0.00%\n",
      "grad_vec0[334]-grad_vec1[334]: 0.00%\n",
      "grad_vec0[335]-grad_vec1[335]: 0.00%\n",
      "grad_vec0[336]-grad_vec1[336]: 0.00%\n",
      "grad_vec0[337]-grad_vec1[337]: 0.00%\n",
      "grad_vec0[338]-grad_vec1[338]: 0.00%\n",
      "grad_vec0[339]-grad_vec1[339]: 0.00%\n",
      "grad_vec0[340]-grad_vec1[340]: 0.00%\n",
      "grad_vec0[341]-grad_vec1[341]: 0.00%\n",
      "grad_vec0[342]-grad_vec1[342]: 0.00%\n",
      "grad_vec0[343]-grad_vec1[343]: 0.00%\n",
      "grad_vec0[344]-grad_vec1[344]: 0.00%\n",
      "grad_vec0[345]-grad_vec1[345]: 0.00%\n",
      "grad_vec0[346]-grad_vec1[346]: 0.00%\n",
      "grad_vec0[347]-grad_vec1[347]: 0.00%\n",
      "grad_vec0[348]-grad_vec1[348]: 0.00%\n",
      "grad_vec0[349]-grad_vec1[349]: 0.00%\n",
      "grad_vec0[350]-grad_vec1[350]: 0.00%\n",
      "grad_vec0[351]-grad_vec1[351]: 0.00%\n",
      "grad_vec0[352]-grad_vec1[352]: 0.00%\n",
      "grad_vec0[353]-grad_vec1[353]: 0.00%\n",
      "grad_vec0[354]-grad_vec1[354]: 0.00%\n",
      "grad_vec0[355]-grad_vec1[355]: 0.00%\n",
      "grad_vec0[356]-grad_vec1[356]: 0.00%\n",
      "grad_vec0[357]-grad_vec1[357]: 0.00%\n",
      "grad_vec0[358]-grad_vec1[358]: 0.00%\n",
      "grad_vec0[359]-grad_vec1[359]: 0.00%\n",
      "grad_vec0[360]-grad_vec1[360]: 0.00%\n",
      "grad_vec0[361]-grad_vec1[361]: 0.00%\n",
      "grad_vec0[362]-grad_vec1[362]: 0.00%\n",
      "grad_vec0[363]-grad_vec1[363]: 0.00%\n",
      "grad_vec0[364]-grad_vec1[364]: 0.00%\n",
      "grad_vec0[365]-grad_vec1[365]: 0.00%\n",
      "grad_vec0[366]-grad_vec1[366]: 0.00%\n",
      "grad_vec0[367]-grad_vec1[367]: 0.00%\n",
      "grad_vec0[368]-grad_vec1[368]: 0.00%\n",
      "grad_vec0[369]-grad_vec1[369]: 0.00%\n",
      "grad_vec0[370]-grad_vec1[370]: 0.00%\n",
      "grad_vec0[371]-grad_vec1[371]: 0.00%\n",
      "grad_vec0[372]-grad_vec1[372]: 0.00%\n",
      "grad_vec0[373]-grad_vec1[373]: 0.00%\n",
      "grad_vec0[374]-grad_vec1[374]: 0.00%\n",
      "grad_vec0[375]-grad_vec1[375]: 0.00%\n",
      "grad_vec0[376]-grad_vec1[376]: 0.00%\n",
      "grad_vec0[377]-grad_vec1[377]: 0.00%\n",
      "grad_vec0[378]-grad_vec1[378]: 0.00%\n",
      "grad_vec0[379]-grad_vec1[379]: 0.00%\n",
      "grad_vec0[380]-grad_vec1[380]: 0.00%\n",
      "grad_vec0[381]-grad_vec1[381]: 0.00%\n",
      "grad_vec0[382]-grad_vec1[382]: 0.00%\n",
      "grad_vec0[383]-grad_vec1[383]: 0.00%\n",
      "grad_vec0[384]-grad_vec1[384]: 0.00%\n",
      "grad_vec0[385]-grad_vec1[385]: 0.00%\n",
      "grad_vec0[386]-grad_vec1[386]: 0.00%\n",
      "grad_vec0[387]-grad_vec1[387]: 0.00%\n",
      "grad_vec0[388]-grad_vec1[388]: 0.00%\n",
      "grad_vec0[389]-grad_vec1[389]: 0.00%\n",
      "grad_vec0[390]-grad_vec1[390]: 0.00%\n",
      "grad_vec0[391]-grad_vec1[391]: 0.00%\n"
     ]
    }
   ],
   "source": [
    "print(torch.allclose(amp0, amp_val))\n",
    "for i in range(len(grad_vec1)):\n",
    "    # show rel err in percentage\n",
    "    print(f'grad_vec0[{i}]-grad_vec1[{i}]: {torch.norm(grad_vec0[i]-grad_vec1[i])/torch.norm(grad_vec0[i]) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25d0820e",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_rel_err = 0.0\n",
    "for rel_contraction_err in model.debug_amp_cache:\n",
    "    average_rel_err += rel_contraction_err[2]\n",
    "average_rel_err /= len(model.debug_amp_cache)\n",
    "# print(f\"Average relative contraction error: {average_rel_err} for D={D}, chi={chi}, time={t1-t0:.2f}s, Lx={Lx}, Ly={Ly}, symmetry={symmetry}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74d1a40",
   "metadata": {},
   "source": [
    "Average relative contraction error: 1.7202865340398485 for D=4, chi=16, time=14.22s, Lx=8, Ly=8, symmetry=Z2\n",
    "Average relative contraction error: 1.374601678306499 for D=4, chi=64, time=16.01s, Lx=8, Ly=8, symmetry=Z2\n",
    "Average relative contraction error: 0.10715998841340528 for D=4, chi=128, time=15.06s, Lx=8, Ly=8, symmetry=Z2\n",
    "Average relative contraction error: 0.0748252922749927 for D=4, chi=160, time=15.44s, Lx=8, Ly=8, symmetry=Z2\n",
    "Average relative contraction error: 8.601565829643471e-14 for D=4, chi=256, time=16.54s, Lx=8, Ly=8, symmetry=Z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a499fbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F=8.52 C=9.27 S=22.00 P=22.32: 100%|| 10/10 [00:00<00:00, 19.96it/s] \n"
     ]
    }
   ],
   "source": [
    "# fPEPS w/o reuse\n",
    "model1 = fTNModel(peps, max_bond=-1, dtype=dtype)\n",
    "vstate1 = Variational_State(model1, hi=H.hilbert, sampler=sampler, dtype=dtype)\n",
    "amp1, grad1 = vstate1.amplitude_grad(sampled_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530d80e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Gradients are not equal: 0.04582833351407129",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m torch.norm(grad-grad1)<\u001b[32m10\u001b[39m**(-\u001b[32m3\u001b[39m)*torch.norm(grad1), \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mGradients are not equal: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch.norm(grad-grad1)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m torch.norm(amp-amp1)<\u001b[32m10\u001b[39m**(-\u001b[32m3\u001b[39m)*torch.norm(amp1), \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mAmplitudes are not equal w rel err: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch.norm(amp-amp1)/\u001b[38;5;250m \u001b[39mtorch.norm(amp1)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n",
      "\u001b[31mAssertionError\u001b[39m: Gradients are not equal: 0.04582833351407129"
     ]
    }
   ],
   "source": [
    "assert torch.norm(grad-grad1)<10**(-3)*torch.norm(grad1), f'Gradients are not equal: {torch.norm(grad-grad1)}'\n",
    "assert torch.norm(amp-amp1)<10**(-3)*torch.norm(amp1), f'Amplitudes are not equal w rel err: {torch.norm(amp-amp1)/ torch.norm(amp1)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488868ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0010, dtype=torch.float64, grad_fn=<DivBackward0>),\n",
       " tensor(0.0058, dtype=torch.float64, grad_fn=<DivBackward0>))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(amp-amp1)/torch.norm(amp1), torch.norm(grad-grad1)/torch.norm(grad1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc41592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local energy with reuse: 117.2844806950575\n",
      "Local energy w/o reuse: 117.3802497272778\n"
     ]
    }
   ],
   "source": [
    "# local energy w reuse\n",
    "op = H\n",
    "sigma = sampled_x\n",
    "psi_sigma = amp\n",
    "eta, O_etasigma = op.get_conn(sigma)\n",
    "psi_eta = vstate.amplitude(eta)\n",
    "psi_sigma = psi_sigma.cpu().detach().numpy()\n",
    "psi_eta = psi_eta.cpu().detach().numpy()\n",
    "op_loc = np.sum(O_etasigma * (psi_eta / psi_sigma), axis=-1)\n",
    "print(f\"Local energy with reuse: {op_loc}\")\n",
    "\n",
    "# local energy w/o reuse\n",
    "op1 = H\n",
    "sigma1 = sampled_x\n",
    "psi_sigma1 = amp1\n",
    "eta1, O_etasigma1 = op1.get_conn(sigma1)\n",
    "psi_eta1 = vstate1.amplitude(eta1)\n",
    "psi_sigma1 = psi_sigma1.cpu().detach().numpy()\n",
    "psi_eta1 = psi_eta1.cpu().detach().numpy()\n",
    "op_loc1 = np.sum(O_etasigma1 * (psi_eta1 / psi_sigma1), axis=-1)\n",
    "print(f\"Local energy w/o reuse: {op_loc1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c20819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: [(0, 1), (1, 2), (2, 3), (3, 4), (4, 5)],\n",
       "  1: [(6, 7), (7, 8), (8, 9), (9, 10), (10, 11)],\n",
       "  2: [(12, 13), (13, 14), (14, 15), (15, 16), (16, 17)],\n",
       "  3: [(18, 19), (19, 20), (20, 21), (21, 22), (22, 23)],\n",
       "  4: [(24, 25), (25, 26), (26, 27), (27, 28), (28, 29)],\n",
       "  5: [(30, 31), (31, 32), (32, 33), (33, 34), (34, 35)]},\n",
       " {0: [(0, 6), (6, 12), (12, 18), (18, 24), (24, 30)],\n",
       "  1: [(1, 7), (7, 13), (13, 19), (19, 25), (25, 31)],\n",
       "  2: [(2, 8), (8, 14), (14, 20), (20, 26), (26, 32)],\n",
       "  3: [(3, 9), (9, 15), (15, 21), (21, 27), (27, 33)],\n",
       "  4: [(4, 10), (10, 16), (16, 22), (22, 28), (28, 34)],\n",
       "  5: [(5, 11), (11, 17), (17, 23), (23, 29), (29, 35)]},\n",
       " [(0, 1),\n",
       "  (0, 6),\n",
       "  (1, 2),\n",
       "  (1, 7),\n",
       "  (2, 3),\n",
       "  (2, 8),\n",
       "  (3, 4),\n",
       "  (3, 9),\n",
       "  (4, 5),\n",
       "  (4, 10),\n",
       "  (5, 11),\n",
       "  (6, 7),\n",
       "  (6, 12),\n",
       "  (7, 8),\n",
       "  (7, 13),\n",
       "  (8, 9),\n",
       "  (8, 14),\n",
       "  (9, 10),\n",
       "  (9, 15),\n",
       "  (10, 11),\n",
       "  (10, 16),\n",
       "  (11, 17),\n",
       "  (12, 13),\n",
       "  (12, 18),\n",
       "  (13, 14),\n",
       "  (13, 19),\n",
       "  (14, 15),\n",
       "  (14, 20),\n",
       "  (15, 16),\n",
       "  (15, 21),\n",
       "  (16, 17),\n",
       "  (16, 22),\n",
       "  (17, 23),\n",
       "  (18, 19),\n",
       "  (18, 24),\n",
       "  (19, 20),\n",
       "  (19, 25),\n",
       "  (20, 21),\n",
       "  (20, 26),\n",
       "  (21, 22),\n",
       "  (21, 27),\n",
       "  (22, 23),\n",
       "  (22, 28),\n",
       "  (23, 29),\n",
       "  (24, 25),\n",
       "  (24, 30),\n",
       "  (25, 26),\n",
       "  (25, 31),\n",
       "  (26, 27),\n",
       "  (26, 32),\n",
       "  (27, 28),\n",
       "  (27, 33),\n",
       "  (28, 29),\n",
       "  (28, 34),\n",
       "  (29, 35),\n",
       "  (30, 31),\n",
       "  (31, 32),\n",
       "  (32, 33),\n",
       "  (33, 34),\n",
       "  (34, 35)])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.row_edges, graph.col_edges, graph.edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0617047b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fTNModel_reuse(peps, max_bond=chi, dtype=dtype, functional=False)\n",
    "model.cache_env_mode = True\n",
    "model(random_x)\n",
    "model.cache_env_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8992aab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.0023186206817626953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "amp0 = model.get_amp_tn(random_x1)\n",
    "t1 = time.time()\n",
    "print(\"Time taken:\", t1 - t0)\n",
    "amp0.contract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b009c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.011317729949951172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "amp1 = model.get_amp_tn(random_x1, reconstruct=True)\n",
    "t1 = time.time()\n",
    "print(\"Time taken:\", t1 - t0)\n",
    "amp1.contract()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51453ae3",
   "metadata": {},
   "source": [
    "# mode = 'dm':\n",
    "ImportError: autoray couldn't find function 'argsort' for backend 'symmray'.\n",
    "\n",
    "##### TO-DO: need to implement eigh_truncate for fermionic tensors\n",
    "\n",
    "# mode = 'fit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad059164",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected FermionicArray, got <class 'numpy.ndarray'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mamp0\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontract_boundary_from_xmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxrange\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLx\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m.contract()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VMC/fermion/mpsds/mpsds/lib/python3.11/site-packages/quimb/tensor/tensor_2d.py:1996\u001b[39m, in \u001b[36mTensorNetwork2D.contract_boundary_from_xmax\u001b[39m\u001b[34m(self, xrange, yrange, max_bond, cutoff, canonize, mode, layer_tags, inplace, sweep_reverse, compress_opts, **contract_boundary_opts)\u001b[39m\n\u001b[32m   1898\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcontract_boundary_from_xmax\u001b[39m(\n\u001b[32m   1899\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1900\u001b[39m     xrange,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1911\u001b[39m     **contract_boundary_opts,\n\u001b[32m   1912\u001b[39m ):\n\u001b[32m   1913\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Contract a 2D tensor network inwards from the top, canonizing and\u001b[39;00m\n\u001b[32m   1914\u001b[39m \u001b[33;03m    compressing (right to left) along the way. If\u001b[39;00m\n\u001b[32m   1915\u001b[39m \u001b[33;03m    ``layer_tags is None`` this looks like::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1994\u001b[39m \u001b[33;03m    contract_boundary_from_ymax\u001b[39;00m\n\u001b[32m   1995\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1996\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcontract_boundary_from\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1997\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxrange\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxrange\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1998\u001b[39m \u001b[43m        \u001b[49m\u001b[43myrange\u001b[49m\u001b[43m=\u001b[49m\u001b[43myrange\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_which\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mxmax\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2001\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcanonize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcanonize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_tags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msweep_reverse\u001b[49m\u001b[43m=\u001b[49m\u001b[43msweep_reverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompress_opts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompress_opts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2007\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2008\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcontract_boundary_opts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2009\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VMC/fermion/mpsds/mpsds/lib/python3.11/site-packages/quimb/tensor/tensor_2d.py:1772\u001b[39m, in \u001b[36mTensorNetwork2D.contract_boundary_from\u001b[39m\u001b[34m(self, xrange, yrange, from_which, max_bond, cutoff, canonize, mode, layer_tags, sweep_reverse, compress_opts, inplace, **contract_boundary_opts)\u001b[39m\n\u001b[32m   1769\u001b[39m     tn._contract_boundary_core(**contract_boundary_opts)\n\u001b[32m   1770\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tn\n\u001b[32m-> \u001b[39m\u001b[32m1772\u001b[39m \u001b[43mtn\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_contract_boundary_core_via_1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1773\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcontract_boundary_opts\u001b[49m\n\u001b[32m   1774\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tn\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VMC/fermion/mpsds/mpsds/lib/python3.11/site-packages/quimb/tensor/tensor_2d.py:1320\u001b[39m, in \u001b[36mTensorNetwork2D._contract_boundary_core_via_1d\u001b[39m\u001b[34m(self, xrange, yrange, from_which, max_bond, cutoff, method, layer_tags, **compress_opts)\u001b[39m\n\u001b[32m   1312\u001b[39m                 \u001b[38;5;28mself\u001b[39m.add_tag(st, where=(tag1,), record=record)\n\u001b[32m   1313\u001b[39m                 \u001b[38;5;28mself\u001b[39m.add_tag(\n\u001b[32m   1314\u001b[39m                     st,\n\u001b[32m   1315\u001b[39m                     where=(tag2, layer_tag),\n\u001b[32m   1316\u001b[39m                     which=\u001b[33m\"\u001b[39m\u001b[33mall\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1317\u001b[39m                     record=record,\n\u001b[32m   1318\u001b[39m                 )\n\u001b[32m-> \u001b[39m\u001b[32m1320\u001b[39m         \u001b[43m_do_compress\u001b[49m\u001b[43m(\u001b[49m\u001b[43msite_tag_tmps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1322\u001b[39m \u001b[38;5;66;03m# rewind *all* the temporary tags\u001b[39;00m\n\u001b[32m   1323\u001b[39m \u001b[38;5;28mself\u001b[39m.drop_tags(site_tag_tmps)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VMC/fermion/mpsds/mpsds/lib/python3.11/site-packages/quimb/tensor/tensor_2d.py:1271\u001b[39m, in \u001b[36mTensorNetwork2D._contract_boundary_core_via_1d.<locals>._do_compress\u001b[39m\u001b[34m(site_tag_tmps)\u001b[39m\n\u001b[32m   1268\u001b[39m tn_boundary = \u001b[38;5;28mself\u001b[39m.partition(site_tag_tmps, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[32m1\u001b[39m]\n\u001b[32m   1270\u001b[39m \u001b[38;5;66;03m# compress it inplace\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1271\u001b[39m \u001b[43mtensor_network_1d_compress\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1272\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtn_boundary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1274\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1275\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1276\u001b[39m \u001b[43m    \u001b[49m\u001b[43msite_tags\u001b[49m\u001b[43m=\u001b[49m\u001b[43msite_tag_tmps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1277\u001b[39m \u001b[43m    \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1278\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcompress_opts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1279\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1281\u001b[39m \u001b[38;5;66;03m# recombine with the main network\u001b[39;00m\n\u001b[32m   1282\u001b[39m \u001b[38;5;28mself\u001b[39m.add_tensor_network(tn_boundary, virtual=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VMC/fermion/mpsds/mpsds/lib/python3.11/site-packages/quimb/tensor/tensor_1d_compress.py:1507\u001b[39m, in \u001b[36mtensor_network_1d_compress\u001b[39m\u001b[34m(tn, max_bond, cutoff, method, site_tags, canonize, permute_arrays, optimize, sweep_reverse, equalize_norms, compress_opts, inplace, **kwargs)\u001b[39m\n\u001b[32m   1504\u001b[39m f_tn1d = _TN1D_COMPRESS_METHODS.get(method, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1505\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m f_tn1d \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1506\u001b[39m     \u001b[38;5;66;03m# 1D specific compression methods\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1507\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf_tn1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1508\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1510\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1511\u001b[39m \u001b[43m        \u001b[49m\u001b[43msite_tags\u001b[49m\u001b[43m=\u001b[49m\u001b[43msite_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1512\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcanonize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcanonize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1513\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpermute_arrays\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpermute_arrays\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1514\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1515\u001b[39m \u001b[43m        \u001b[49m\u001b[43msweep_reverse\u001b[49m\u001b[43m=\u001b[49m\u001b[43msweep_reverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1516\u001b[39m \u001b[43m        \u001b[49m\u001b[43mequalize_norms\u001b[49m\u001b[43m=\u001b[49m\u001b[43mequalize_norms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1517\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1518\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcompress_opts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1519\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1520\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;66;03m# generic tensor network compression methods\u001b[39;00m\n\u001b[32m   1523\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sweep_reverse:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VMC/fermion/mpsds/mpsds/lib/python3.11/site-packages/quimb/tensor/tensor_1d_compress.py:1332\u001b[39m, in \u001b[36mtensor_network_1d_compress_fit\u001b[39m\u001b[34m(tns, max_bond, cutoff, tn_fit, bsz, initial_bond_dim, max_iterations, tol, site_tags, cutoff_mode, sweep_sequence, normalize, permute_arrays, optimize, canonize, sweep_reverse, equalize_norms, inplace_fit, inplace, progbar, **compress_opts)\u001b[39m\n\u001b[32m   1329\u001b[39m     current_bond_dim = \u001b[38;5;28mmin\u001b[39m(\u001b[32m2\u001b[39m * current_bond_dim, max_bond)\n\u001b[32m   1331\u001b[39m \u001b[38;5;66;03m# perform a single sweep\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1332\u001b[39m max_tdiff = \u001b[43mf_sweep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtn_fit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtn_overlaps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurrent_bond_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1337\u001b[39m \u001b[43m    \u001b[49m\u001b[43menvs\u001b[49m\u001b[43m=\u001b[49m\u001b[43menvs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1338\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprepare\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_direction\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mold_direction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[43m    \u001b[49m\u001b[43msite_tags\u001b[49m\u001b[43m=\u001b[49m\u001b[43msite_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1340\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreverse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1341\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1342\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompute_tdiff\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompute_tdiff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcompress_opts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1344\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1346\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m progbar:\n\u001b[32m   1347\u001b[39m     its.set_description(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmax_tdiff=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_tdiff\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VMC/fermion/mpsds/mpsds/lib/python3.11/site-packages/quimb/tensor/tensor_1d_compress.py:874\u001b[39m, in \u001b[36m_tn1d_fit_sum_sweep_1site\u001b[39m\u001b[34m(tn_fit, tn_overlaps, site_tags, max_bond, cutoff, envs, prepare, reverse, compute_tdiff, optimize)\u001b[39m\n\u001b[32m    872\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m k, tn_overlap \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tn_overlaps):\n\u001b[32m    873\u001b[39m             tni = envs[\u001b[33m\"\u001b[39m\u001b[33mR\u001b[39m\u001b[33m\"\u001b[39m, i + \u001b[32m1\u001b[39m, k] | tn_overlap.select(site_r)\n\u001b[32m--> \u001b[39m\u001b[32m874\u001b[39m             envs[\u001b[33m\"\u001b[39m\u001b[33mR\u001b[39m\u001b[33m\"\u001b[39m, i, k] = \u001b[43mtni\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontract\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mall\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    876\u001b[39m     \u001b[38;5;66;03m# move canonical center to right\u001b[39;00m\n\u001b[32m    877\u001b[39m     tn_fit.canonize_around_(site_tags[-\u001b[32m1\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VMC/fermion/mpsds/mpsds/lib/python3.11/site-packages/quimb/tensor/tensor_core.py:9283\u001b[39m, in \u001b[36mTensorNetwork.contract\u001b[39m\u001b[34m(self, tags, output_inds, optimize, get, max_bond, strip_exponent, preserve_tensor, backend, inplace, **kwargs)\u001b[39m\n\u001b[32m   9281\u001b[39m \u001b[38;5;66;03m# contracting everything to single output\u001b[39;00m\n\u001b[32m   9282\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m all_tags \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inplace:\n\u001b[32m-> \u001b[39m\u001b[32m9283\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_contract\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9284\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtensor_map\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9285\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrip_exponent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrip_exponent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9286\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexponent\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexponent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9287\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9288\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   9290\u001b[39m \u001b[38;5;66;03m# contract some or all tensors, but keeping tensor network\u001b[39;00m\n\u001b[32m   9291\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.contract_tags(\n\u001b[32m   9292\u001b[39m     tags, strip_exponent=strip_exponent, inplace=inplace, **kwargs\n\u001b[32m   9293\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/functools.py:909\u001b[39m, in \u001b[36msingledispatch.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires at least \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    907\u001b[39m                     \u001b[33m'\u001b[39m\u001b[33m1 positional argument\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m909\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VMC/fermion/mpsds/mpsds/lib/python3.11/site-packages/quimb/tensor/tensor_core.py:309\u001b[39m, in \u001b[36mtensor_contract\u001b[39m\u001b[34m(output_inds, optimize, get, backend, preserve_tensor, drop_tags, strip_exponent, exponent, *tensors, **contract_opts)\u001b[39m\n\u001b[32m    298\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_contract_get_other(\n\u001b[32m    299\u001b[39m         arrays=arrays,\n\u001b[32m    300\u001b[39m         inds=inds,\n\u001b[32m   (...)\u001b[39m\u001b[32m    305\u001b[39m         **contract_opts,\n\u001b[32m    306\u001b[39m     )\n\u001b[32m    308\u001b[39m \u001b[38;5;66;03m# perform the contraction!\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m data_out = \u001b[43marray_contract\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m    \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43minds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43minds_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrip_exponent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrip_exponent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcontract_opts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m strip_exponent:\n\u001b[32m    320\u001b[39m     \u001b[38;5;66;03m# mantissa and exponent returned separately\u001b[39;00m\n\u001b[32m    321\u001b[39m     data_out, result_exponent = data_out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VMC/fermion/mpsds/mpsds/lib/python3.11/site-packages/quimb/tensor/contraction.py:285\u001b[39m, in \u001b[36marray_contract\u001b[39m\u001b[34m(arrays, inputs, output, optimize, backend, **kwargs)\u001b[39m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    284\u001b[39m     backend = get_contract_backend()\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mctg\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray_contract\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m    \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VMC/fermion/mpsds/mpsds/lib/python3.11/site-packages/cotengra/interface.py:864\u001b[39m, in \u001b[36marray_contract\u001b[39m\u001b[34m(arrays, inputs, output, optimize, strip_exponent, cache_expression, backend, **kwargs)\u001b[39m\n\u001b[32m    854\u001b[39m shapes = \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(ar.shape, arrays))\n\u001b[32m    855\u001b[39m expr = array_contract_expression(\n\u001b[32m    856\u001b[39m     inputs,\n\u001b[32m    857\u001b[39m     output,\n\u001b[32m   (...)\u001b[39m\u001b[32m    862\u001b[39m     **kwargs,\n\u001b[32m    863\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m864\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexpr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VMC/fermion/mpsds/mpsds/lib/python3.11/site-packages/cotengra/contract.py:784\u001b[39m, in \u001b[36mContractor.__call__\u001b[39m\u001b[34m(self, *arrays, **kwargs)\u001b[39m\n\u001b[32m    781\u001b[39m r_array = temps.pop(r)\n\u001b[32m    783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tdot:\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m     p_array = \u001b[43m_tensordot\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    785\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m perm:\n\u001b[32m    786\u001b[39m         p_array = do(\u001b[33m\"\u001b[39m\u001b[33mtranspose\u001b[39m\u001b[33m\"\u001b[39m, p_array, perm, like=backend)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/functools.py:909\u001b[39m, in \u001b[36msingledispatch.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires at least \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    907\u001b[39m                     \u001b[33m'\u001b[39m\u001b[33m1 positional argument\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m909\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/VMC/fermion/mpsds/mpsds/lib/python3.11/site-packages/symmray/fermionic_core.py:840\u001b[39m, in \u001b[36mtensordot_fermionic\u001b[39m\u001b[34m(a, b, axes, preserve_array, **kwargs)\u001b[39m\n\u001b[32m    838\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m a * b\n\u001b[32m    839\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m840\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected FermionicArray, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(b)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    842\u001b[39m ndim_a, ndim_b = a.ndim, b.ndim\n\u001b[32m    843\u001b[39m left_axes, axes_a, axes_b, right_axes = parse_tensordot_axes(\n\u001b[32m    844\u001b[39m     axes, ndim_a, ndim_b\n\u001b[32m    845\u001b[39m )\n",
      "\u001b[31mTypeError\u001b[39m: Expected FermionicArray, got <class 'numpy.ndarray'>."
     ]
    }
   ],
   "source": [
    "amp0.contract_boundary_from_xmax(xrange=(0, model.Lx-1), max_bond=16, cutoff=0.0, mode='fit').contract()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpsds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
