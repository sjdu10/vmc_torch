{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simplest example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from functorch import vmap, jacrev\n",
    "\n",
    "# class MyModel(nn.Module):\n",
    "#     def __init__(self, in_dim, out_dim):\n",
    "#         super().__init__()\n",
    "#         self.linear = nn.Linear(in_dim, out_dim, bias=True)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # x shape: [batch_size, in_dim]\n",
    "#         return self.linear(x)  # [batch_size, out_dim]\n",
    "\n",
    "# # Instantiate a toy model\n",
    "# model = MyModel(in_dim=3, out_dim=1)\n",
    "\n",
    "# # Create a batch of inputs: shape [m, in_dim]\n",
    "# X = torch.randn(5, 3)  # m=5 examples, each dimension=3\n",
    "\n",
    "# # Extract model parameters as a tuple\n",
    "# # For a single Linear layer: params=(weight, bias)\n",
    "# params0 = tuple(model.parameters())  # (W, b)\n",
    "# params = {'W': params0[0], 'b': params0[1]}\n",
    "\n",
    "# def model_functional(params, x):\n",
    "#     \"\"\"\n",
    "#     params = {'W': W, 'b': b}\n",
    "#     x      = single input, shape: [in_dim]\n",
    "#     Return f_theta(x), shape: [out_dim].\n",
    "#     \"\"\"\n",
    "#     W = params['W']\n",
    "#     b = params['b']\n",
    "#     return x @ W.T + b\n",
    "\n",
    "# def single_sample_jac(params, x):\n",
    "#     \"\"\"\n",
    "#     Return the Jacobian of model_functional w.r.t. 'params'\n",
    "#     for a single input x.\n",
    "\n",
    "#     Shape details:\n",
    "#       * f_theta(x) in R^(out_dim)\n",
    "#       * 'params' is a tuple (W, b)\n",
    "#     Result is a tuple of the same structure as 'params':\n",
    "#       (Jac_of_W, Jac_of_b)\n",
    "#     \"\"\"\n",
    "#     # 'lambda p: model_functional(p, x)' is a function of 'p' only\n",
    "#     return jacrev(lambda p: model_functional(p, x))(params)\n",
    "\n",
    "# # We'll define a \"batched\" version of single_sample_jac:\n",
    "# batched_param_jac = vmap(single_sample_jac, in_dims=(None, 0))\n",
    "# #  -> 'params' is not varying (None), \n",
    "# #     'x' is taken from the 0th dim of X.\n",
    "\n",
    "# # Now compute the per-example Jacobian:\n",
    "# jac_per_sample = batched_param_jac(params, X)\n",
    "\n",
    "# jac_per_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F=4.76 C=5.57 S=10.00 P=11.43: 100%|██████████| 10/10 [00:00<00:00, 844.45it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '1'\n",
    "os.environ['DENSE_TENSOR'] = '1'\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "import pickle\n",
    "pwd = '/home/sijingdu/TNVMC/VMC_code/vmc_torch/data'\n",
    "# torch\n",
    "import torch\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "\n",
    "# quimb\n",
    "import quimb.tensor as qtn\n",
    "import autoray as ar\n",
    "\n",
    "from vmc_torch.experiment.tn_model import *\n",
    "from vmc_torch.sampler import MetropolisExchangeSamplerSpinful, MetropolisMPSSamplerSpinful\n",
    "from vmc_torch.variational_state import Variational_State\n",
    "from vmc_torch.optimizer import SGD, SR,Adam, SGD_momentum, DecayScheduler, TrivialPreconditioner\n",
    "from vmc_torch.VMC import VMC\n",
    "from vmc_torch.hamiltonian_torch import spinful_Fermi_Hubbard_square_lattice_torch\n",
    "# from vmc_torch.torch_utils import SVD,QR\n",
    "\n",
    "# # Register safe SVD and QR functions to torch\n",
    "# ar.register_function('torch','linalg.svd',SVD.apply)\n",
    "# ar.register_function('torch','linalg.qr',QR.apply)\n",
    "\n",
    "from vmc_torch.global_var import DEBUG\n",
    "from vmc_torch.utils import closest_divisible\n",
    "\n",
    "\n",
    "COMM = MPI.COMM_WORLD\n",
    "SIZE = COMM.Get_size()\n",
    "RANK = COMM.Get_rank()\n",
    "\n",
    "# Hamiltonian parameters\n",
    "Lx = int(4)\n",
    "Ly = int(4)\n",
    "symmetry = 'Z2'\n",
    "t = 1.0\n",
    "U = 8.0\n",
    "N_f = int(Lx*Ly)\n",
    "# N_f = int(Lx*Ly)\n",
    "n_fermions_per_spin = (N_f//2, N_f//2)\n",
    "H = spinful_Fermi_Hubbard_square_lattice_torch(Lx, Ly, t, U, N_f, pbc=False, n_fermions_per_spin=n_fermions_per_spin)\n",
    "graph = H.graph\n",
    "# TN parameters\n",
    "D = 4\n",
    "chi = 128\n",
    "dtype=torch.float64\n",
    "torch.random.manual_seed(RANK)\n",
    "np.random.seed(RANK)\n",
    "\n",
    "# Load PEPS\n",
    "skeleton = pickle.load(open(pwd+f\"/{Lx}x{Ly}/t={t}_U={U}/N={N_f}/{symmetry}/D={D}/peps_skeleton.pkl\", \"rb\"))\n",
    "peps_params = pickle.load(open(pwd+f\"/{Lx}x{Ly}/t={t}_U={U}/N={N_f}/{symmetry}/D={D}/peps_su_params.pkl\", \"rb\"))\n",
    "peps = qtn.unpack(peps_params, skeleton)\n",
    "device = torch.device(\"cuda\")\n",
    "peps.apply_to_arrays(lambda x: torch.tensor(x, dtype=dtype, device=device))\n",
    "peps.exponent = torch.tensor(peps.exponent, dtype=dtype, device=device)\n",
    "\n",
    "# # randomize the PEPS tensors\n",
    "# peps.apply_to_arrays(lambda x: torch.randn_like(torch.tensor(x, dtype=dtype), dtype=dtype))\n",
    "\n",
    "# VMC sample size\n",
    "N_samples = int(20)\n",
    "N_samples = closest_divisible(N_samples, SIZE)\n",
    "if (N_samples/SIZE)%2 != 0:\n",
    "    N_samples += SIZE\n",
    "        \n",
    "# nn_hidden_dim = Lx*Ly\n",
    "model = fTNModel_vec(peps, max_bond=chi, dtype=dtype, functional=True, device=device)\n",
    "model1 = fTNModel(peps, max_bond=chi, dtype=dtype, functional=False)\n",
    "model1.tree = model.tree\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = fTN_backflow_attn_Tensorwise_Model_v1(\n",
    "#     peps,\n",
    "#     max_bond=chi,\n",
    "#     embedding_dim=16,\n",
    "#     attention_heads=4,\n",
    "#     nn_final_dim=4,\n",
    "#     nn_eta=1.0,\n",
    "#     dtype=dtype,\n",
    "# )\n",
    "\n",
    "# Set up sampler\n",
    "sampler = MetropolisExchangeSamplerSpinful(H.hilbert, graph, N_samples=N_samples, burn_in_steps=2, reset_chain=False, random_edge=False, equal_partition=True, dtype=dtype, subchain_length=10)\n",
    "# mps_dir = '/home/sijingdu/TNVMC/VMC_code/vmc_torch/data'+f'/{Lx}x{Ly}/t={t}_U={U}/N={N_f}/tmp'\n",
    "# sampler = MetropolisMPSSamplerSpinful(H.hilbert, graph, mps_dir=mps_dir, mps_n_sample=1, N_samples=N_samples, burn_in_steps=20, reset_chain=True, equal_partition=True, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 3]' is invalid for input of size 9",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m amp0 = peps.get_amp(X[\u001b[32m0\u001b[39m], functional=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      4\u001b[39m amp00 = peps.get_amp(X[\u001b[32m0\u001b[39m], functional=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m amp1 = \u001b[43mamp0\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontract_boundary_from_xmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxrange\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLx\u001b[49m\u001b[43m/\u001b[49m\u001b[43m/\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m amp2 = amp1.contract_boundary_from_xmax(max_bond=-\u001b[32m1\u001b[39m, xrange=(Lx//\u001b[32m2\u001b[39m, Lx-\u001b[32m1\u001b[39m))\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# amp00.contract(), amp0.contract()\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/quimb/tensor/tensor_2d.py:1870\u001b[39m, in \u001b[36mTensorNetwork2D.contract_boundary_from_xmin\u001b[39m\u001b[34m(self, xrange, yrange, max_bond, cutoff, canonize, mode, layer_tags, sweep_reverse, compress_opts, inplace, **contract_boundary_opts)\u001b[39m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcontract_boundary_from_xmin\u001b[39m(\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1774\u001b[39m     xrange,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1785\u001b[39m     **contract_boundary_opts,\n\u001b[32m   1786\u001b[39m ):\n\u001b[32m   1787\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Contract a 2D tensor network inwards from the bottom, canonizing\u001b[39;00m\n\u001b[32m   1788\u001b[39m \u001b[33;03m    and compressing (left to right) along the way. If\u001b[39;00m\n\u001b[32m   1789\u001b[39m \u001b[33;03m    ``layer_tags is None`` this looks like::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1868\u001b[39m \u001b[33;03m    contract_boundary_from_ymax\u001b[39;00m\n\u001b[32m   1869\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1870\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcontract_boundary_from\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1871\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxrange\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxrange\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1872\u001b[39m \u001b[43m        \u001b[49m\u001b[43myrange\u001b[49m\u001b[43m=\u001b[49m\u001b[43myrange\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1873\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_which\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mxmin\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1874\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1875\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1876\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcanonize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcanonize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1877\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1878\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_tags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1879\u001b[39m \u001b[43m        \u001b[49m\u001b[43msweep_reverse\u001b[49m\u001b[43m=\u001b[49m\u001b[43msweep_reverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1880\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompress_opts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompress_opts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcontract_boundary_opts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/quimb/tensor/tensor_2d.py:1760\u001b[39m, in \u001b[36mTensorNetwork2D.contract_boundary_from\u001b[39m\u001b[34m(self, xrange, yrange, from_which, max_bond, cutoff, canonize, mode, layer_tags, sweep_reverse, compress_opts, inplace, **contract_boundary_opts)\u001b[39m\n\u001b[32m   1757\u001b[39m contract_boundary_opts[\u001b[33m\"\u001b[39m\u001b[33msweep_reverse\u001b[39m\u001b[33m\"\u001b[39m] = sweep_reverse\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mmps\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1760\u001b[39m     \u001b[43mtn\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_contract_boundary_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcontract_boundary_opts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1761\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tn\n\u001b[32m   1763\u001b[39m tn._contract_boundary_core_via_1d(\n\u001b[32m   1764\u001b[39m     method=mode, **contract_boundary_opts\n\u001b[32m   1765\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/quimb/tensor/tensor_2d.py:1435\u001b[39m, in \u001b[36mTensorNetwork2D._contract_boundary_core\u001b[39m\u001b[34m(self, xrange, yrange, from_which, max_bond, cutoff, canonize, layer_tags, compress_late, sweep_reverse, equalize_norms, compress_opts, canonize_opts)\u001b[39m\n\u001b[32m   1422\u001b[39m     \u001b[38;5;28mself\u001b[39m.canonize_plane(\n\u001b[32m   1423\u001b[39m         xrange=xrange \u001b[38;5;28;01mif\u001b[39;00m plane != \u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m (i, i),\n\u001b[32m   1424\u001b[39m         xreverse=\u001b[38;5;129;01mnot\u001b[39;00m sweep_reverse,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1428\u001b[39m         canonize_opts=canonize_opts,\n\u001b[32m   1429\u001b[39m     )\n\u001b[32m   1430\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m   1431\u001b[39m \u001b[38;5;66;03m#    │  │  │  │  │  -->  │  │  │  │  │  -->  │  │  │  │  │\u001b[39;00m\n\u001b[32m   1432\u001b[39m \u001b[38;5;66;03m#    >──O══O══O══O  -->  >──>──O══O══O  -->  >──>──>──O══O\u001b[39;00m\n\u001b[32m   1433\u001b[39m \u001b[38;5;66;03m#    .  .           -->     .  .        -->        .  .\u001b[39;00m\n\u001b[32m   1434\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1435\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompress_plane\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1436\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxrange\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxrange\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mplane\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1437\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxreverse\u001b[49m\u001b[43m=\u001b[49m\u001b[43msweep_reverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1438\u001b[39m \u001b[43m    \u001b[49m\u001b[43myrange\u001b[49m\u001b[43m=\u001b[49m\u001b[43myrange\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mplane\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43my\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1439\u001b[39m \u001b[43m    \u001b[49m\u001b[43myreverse\u001b[49m\u001b[43m=\u001b[49m\u001b[43msweep_reverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1440\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1441\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1442\u001b[39m \u001b[43m    \u001b[49m\u001b[43mequalize_norms\u001b[49m\u001b[43m=\u001b[49m\u001b[43mequalize_norms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompress_opts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompress_opts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1444\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/quimb/tensor/tensor_2d.py:1103\u001b[39m, in \u001b[36mTensorNetwork2D.compress_plane\u001b[39m\u001b[34m(self, xrange, yrange, max_bond, cutoff, equalize_norms, compress_opts, **gen_pair_opts)\u001b[39m\n\u001b[32m   1100\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m   1101\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompress_between\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtag_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtag_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcompress_opts\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/quimb/tensor/tensor_core.py:6441\u001b[39m, in \u001b[36mTensorNetwork.compress_between\u001b[39m\u001b[34m(self, tags1, tags2, max_bond, cutoff, absorb, canonize_distance, canonize_opts, equalize_norms, **compress_opts)\u001b[39m\n\u001b[32m   6438\u001b[39m (tid1,) = \u001b[38;5;28mself\u001b[39m._get_tids_from_tags(tags1, which=\u001b[33m\"\u001b[39m\u001b[33mall\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6439\u001b[39m (tid2,) = \u001b[38;5;28mself\u001b[39m._get_tids_from_tags(tags2, which=\u001b[33m\"\u001b[39m\u001b[33mall\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m6441\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compress_between_tids\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   6442\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtid1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtid2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6444\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6445\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6446\u001b[39m \u001b[43m    \u001b[49m\u001b[43mabsorb\u001b[49m\u001b[43m=\u001b[49m\u001b[43mabsorb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6447\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcanonize_distance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcanonize_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6448\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcanonize_opts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcanonize_opts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6449\u001b[39m \u001b[43m    \u001b[49m\u001b[43mequalize_norms\u001b[49m\u001b[43m=\u001b[49m\u001b[43mequalize_norms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6450\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcompress_opts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6451\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/quimb/tensor/tensor_core.py:6352\u001b[39m, in \u001b[36mTensorNetwork._compress_between_tids\u001b[39m\u001b[34m(self, tid1, tid2, max_bond, cutoff, absorb, canonize_distance, canonize_opts, canonize_after_distance, canonize_after_opts, mode, equalize_norms, gauges, gauge_smudge, callback, **compress_opts)\u001b[39m\n\u001b[32m   6343\u001b[39m     \u001b[38;5;28mself\u001b[39m._canonize_around_tids(\n\u001b[32m   6344\u001b[39m         (tid1, tid2),\n\u001b[32m   6345\u001b[39m         gauges=gauges,\n\u001b[32m   (...)\u001b[39m\u001b[32m   6348\u001b[39m         **canonize_opts,\n\u001b[32m   6349\u001b[39m     )\n\u001b[32m   6351\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mbasic\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m6352\u001b[39m     \u001b[43mtensor_compress_bond\u001b[49m\u001b[43m(\u001b[49m\u001b[43mta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcompress_opts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6353\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mvirtual-tree\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   6354\u001b[39m     \u001b[38;5;28mself\u001b[39m._compress_between_virtual_tree_tids(\n\u001b[32m   6355\u001b[39m         tid1, tid2, **compress_opts\n\u001b[32m   6356\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/functools.py:909\u001b[39m, in \u001b[36msingledispatch.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires at least \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    907\u001b[39m                     \u001b[33m'\u001b[39m\u001b[33m1 positional argument\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m909\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/quimb/tensor/tensor_core.py:876\u001b[39m, in \u001b[36mtensor_compress_bond\u001b[39m\u001b[34m(T1, T2, reduced, absorb, gauges, gauge_smudge, info, **compress_opts)\u001b[39m\n\u001b[32m    868\u001b[39m T1C, *s, M = T1.split(\n\u001b[32m    869\u001b[39m     left_inds=lix,\n\u001b[32m    870\u001b[39m     right_inds=bix,\n\u001b[32m   (...)\u001b[39m\u001b[32m    873\u001b[39m     **compress_opts,\n\u001b[32m    874\u001b[39m )\n\u001b[32m    875\u001b[39m \u001b[38;5;66;03m# try:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m876\u001b[39m T2C = \u001b[43mM\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mT2\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# except Exception as e:\u001b[39;00m\n\u001b[32m    878\u001b[39m \u001b[38;5;66;03m#     # print error details\u001b[39;00m\n\u001b[32m    879\u001b[39m \u001b[38;5;66;03m#     print(e)\u001b[39;00m\n\u001b[32m    880\u001b[39m \u001b[38;5;66;03m#     # print(T1, T2)\u001b[39;00m\n\u001b[32m    881\u001b[39m \u001b[38;5;66;03m#     # print(T1C.data.blocks, s, M.data.blocks)\u001b[39;00m\n\u001b[32m    882\u001b[39m \u001b[38;5;66;03m#     print(M.data, T2.data)\u001b[39;00m\n\u001b[32m    884\u001b[39m T1C.transpose_like_(T1)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/quimb/tensor/tensor_core.py:3122\u001b[39m, in \u001b[36mTensor.__matmul__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m   3120\u001b[39m ax1 = \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m.inds.index(b) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m bix)\n\u001b[32m   3121\u001b[39m ax2 = \u001b[38;5;28mtuple\u001b[39m(other.inds.index(b) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m bix)\n\u001b[32m-> \u001b[39m\u001b[32m3122\u001b[39m data_out = \u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3123\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtensordot\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3124\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mother\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3126\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43max1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43max2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlike\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_contract_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3128\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3129\u001b[39m new_inds = lix + rix\n\u001b[32m   3130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_inds:\n\u001b[32m   3131\u001b[39m     \u001b[38;5;66;03m# scalar\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/autoray/autoray.py:81\u001b[39m, in \u001b[36mdo\u001b[39m\u001b[34m(fn, like, *args, **kwargs)\u001b[39m\n\u001b[32m     79\u001b[39m backend = _choose_backend(fn, args, kwargs, like=like)\n\u001b[32m     80\u001b[39m func = get_lib_fn(backend, fn)\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/functools.py:909\u001b[39m, in \u001b[36msingledispatch.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires at least \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    907\u001b[39m                     \u001b[33m'\u001b[39m\u001b[33m1 positional argument\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m909\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/symmray/fermionic_core.py:827\u001b[39m, in \u001b[36mtensordot_fermionic\u001b[39m\u001b[34m(a, b, axes, preserve_array, **kwargs)\u001b[39m\n\u001b[32m    824\u001b[39m b.phase_sync(inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    826\u001b[39m \u001b[38;5;66;03m# perform blocked contraction!\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m827\u001b[39m c = \u001b[43mtensordot_abelian\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    828\u001b[39m \u001b[43m    \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[43m    \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_axes_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_axes_b\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# preserve array for resolving oddposs\u001b[39;49;00m\n\u001b[32m    832\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreserve_array\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[38;5;66;03m# potential global phase flip from oddpos sorting\u001b[39;00m\n\u001b[32m    837\u001b[39m resolve_combined_oddpos(a, b, c)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/symmray/abelian_core.py:2410\u001b[39m, in \u001b[36mtensordot_abelian\u001b[39m\u001b[34m(a, b, axes, mode, preserve_array)\u001b[39m\n\u001b[32m   2407\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2408\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown tensordot mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2410\u001b[39m c = \u001b[43m_tdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_axes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2412\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[32m   2413\u001b[39m     c.check()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/symmray/abelian_core.py:2318\u001b[39m, in \u001b[36m_tensordot_via_fused\u001b[39m\u001b[34m(a, b, left_axes, axes_a, axes_b, right_axes)\u001b[39m\n\u001b[32m   2311\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ts.copy_with(\n\u001b[32m   2312\u001b[39m         indices=without(a.indices, axes_a) + without(b.indices, axes_b),\n\u001b[32m   2313\u001b[39m         charge=a.symmetry.combine(a.charge, b.charge),\n\u001b[32m   2314\u001b[39m         blocks={},\n\u001b[32m   2315\u001b[39m     )\n\u001b[32m   2317\u001b[39m \u001b[38;5;66;03m# fuse into matrices or maybe vectors\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2318\u001b[39m af = \u001b[43mAbelianArray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfuse\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_empty\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2319\u001b[39m bf = AbelianArray.fuse(b, axes_b, right_axes, expand_empty=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   2321\u001b[39m \u001b[38;5;66;03m# handle potential vector and scalar cases\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/symmray/abelian_core.py:1817\u001b[39m, in \u001b[36mAbelianArray.fuse\u001b[39m\u001b[34m(self, expand_empty, inplace, *axes_groups)\u001b[39m\n\u001b[32m   1814\u001b[39m         _axes_expand.append(ax)\n\u001b[32m   1816\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _axes_groups:\n\u001b[32m-> \u001b[39m\u001b[32m1817\u001b[39m     xf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fuse_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_axes_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1818\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1819\u001b[39m     xf = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/symmray/abelian_core.py:1703\u001b[39m, in \u001b[36mAbelianArray._fuse_core\u001b[39m\u001b[34m(self, inplace, *axes_groups)\u001b[39m\n\u001b[32m   1701\u001b[39m     \u001b[38;5;66;03m# fuse (via transpose+reshape) the actual array, to concat later\u001b[39;00m\n\u001b[32m   1702\u001b[39m     new_array = _transpose(array, perm)\n\u001b[32m-> \u001b[39m\u001b[32m1703\u001b[39m     new_array = \u001b[43m_reshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1704\u001b[39m     new_blocks.setdefault(new_sector, {})[subsectors] = new_array\n\u001b[32m   1706\u001b[39m \u001b[38;5;66;03m# explicity handle zeros function and dtype and device kwargs\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: shape '[1, 3]' is invalid for input of size 9"
     ]
    }
   ],
   "source": [
    "X = [H.hilbert.random_state(i) for i in range(10)]\n",
    "X = torch.tensor(X, dtype=dtype, device=device)\n",
    "amp0 = peps.get_amp(X[0], functional=True)\n",
    "amp00 = peps.get_amp(X[0], functional=False)\n",
    "\n",
    "amp1 = amp0.contract_boundary_from_xmin(max_bond=-1, xrange=(0, Lx//2-1))\n",
    "amp2 = amp1.contract_boundary_from_xmax(max_bond=-1, xrange=(Lx//2, Lx-1))\n",
    "# amp00.contract(), amp0.contract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[3, 8]' is invalid for input of size 8",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     44\u001b[39m X = [H.hilbert.random_state(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m10\u001b[39m)]\n\u001b[32m     45\u001b[39m X = torch.tensor(X, dtype=dtype, device=device)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m amps_vec, amps = model(X), \u001b[43mmodel1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m amps_vec/amps\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/vmc_torch/vmc_torch/experiment/tn_model.py:98\u001b[39m, in \u001b[36mwavefunctionModel.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m     96\u001b[39m     \u001b[38;5;66;03m# If input is not batched, add a batch dimension\u001b[39;00m\n\u001b[32m     97\u001b[39m     x = x.unsqueeze(\u001b[32m0\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mamplitude\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/vmc_torch/vmc_torch/experiment/tn_model.py:1245\u001b[39m, in \u001b[36mfTNModel.amplitude\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m   1243\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1244\u001b[39m     amp = amp.contract_boundary_from_ymin(max_bond=\u001b[38;5;28mself\u001b[39m.max_bond, cutoff=\u001b[32m0.0\u001b[39m, yrange=[\u001b[32m0\u001b[39m, psi.Ly//\u001b[32m2\u001b[39m-\u001b[32m1\u001b[39m])\n\u001b[32m-> \u001b[39m\u001b[32m1245\u001b[39m     amp = \u001b[43mamp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontract_boundary_from_ymax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myrange\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpsi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLy\u001b[49m\u001b[43m/\u001b[49m\u001b[43m/\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpsi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLy\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1246\u001b[39m     amp_val = amp.contract()\n\u001b[32m   1248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m amp_val==\u001b[32m0.0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/quimb/tensor/tensor_2d.py:2254\u001b[39m, in \u001b[36mTensorNetwork2D.contract_boundary_from_ymax\u001b[39m\u001b[34m(self, yrange, xrange, max_bond, cutoff, canonize, mode, layer_tags, sweep_reverse, compress_opts, inplace, **contract_boundary_opts)\u001b[39m\n\u001b[32m   2140\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcontract_boundary_from_ymax\u001b[39m(\n\u001b[32m   2141\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2142\u001b[39m     yrange,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2153\u001b[39m     **contract_boundary_opts,\n\u001b[32m   2154\u001b[39m ):\n\u001b[32m   2155\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Contract a 2D tensor network inwards from the left, canonizing and\u001b[39;00m\n\u001b[32m   2156\u001b[39m \u001b[33;03m    compressing (top to bottom) along the way. If\u001b[39;00m\n\u001b[32m   2157\u001b[39m \u001b[33;03m    ``layer_tags is None`` this looks like::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2252\u001b[39m \u001b[33;03m    contract_boundary_from_ymin\u001b[39;00m\n\u001b[32m   2253\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2254\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcontract_boundary_from\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxrange\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxrange\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2256\u001b[39m \u001b[43m        \u001b[49m\u001b[43myrange\u001b[49m\u001b[43m=\u001b[49m\u001b[43myrange\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrom_which\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mymax\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcanonize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcanonize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_tags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlayer_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2263\u001b[39m \u001b[43m        \u001b[49m\u001b[43msweep_reverse\u001b[49m\u001b[43m=\u001b[49m\u001b[43msweep_reverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompress_opts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompress_opts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2265\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2266\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcontract_boundary_opts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2267\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/quimb/tensor/tensor_2d.py:1760\u001b[39m, in \u001b[36mTensorNetwork2D.contract_boundary_from\u001b[39m\u001b[34m(self, xrange, yrange, from_which, max_bond, cutoff, canonize, mode, layer_tags, sweep_reverse, compress_opts, inplace, **contract_boundary_opts)\u001b[39m\n\u001b[32m   1757\u001b[39m contract_boundary_opts[\u001b[33m\"\u001b[39m\u001b[33msweep_reverse\u001b[39m\u001b[33m\"\u001b[39m] = sweep_reverse\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mmps\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1760\u001b[39m     \u001b[43mtn\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_contract_boundary_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcontract_boundary_opts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1761\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m tn\n\u001b[32m   1763\u001b[39m tn._contract_boundary_core_via_1d(\n\u001b[32m   1764\u001b[39m     method=mode, **contract_boundary_opts\n\u001b[32m   1765\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/quimb/tensor/tensor_2d.py:1435\u001b[39m, in \u001b[36mTensorNetwork2D._contract_boundary_core\u001b[39m\u001b[34m(self, xrange, yrange, from_which, max_bond, cutoff, canonize, layer_tags, compress_late, sweep_reverse, equalize_norms, compress_opts, canonize_opts)\u001b[39m\n\u001b[32m   1422\u001b[39m     \u001b[38;5;28mself\u001b[39m.canonize_plane(\n\u001b[32m   1423\u001b[39m         xrange=xrange \u001b[38;5;28;01mif\u001b[39;00m plane != \u001b[33m\"\u001b[39m\u001b[33mx\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m (i, i),\n\u001b[32m   1424\u001b[39m         xreverse=\u001b[38;5;129;01mnot\u001b[39;00m sweep_reverse,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1428\u001b[39m         canonize_opts=canonize_opts,\n\u001b[32m   1429\u001b[39m     )\n\u001b[32m   1430\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m   1431\u001b[39m \u001b[38;5;66;03m#    │  │  │  │  │  -->  │  │  │  │  │  -->  │  │  │  │  │\u001b[39;00m\n\u001b[32m   1432\u001b[39m \u001b[38;5;66;03m#    >──O══O══O══O  -->  >──>──O══O══O  -->  >──>──>──O══O\u001b[39;00m\n\u001b[32m   1433\u001b[39m \u001b[38;5;66;03m#    .  .           -->     .  .        -->        .  .\u001b[39;00m\n\u001b[32m   1434\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1435\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompress_plane\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1436\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxrange\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxrange\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mplane\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mx\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1437\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxreverse\u001b[49m\u001b[43m=\u001b[49m\u001b[43msweep_reverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1438\u001b[39m \u001b[43m    \u001b[49m\u001b[43myrange\u001b[49m\u001b[43m=\u001b[49m\u001b[43myrange\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mplane\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43my\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1439\u001b[39m \u001b[43m    \u001b[49m\u001b[43myreverse\u001b[49m\u001b[43m=\u001b[49m\u001b[43msweep_reverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1440\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1441\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1442\u001b[39m \u001b[43m    \u001b[49m\u001b[43mequalize_norms\u001b[49m\u001b[43m=\u001b[49m\u001b[43mequalize_norms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1443\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompress_opts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompress_opts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1444\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/quimb/tensor/tensor_2d.py:1103\u001b[39m, in \u001b[36mTensorNetwork2D.compress_plane\u001b[39m\u001b[34m(self, xrange, yrange, max_bond, cutoff, equalize_norms, compress_opts, **gen_pair_opts)\u001b[39m\n\u001b[32m   1100\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m   1101\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompress_between\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtag_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtag_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcompress_opts\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/quimb/tensor/tensor_core.py:6433\u001b[39m, in \u001b[36mTensorNetwork.compress_between\u001b[39m\u001b[34m(self, tags1, tags2, max_bond, cutoff, absorb, canonize_distance, canonize_opts, equalize_norms, **compress_opts)\u001b[39m\n\u001b[32m   6430\u001b[39m (tid1,) = \u001b[38;5;28mself\u001b[39m._get_tids_from_tags(tags1, which=\u001b[33m\"\u001b[39m\u001b[33mall\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6431\u001b[39m (tid2,) = \u001b[38;5;28mself\u001b[39m._get_tids_from_tags(tags2, which=\u001b[33m\"\u001b[39m\u001b[33mall\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m6433\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_compress_between_tids\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   6434\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtid1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6435\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtid2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6436\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_bond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6437\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6438\u001b[39m \u001b[43m    \u001b[49m\u001b[43mabsorb\u001b[49m\u001b[43m=\u001b[49m\u001b[43mabsorb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6439\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcanonize_distance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcanonize_distance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6440\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcanonize_opts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcanonize_opts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6441\u001b[39m \u001b[43m    \u001b[49m\u001b[43mequalize_norms\u001b[49m\u001b[43m=\u001b[49m\u001b[43mequalize_norms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6442\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcompress_opts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6443\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/quimb/tensor/tensor_core.py:6288\u001b[39m, in \u001b[36mTensorNetwork._compress_between_tids\u001b[39m\u001b[34m(self, tid1, tid2, max_bond, cutoff, absorb, canonize_distance, canonize_opts, canonize_after_distance, canonize_after_opts, mode, equalize_norms, gauges, gauge_smudge, callback, **compress_opts)\u001b[39m\n\u001b[32m   6283\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (lsize <= max_bond) \u001b[38;5;129;01mor\u001b[39;00m (rsize <= max_bond):\n\u001b[32m   6284\u001b[39m     \u001b[38;5;66;03m# special case - fixing any orthonormal basis for the left or\u001b[39;00m\n\u001b[32m   6285\u001b[39m     \u001b[38;5;66;03m# right tensor (whichever has smallest outer dimensions) will\u001b[39;00m\n\u001b[32m   6286\u001b[39m     \u001b[38;5;66;03m# produce the required compression without any SVD\u001b[39;00m\n\u001b[32m   6287\u001b[39m     compress_absorb = \u001b[33m\"\u001b[39m\u001b[33mright\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m lsize <= rsize \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m6288\u001b[39m     \u001b[43mtensor_canonize_bond\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   6289\u001b[39m \u001b[43m        \u001b[49m\u001b[43mta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6290\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6291\u001b[39m \u001b[43m        \u001b[49m\u001b[43mabsorb\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompress_absorb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6292\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgauges\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgauges\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6293\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgauge_smudge\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgauge_smudge\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   6294\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6296\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m absorb != compress_absorb:\n\u001b[32m   6297\u001b[39m         tensor_canonize_bond(\n\u001b[32m   6298\u001b[39m             ta,\n\u001b[32m   6299\u001b[39m             tb,\n\u001b[32m   (...)\u001b[39m\u001b[32m   6302\u001b[39m             gauge_smudge=gauge_smudge,\n\u001b[32m   6303\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/functools.py:909\u001b[39m, in \u001b[36msingledispatch.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires at least \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    907\u001b[39m                     \u001b[33m'\u001b[39m\u001b[33m1 positional argument\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m909\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/quimb/tensor/tensor_core.py:718\u001b[39m, in \u001b[36mtensor_canonize_bond\u001b[39m\u001b[34m(T1, T2, absorb, gauges, gauge_smudge, **split_opts)\u001b[39m\n\u001b[32m    715\u001b[39m     gauges.pop(bix, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    717\u001b[39m new_T1, tRfact = T1.split(lix, get=\u001b[33m\"\u001b[39m\u001b[33mtensors\u001b[39m\u001b[33m\"\u001b[39m, **split_opts)\n\u001b[32m--> \u001b[39m\u001b[32m718\u001b[39m new_T2 = \u001b[43mtRfact\u001b[49m\u001b[43m \u001b[49m\u001b[43m@\u001b[49m\u001b[43m \u001b[49m\u001b[43mT2\u001b[49m\n\u001b[32m    720\u001b[39m new_T1.transpose_like_(T1)\n\u001b[32m    721\u001b[39m new_T2.transpose_like_(T2)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/quimb/tensor/tensor_core.py:3114\u001b[39m, in \u001b[36mTensor.__matmul__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m   3112\u001b[39m ax1 = \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m.inds.index(b) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m bix)\n\u001b[32m   3113\u001b[39m ax2 = \u001b[38;5;28mtuple\u001b[39m(other.inds.index(b) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m bix)\n\u001b[32m-> \u001b[39m\u001b[32m3114\u001b[39m data_out = \u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3115\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtensordot\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3116\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3117\u001b[39m \u001b[43m    \u001b[49m\u001b[43mother\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3118\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43max1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43max2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3119\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlike\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_contract_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3120\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3121\u001b[39m new_inds = lix + rix\n\u001b[32m   3122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_inds:\n\u001b[32m   3123\u001b[39m     \u001b[38;5;66;03m# scalar\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/autoray/autoray.py:81\u001b[39m, in \u001b[36mdo\u001b[39m\u001b[34m(fn, like, *args, **kwargs)\u001b[39m\n\u001b[32m     79\u001b[39m backend = _choose_backend(fn, args, kwargs, like=like)\n\u001b[32m     80\u001b[39m func = get_lib_fn(backend, fn)\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-linux-x86_64-gnu/lib/python3.11/functools.py:909\u001b[39m, in \u001b[36msingledispatch.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[32m    906\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires at least \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    907\u001b[39m                     \u001b[33m'\u001b[39m\u001b[33m1 positional argument\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m909\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/symmray/fermionic_core.py:827\u001b[39m, in \u001b[36mtensordot_fermionic\u001b[39m\u001b[34m(a, b, axes, preserve_array, **kwargs)\u001b[39m\n\u001b[32m    824\u001b[39m b.phase_sync(inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    826\u001b[39m \u001b[38;5;66;03m# perform blocked contraction!\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m827\u001b[39m c = \u001b[43mtensordot_abelian\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    828\u001b[39m \u001b[43m    \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[43m    \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_axes_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_axes_b\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# preserve array for resolving oddposs\u001b[39;49;00m\n\u001b[32m    832\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreserve_array\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[38;5;66;03m# potential global phase flip from oddpos sorting\u001b[39;00m\n\u001b[32m    837\u001b[39m resolve_combined_oddpos(a, b, c)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/symmray/abelian_core.py:2410\u001b[39m, in \u001b[36mtensordot_abelian\u001b[39m\u001b[34m(a, b, axes, mode, preserve_array)\u001b[39m\n\u001b[32m   2407\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2408\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown tensordot mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2410\u001b[39m c = \u001b[43m_tdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_axes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2412\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[32m   2413\u001b[39m     c.check()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/symmray/abelian_core.py:2318\u001b[39m, in \u001b[36m_tensordot_via_fused\u001b[39m\u001b[34m(a, b, left_axes, axes_a, axes_b, right_axes)\u001b[39m\n\u001b[32m   2311\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ts.copy_with(\n\u001b[32m   2312\u001b[39m         indices=without(a.indices, axes_a) + without(b.indices, axes_b),\n\u001b[32m   2313\u001b[39m         charge=a.symmetry.combine(a.charge, b.charge),\n\u001b[32m   2314\u001b[39m         blocks={},\n\u001b[32m   2315\u001b[39m     )\n\u001b[32m   2317\u001b[39m \u001b[38;5;66;03m# fuse into matrices or maybe vectors\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2318\u001b[39m af = \u001b[43mAbelianArray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfuse\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_empty\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2319\u001b[39m bf = AbelianArray.fuse(b, axes_b, right_axes, expand_empty=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   2321\u001b[39m \u001b[38;5;66;03m# handle potential vector and scalar cases\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/symmray/abelian_core.py:1817\u001b[39m, in \u001b[36mAbelianArray.fuse\u001b[39m\u001b[34m(self, expand_empty, inplace, *axes_groups)\u001b[39m\n\u001b[32m   1814\u001b[39m         _axes_expand.append(ax)\n\u001b[32m   1816\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _axes_groups:\n\u001b[32m-> \u001b[39m\u001b[32m1817\u001b[39m     xf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fuse_core\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m_axes_groups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1818\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1819\u001b[39m     xf = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/symmray/abelian_core.py:1702\u001b[39m, in \u001b[36mAbelianArray._fuse_core\u001b[39m\u001b[34m(self, inplace, *axes_groups)\u001b[39m\n\u001b[32m   1700\u001b[39m \u001b[38;5;66;03m# fuse (via transpose+reshape) the actual array, to concat later\u001b[39;00m\n\u001b[32m   1701\u001b[39m new_array = _transpose(array, perm)\n\u001b[32m-> \u001b[39m\u001b[32m1702\u001b[39m new_array = \u001b[43m_reshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1703\u001b[39m \u001b[38;5;66;03m# group the subblock into the correct new fused block\u001b[39;00m\n\u001b[32m   1704\u001b[39m new_blocks.setdefault(new_sector, {})[subsectors] = new_array\n",
      "\u001b[31mRuntimeError\u001b[39m: shape '[3, 8]' is invalid for input of size 8"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "from torch.func import functional_call\n",
    "from torch.autograd.functional import jacobian\n",
    "import pyinstrument\n",
    "\n",
    "param_dict = dict(model.named_parameters())\n",
    "# 1) Suppose we've already built a param_dict, but we also want to store\n",
    "#    the shape/size info for each param in a fixed order:\n",
    "names, params = zip(*param_dict.items())  # separate keys, values\n",
    "shapes = [p.shape for p in params]\n",
    "numels = [p.numel() for p in params]\n",
    "\n",
    "def vector_to_param_dict(vec):\n",
    "    \"\"\"\n",
    "    vec: 1D Tensor containing *all* parameters in the correct order.\n",
    "    returns a dict { name_i : param_tensor_i }, with shapes matching the original.\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    start = 0\n",
    "    for name, shape, length in zip(names, shapes, numels):\n",
    "        end = start + length\n",
    "        out[name] = vec[start:end].reshape(shape)\n",
    "        start = end\n",
    "    return out\n",
    "\n",
    "model.to(device)\n",
    "model1.to(device)\n",
    "model.skeleton.exponent = model.skeleton.exponent.to(device)\n",
    "\n",
    "# Example usage\n",
    "new_vec = model.from_params_to_vec()\n",
    "new_param_dict = vector_to_param_dict(new_vec)  # {\"linear1.weight\": tensor(...), ...}\n",
    "\n",
    "# # 2) Now define a \"functional\" forward using functional_call:\n",
    "# def fmodel(vec, x):\n",
    "#     # Overwrite the model's original parameters with the new ones from vec\n",
    "#     pdict = vector_to_param_dict(vec,)\n",
    "#     return functional_call(model, pdict, (x,))\n",
    "\n",
    "# 3) Finally, we can compute the Jacobian:\n",
    "np.random.seed(0)\n",
    "rand_number = np.random.randint(0, 1000)\n",
    "X = [H.hilbert.random_state(i) for i in range(10)]\n",
    "X = torch.tensor(X, dtype=dtype, device=device)\n",
    "\n",
    "amps_vec, amps = model(X), model1(X)\n",
    "amps_vec/amps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
       "        1.0000], device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amp_val = torch.tensor([peps.get_amp(x).contract() for x in X], device=device)\n",
    "model1(X)/amp_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check contraction tree\n",
    "# for i, (_, left_tids, right_tids) in enumerate(model.tree.traverse()):\n",
    "#     print(i, left_tids, right_tids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  _     ._   __/__   _ _  _  _ _/_   Recorded: 20:54:39  Samples:  159\n",
      " /_//_/// /_\\ / //_// / //_'/ //     Duration: 0.164     CPU time: 0.164\n",
      "/   _/                      v5.0.1\n",
      "\n",
      "Profile at /tmp/ipykernel_22040/3565115910.py:1\n",
      "\n",
      "0.163 <module>  ../ipykernel_22040/3565115910.py:1\n",
      "└─ 0.163 fTNModel_vec._wrapped_call_impl  torch/nn/modules/module.py:1735\n",
      "   └─ 0.163 fTNModel_vec._call_impl  torch/nn/modules/module.py:1743\n",
      "      └─ 0.163 fTNModel_vec.forward  ../tn_model.py:1374\n",
      "         └─ 0.163 fTNModel_vec.amplitude  ../tn_model.py:1330\n",
      "            ├─ 0.160 wrapped  torch/_functorch/apis.py:202\n",
      "            │  └─ 0.160 vmap_impl  torch/_functorch/vmap.py:309\n",
      "            │     └─ 0.160 _flat_vmap  torch/_functorch/vmap.py:472\n",
      "            │        └─ 0.160 amplitude_func  ../tn_model.py:1343\n",
      "            │           ├─ 0.072 PEPS.contract  quimb/tensor/tensor_core.py:8934\n",
      "            │           │     [42 frames hidden]  functools, quimb, cotengra, symmray, ...\n",
      "            │           ├─ 0.051 fTNModel_vec.compute_global_phase  ../tn_model.py:1308\n",
      "            │           │  └─ 0.050 calculate_phase_from_adjacent_trans_dict  ../../fermion_utils.py:1409\n",
      "            │           │     ├─ 0.030 [self]  ../../fermion_utils.py\n",
      "            │           │     ├─ 0.011 wrapped  torch/_tensor.py:33\n",
      "            │           │     │     [2 frames hidden]  torch, <built-in>\n",
      "            │           │     ├─ 0.005 <listcomp>  ../../fermion_utils.py:1463\n",
      "            │           │     └─ 0.002 ContractionTree.traverse  cotengra/core.py:1464\n",
      "            │           │        └─ 0.002 ContractionTree._traverse_dfs  cotengra/core.py:1411\n",
      "            │           └─ 0.037 fPEPS.get_amp  ../../fermion_utils.py:215\n",
      "            │              └─ 0.037 fPEPS.get_amp_functional  ../../fermion_utils.py:333\n",
      "            │                 ├─ 0.028 TensorNetwork.contract  quimb/tensor/tensor_core.py:8934\n",
      "            │                 │     [29 frames hidden]  quimb, functools, cotengra, symmray, ...\n",
      "            │                 └─ 0.006 fPEPS.product_bra_state_functional  ../../fermion_utils.py:157\n",
      "            │                    └─ 0.005 select_block  ../../fermion_utils.py:183\n",
      "            │                       └─ 0.005 <dictcomp>  ../../fermion_utils.py:185\n",
      "            └─ 0.002 <dictcomp>  ../tn_model.py:1332\n",
      "               └─ 0.002 <dictcomp>  ../tn_model.py:1333\n",
      "\n",
      "\n",
      "\n",
      "  _     ._   __/__   _ _  _  _ _/_   Recorded: 20:54:39  Samples:  530\n",
      " /_//_/// /_\\ / //_// / //_'/ //     Duration: 0.540     CPU time: 0.540\n",
      "/   _/                      v5.0.1\n",
      "\n",
      "Profile at /tmp/ipykernel_22040/3565115910.py:4\n",
      "\n",
      "0.540 <module>  ../ipykernel_22040/3565115910.py:1\n",
      "└─ 0.539 fTNModel._wrapped_call_impl  torch/nn/modules/module.py:1735\n",
      "   └─ 0.539 fTNModel._call_impl  torch/nn/modules/module.py:1743\n",
      "      └─ 0.539 fTNModel.forward  ../tn_model.py:94\n",
      "         └─ 0.539 fTNModel.amplitude  ../tn_model.py:1213\n",
      "            ├─ 0.366 PEPS.contract  quimb/tensor/tensor_core.py:8934\n",
      "            │     [43 frames hidden]  functools, quimb, cotengra, symmray, ...\n",
      "            └─ 0.168 fPEPS.get_amp  ../../fermion_utils.py:215\n",
      "               └─ 0.168 fPEPS.get_amp_efficient  ../../fermion_utils.py:244\n",
      "                  ├─ 0.078 do  autoray/autoray.py:30\n",
      "                  │     [4 frames hidden]  autoray, torch, <built-in>\n",
      "                  ├─ 0.061 [self]  ../../fermion_utils.py\n",
      "                  └─ 0.009 FermionicArray.from_blocks  symmray/abelian_core.py:1300\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with pyinstrument.Profiler() as prof:\n",
    "    model(X)\n",
    "prof.print()\n",
    "with pyinstrument.Profiler() as prof:\n",
    "    model1(X)\n",
    "prof.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use vmap to compute the Jacobian\n",
    "from functorch import jacrev, vmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  _     ._   __/__   _ _  _  _ _/_   Recorded: 18:05:36  Samples:  348\n",
      " /_//_/// /_\\ / //_// / //_'/ //     Duration: 0.876     CPU time: 0.860\n",
      "/   _/                      v5.0.1\n",
      "\n",
      "Profile at /tmp/ipykernel_31234/2870813720.py:3\n",
      "\n",
      "0.876 <module>  ../ipykernel_31234/2870813720.py:1\n",
      "└─ 0.875 jacobian  torch/autograd/functional.py:575\n",
      "      [6 frames hidden]  torch\n",
      "         0.566 <lambda>  ../ipykernel_31234/2870813720.py:4\n",
      "         └─ 0.566 fmodel  ../ipykernel_31234/2641142638.py:36\n",
      "            └─ 0.564 functional_call  torch/_functorch/functional_call.py:11\n",
      "                  [2 frames hidden]  torch\n",
      "                     0.561 fTNModel_vec._call_impl  torch/nn/modules/module.py:1743\n",
      "                     └─ 0.561 fTNModel_vec.forward  ../tn_model.py:1364\n",
      "                        └─ 0.561 fTNModel_vec.amplitude  ../tn_model.py:1317\n",
      "                           └─ 0.554 wrapped  torch/_functorch/apis.py:202\n",
      "                              └─ 0.554 vmap_impl  torch/_functorch/vmap.py:309\n",
      "                                 └─ 0.554 _flat_vmap  torch/_functorch/vmap.py:472\n",
      "                                    └─ 0.554 amplitude_func  ../tn_model.py:1330\n",
      "                                       ├─ 0.428 PEPS.contract  quimb/tensor/tensor_core.py:8934\n",
      "                                       │     [36 frames hidden]  functools, quimb, cotengra, symmray, ...\n",
      "                                       │        0.214 <genexpr>  symmray/abelian_core.py:1874\n",
      "                                       ├─ 0.064 fPEPS.get_amp  ../../fermion_utils.py:215\n",
      "                                       │  └─ 0.064 fPEPS.get_amp_functional  ../../fermion_utils.py:333\n",
      "                                       │     ├─ 0.052 TensorNetwork.contract  quimb/tensor/tensor_core.py:8934\n",
      "                                       │     │     [13 frames hidden]  quimb, functools, cotengra, symmray\n",
      "                                       │     └─ 0.010 fPEPS.product_bra_state_functional  ../../fermion_utils.py:157\n",
      "                                       └─ 0.063 fTNModel_vec.compute_global_phase  ../tn_model.py:1303\n",
      "                                          └─ 0.063 calculate_phase_from_adjacent_trans_dict  ../../fermion_utils.py:1409\n",
      "                                             ├─ 0.027 [self]  ../../fermion_utils.py\n",
      "                                             └─ 0.019 wrapped  torch/_tensor.py:33\n",
      "                                                   [2 frames hidden]  torch, <built-in>\n",
      "         0.308 _EngineBase.run_backward  <built-in>\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "iteration over a 0-d tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m     amp_list = []\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m         amp, _ = \u001b[43mvariational_state\u001b[49m\u001b[43m.\u001b[49m\u001b[43mamplitude_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m         amp_list.append(amp)\n\u001b[32m     11\u001b[39m prof.print()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/vmc_torch/vmc_torch/utils.py:45\u001b[39m, in \u001b[36mtensor_aware_lru_cache.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     43\u001b[39m     cache.move_to_end(key)\n\u001b[32m     44\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cache[key]\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m cache[key] = result\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cache) > maxsize:\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# Pop the least recently used item\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/vmc_torch/vmc_torch/variational_state.py:112\u001b[39m, in \u001b[36mVariational_State.amplitude_grad\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(x) == torch.Tensor:\n\u001b[32m    111\u001b[39m     x = torch.tensor(np.asarray(x), dtype=\u001b[38;5;28mself\u001b[39m.dtype)\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m amp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvstate_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    114\u001b[39m     amp.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/vmc_torch/vmc_torch/experiment/tn_model.py:1365\u001b[39m, in \u001b[36mfTNModel_vec.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m   1364\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mamplitude\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/vmc_torch/vmc_torch/experiment/tn_model.py:1361\u001b[39m, in \u001b[36mfTNModel_vec.amplitude\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m   1359\u001b[39m vec_amplitude_func = vmap(amplitude_func, in_dims=(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[32m0\u001b[39m), randomness=\u001b[33m'\u001b[39m\u001b[33mdifferent\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   1360\u001b[39m \u001b[38;5;66;03m# Get the amplitude\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1361\u001b[39m batch_amps = \u001b[43mvec_amplitude_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpsi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1362\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m batch_amps\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/torch/_functorch/apis.py:203\u001b[39m, in \u001b[36mvmap.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/torch/_functorch/vmap.py:331\u001b[39m, in \u001b[36mvmap_impl\u001b[39m\u001b[34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[39m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(\n\u001b[32m    321\u001b[39m         func,\n\u001b[32m    322\u001b[39m         flat_in_dims,\n\u001b[32m   (...)\u001b[39m\u001b[32m    327\u001b[39m         **kwargs,\n\u001b[32m    328\u001b[39m     )\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/torch/_functorch/vmap.py:479\u001b[39m, in \u001b[36m_flat_vmap\u001b[39m\u001b[34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[32m    476\u001b[39m     batched_inputs = _create_batched_inputs(\n\u001b[32m    477\u001b[39m         flat_in_dims, flat_args, vmap_level, args_spec\n\u001b[32m    478\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m     batched_outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/vmc_torch/vmc_torch/experiment/tn_model.py:1338\u001b[39m, in \u001b[36mfTNModel_vec.amplitude.<locals>.amplitude_func\u001b[39m\u001b[34m(psi, x_i)\u001b[39m\n\u001b[32m   1336\u001b[39m         x_i = x_i.to(torch.int \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.functional \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.param_dtype)\n\u001b[32m   1337\u001b[39m \u001b[38;5;66;03m# Get the amplitude\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1338\u001b[39m amp = \u001b[43mpsi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_amp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.max_bond \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1340\u001b[39m     amp = amp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/vmc_torch/vmc_torch/fermion_utils.py:218\u001b[39m, in \u001b[36mfPEPS.get_amp\u001b[39m\u001b[34m(self, config, inplace, conj, reverse, contract, efficient, functional)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Get the amplitude of a configuration in a PEPS.\"\"\"\u001b[39;00m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m functional:\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_amp_functional\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m efficient:\n\u001b[32m    220\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.get_amp_efficient(config, inplace=inplace)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/vmc_torch/vmc_torch/fermion_utils.py:335\u001b[39m, in \u001b[36mfPEPS.get_amp_functional\u001b[39m\u001b[34m(self, config, inplace, conj, reverse, contract)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_amp_functional\u001b[39m(\u001b[38;5;28mself\u001b[39m, config, inplace=\u001b[38;5;28;01mFalse\u001b[39;00m, conj=\u001b[38;5;28;01mTrue\u001b[39;00m, reverse=\u001b[32m1\u001b[39m, contract=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    334\u001b[39m     peps = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     product_state = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mproduct_bra_state_functional\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreverse\u001b[49m\u001b[43m)\u001b[49m.conj() \u001b[38;5;28;01mif\u001b[39;00m conj \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.product_bra_state_functional(config, reverse=reverse)\n\u001b[32m    337\u001b[39m     amp = peps|product_state \u001b[38;5;66;03m# ---T---<---|n>\u001b[39;00m\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m contract:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/vmc_torch/vmc_torch/fermion_utils.py:191\u001b[39m, in \u001b[36mfPEPS.product_bra_state_functional\u001b[39m\u001b[34m(self, config, reverse)\u001b[39m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    189\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mFunctional bra state is not implemented for spinful fermions.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n, site \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msites\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    192\u001b[39m     p_ind = \u001b[38;5;28mself\u001b[39m.site_ind_id.format(*site)\n\u001b[32m    193\u001b[39m     p_tag = \u001b[38;5;28mself\u001b[39m.site_tag_id.format(*site)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TNVMC/VMC_code/mpsds/mpsds/lib/python3.11/site-packages/torch/_tensor.py:1154\u001b[39m, in \u001b[36mTensor.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1144\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1145\u001b[39m     \u001b[38;5;66;03m# NB: we use 'imap' and not 'map' here, so that in Python 2 we get a\u001b[39;00m\n\u001b[32m   1146\u001b[39m     \u001b[38;5;66;03m# generator and don't eagerly perform all the indexes.  This could\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1151\u001b[39m     \u001b[38;5;66;03m# NB: We have intentionally skipped __torch_function__ dispatch here.\u001b[39;00m\n\u001b[32m   1152\u001b[39m     \u001b[38;5;66;03m# See gh-54457\u001b[39;00m\n\u001b[32m   1153\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dim() == \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1154\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33miteration over a 0-d tensor\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1155\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._C._get_tracing_state():\n\u001b[32m   1156\u001b[39m         warnings.warn(\n\u001b[32m   1157\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mIterating over a tensor might cause the trace to be incorrect. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1158\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mPassing a tensor of different shape won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt change the number of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1162\u001b[39m             stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m   1163\u001b[39m         )\n",
      "\u001b[31mTypeError\u001b[39m: iteration over a 0-d tensor"
     ]
    }
   ],
   "source": [
    "# Set up variational state\n",
    "variational_state = Variational_State(model, hi=H.hilbert, sampler=sampler, dtype=dtype)\n",
    "with pyinstrument.Profiler() as prof:\n",
    "    J = jacobian(lambda v: fmodel(v, X), new_vec, vectorize=True)\n",
    "prof.print()\n",
    "with pyinstrument.Profiler() as prof:\n",
    "    amp_list = []\n",
    "    for x in X:\n",
    "        amp, _ = variational_state.amplitude_grad(x)\n",
    "        amp_list.append(amp)\n",
    "prof.print()\n",
    "print(\"amp_list\", amp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ContractionTree(N=16, F=4.62, C=5.61, S=10.00, P=11.35)>\n",
      "\n",
      "  _     ._   __/__   _ _  _  _ _/_   Recorded: 15:31:44  Samples:  57\n",
      " /_//_/// /_\\ / //_// / //_'/ //     Duration: 0.096     CPU time: 0.096\n",
      "/   _/                      v5.0.1\n",
      "\n",
      "Profile at /tmp/ipykernel_6982/2801438995.py:22\n",
      "\n",
      "0.095 <module>  /tmp/ipykernel_6982/2801438995.py:1\n",
      "└─ 0.095 jacobian  torch/autograd/functional.py:575\n",
      "      [6 frames hidden]  torch\n",
      "         0.056 <lambda>  /tmp/ipykernel_6982/2801438995.py:23\n",
      "         └─ 0.056 fmodel  /tmp/ipykernel_6982/2801438995.py:11\n",
      "            └─ 0.056 functional_call  torch/_functorch/functional_call.py:11\n",
      "                  [11 frames hidden]  torch\n",
      "                     0.053 fTN_backflow_attn_Tensorwise_Model_v1._call_impl  torch/nn/modules/module.py:1743\n",
      "                     └─ 0.053 fTN_backflow_attn_Tensorwise_Model_v1.forward  ../tn_model.py:91\n",
      "                        └─ 0.053 fTN_backflow_attn_Tensorwise_Model_v1.amplitude  ../tn_model.py:2306\n",
      "                           ├─ 0.031 PEPS.contract  quimb/tensor/tensor_core.py:8934\n",
      "                           │     [54 frames hidden]  functools, quimb, cotengra, symmray, ...\n",
      "                           ├─ 0.014 fPEPS.get_amp  ../../fermion_utils.py:158\n",
      "                           │  └─ 0.014 fPEPS.get_amp_efficient  ../../fermion_utils.py:185\n",
      "                           │     ├─ 0.005 do  autoray/autoray.py:30\n",
      "                           │     │     [4 frames hidden]  autoray, torch, <built-in>\n",
      "                           │     ├─ 0.002 Tensor.modify  quimb/tensor/tensor_core.py:1653\n",
      "                           │     │     [4 frames hidden]  quimb\n",
      "                           │     ├─ 0.002 FermionicArray.from_blocks  symmray/abelian_core.py:1300\n",
      "                           │     │     [3 frames hidden]  symmray, autoray\n",
      "                           │     ├─ 0.002 fPEPS.copy  quimb/tensor/tensor_core.py:4065\n",
      "                           │     │  └─ 0.002 fPEPS.__init__  ../../fermion_utils.py:78\n",
      "                           │     │     └─ 0.002 fPEPS.__init__  quimb/tensor/tensor_2d.py:4831\n",
      "                           │     │           [7 frames hidden]  quimb\n",
      "                           │     ├─ 0.001 [self]  ../../fermion_utils.py\n",
      "                           │     ├─ 0.001 PEPS.__init__  quimb/tensor/tensor_2d.py:4831\n",
      "                           │     │     [2 frames hidden]  quimb\n",
      "                           │     └─ 0.001 fPEPS.sites  quimb/tensor/tensor_arbgeom.py:598\n",
      "                           │        └─ 0.001 getattr  <built-in>\n",
      "                           ├─ 0.003 <listcomp>  ../tn_model.py:2331\n",
      "                           │  └─ 0.003 Sequential._wrapped_call_impl  torch/nn/modules/module.py:1735\n",
      "                           │        [9 frames hidden]  torch, <built-in>\n",
      "                           ├─ 0.002 reconstruct_proj_params  ../../fermion_utils.py:1217\n",
      "                           │  ├─ 0.001 Tensor.numel  <built-in>\n",
      "                           │  └─ 0.001 Tensor.reshape  <built-in>\n",
      "                           ├─ 0.001 unpack  quimb/tensor/interface.py:50\n",
      "                           │  └─ 0.001 fPEPS.copy  quimb/tensor/tensor_core.py:4065\n",
      "                           │     └─ 0.001 fPEPS.__init__  ../../fermion_utils.py:78\n",
      "                           │        └─ 0.001 fPEPS.__init__  quimb/tensor/tensor_2d.py:4831\n",
      "                           │              [5 frames hidden]  quimb, jax\n",
      "                           ├─ 0.001 flatten_proj_params  ../../fermion_utils.py:1189\n",
      "                           │  └─ 0.001 Tensor.reshape  <built-in>\n",
      "                           └─ 0.001 <dictcomp>  ../tn_model.py:2308\n",
      "                              └─ 0.001 <dictcomp>  ../tn_model.py:2309\n",
      "                                 └─ 0.001 literal_eval  ast.py:54\n",
      "         0.039 _EngineBase.run_backward  <built-in>\n",
      "\n",
      "\n",
      "\n",
      "  _     ._   __/__   _ _  _  _ _/_   Recorded: 15:31:44  Samples:  44\n",
      " /_//_/// /_\\ / //_// / //_'/ //     Duration: 0.064     CPU time: 0.064\n",
      "/   _/                      v5.0.1\n",
      "\n",
      "Profile at /tmp/ipykernel_6982/2801438995.py:25\n",
      "\n",
      "0.064 <module>  /tmp/ipykernel_6982/2801438995.py:1\n",
      "├─ 0.063 wrapper  ../../utils.py:39\n",
      "│  └─ 0.063 Variational_State.amplitude_grad  ../../variational_state.py:98\n",
      "│     ├─ 0.038 fTN_backflow_attn_Tensorwise_Model_v1._wrapped_call_impl  torch/nn/modules/module.py:1735\n",
      "│     │  └─ 0.038 fTN_backflow_attn_Tensorwise_Model_v1._call_impl  torch/nn/modules/module.py:1743\n",
      "│     │     └─ 0.038 fTN_backflow_attn_Tensorwise_Model_v1.forward  ../tn_model.py:91\n",
      "│     │        └─ 0.038 fTN_backflow_attn_Tensorwise_Model_v1.amplitude  ../tn_model.py:2306\n",
      "│     │           ├─ 0.024 PEPS.contract  quimb/tensor/tensor_core.py:8934\n",
      "│     │           │     [55 frames hidden]  functools, quimb, cotengra, symmray, ...\n",
      "│     │           ├─ 0.005 fPEPS.get_amp  ../../fermion_utils.py:158\n",
      "│     │           │  └─ 0.005 fPEPS.get_amp_efficient  ../../fermion_utils.py:185\n",
      "│     │           │     ├─ 0.004 do  autoray/autoray.py:30\n",
      "│     │           │     │     [4 frames hidden]  autoray, torch, <built-in>\n",
      "│     │           │     └─ 0.001 Z2FermionicArray.phase_sync  symmray/fermionic_core.py:422\n",
      "│     │           │        └─ 0.001 Z2FermionicArray.phases  symmray/fermionic_core.py:158\n",
      "│     │           ├─ 0.003 <dictcomp>  ../tn_model.py:2308\n",
      "│     │           │  └─ 0.003 <dictcomp>  ../tn_model.py:2309\n",
      "│     │           │     ├─ 0.001 [self]  ../tn_model.py\n",
      "│     │           │     ├─ 0.001 <genexpr>  torch/nn/modules/container.py:893\n",
      "│     │           │     │     [3 frames hidden]  torch, <built-in>\n",
      "│     │           │     └─ 0.001 literal_eval  ast.py:54\n",
      "│     │           │        └─ 0.001 parse  ast.py:33\n",
      "│     │           ├─ 0.002 <listcomp>  ../tn_model.py:2331\n",
      "│     │           │  └─ 0.002 Sequential._wrapped_call_impl  torch/nn/modules/module.py:1735\n",
      "│     │           │        [6 frames hidden]  torch, <built-in>\n",
      "│     │           ├─ 0.002 unpack  quimb/tensor/interface.py:50\n",
      "│     │           │     [5 frames hidden]  quimb, symmray, <built-in>\n",
      "│     │           │        0.001 fPEPS.copy  quimb/tensor/tensor_core.py:4065\n",
      "│     │           │        └─ 0.001 fPEPS.__init__  ../../fermion_utils.py:78\n",
      "│     │           │           └─ 0.001 fPEPS.__init__  quimb/tensor/tensor_2d.py:4831\n",
      "│     │           │                 [9 frames hidden]  quimb, symmray, <built-in>\n",
      "│     │           └─ 0.002 flatten_proj_params  ../../fermion_utils.py:1189\n",
      "│     │              ├─ 0.001 Parameter.reshape  <built-in>\n",
      "│     │              └─ 0.001 [self]  ../../fermion_utils.py\n",
      "│     ├─ 0.023 Tensor.backward  torch/_tensor.py:570\n",
      "│     │     [3 frames hidden]  torch\n",
      "│     │        0.022 _EngineBase.run_backward  <built-in>\n",
      "│     └─ 0.002 fTN_backflow_attn_Tensorwise_Model_v1.params_grad_to_vec  ../tn_model.py:70\n",
      "│        ├─ 0.001 <listcomp>  ../tn_model.py:71\n",
      "│        │  └─ 0.001 fTN_backflow_attn_Tensorwise_Model_v1.parameters  torch/nn/modules/module.py:2608\n",
      "│        │        [2 frames hidden]  torch\n",
      "│        └─ 0.001 _VariableFunctionsClass.cat  <built-in>\n",
      "└─ 0.001 Profiler.__exit__  pyinstrument/profiler.py:246\n",
      "      [2 frames hidden]  pyinstrument\n",
      "\n",
      "\n",
      "amp_list [tensor([-19.2735], dtype=torch.float64, grad_fn=<StackBackward0>), tensor([-78.6608], dtype=torch.float64, grad_fn=<StackBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "model.skeleton.exponent = model.skeleton.exponent.to(device)\n",
    "print(model.tree)\n",
    "\n",
    "# Example usage\n",
    "new_vec = model.from_params_to_vec()\n",
    "new_param_dict = vector_to_param_dict(new_vec)  # {\"linear1.weight\": tensor(...), ...}\n",
    "\n",
    "# 2) Now define a \"functional\" forward using functional_call:\n",
    "def fmodel(vec, x):\n",
    "    # Overwrite the model's original parameters with the new ones from vec\n",
    "    pdict = vector_to_param_dict(vec,)\n",
    "    return functional_call(model, pdict, (x,))\n",
    "# 3) Finally, we can compute the Jacobian:\n",
    "np.random.seed(0)\n",
    "rand_number = np.random.randint(0, 1000)\n",
    "X = [H.hilbert.random_state(i) for i in range(2)]\n",
    "X = torch.tensor(X, dtype=dtype, device=device)\n",
    "# Set up variational state\n",
    "variational_state = Variational_State(model, hi=H.hilbert, sampler=sampler, dtype=dtype)\n",
    "with pyinstrument.Profiler() as prof:\n",
    "    J = jacobian(lambda v: fmodel(v, X), new_vec, vectorize=True)\n",
    "prof.print()\n",
    "with pyinstrument.Profiler() as prof:\n",
    "    amp_list = []\n",
    "    for x in X:\n",
    "        amp, _ = variational_state.amplitude_grad(x)\n",
    "        amp_list.append(amp)\n",
    "prof.print()\n",
    "print(\"amp_list\", amp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[ 0.0507,  0.0008],\n",
       "         [ 0.0943, -0.0176],\n",
       "         [ 0.0776,  0.0564],\n",
       "         [ 0.1230,  0.0463]],\n",
       "\n",
       "        [[ 0.0230,  0.0078],\n",
       "         [-0.0103, -0.0031],\n",
       "         [ 0.0686, -0.0179],\n",
       "         [ 0.0319,  0.0093]],\n",
       "\n",
       "        [[-0.1914,  0.0003],\n",
       "         [ 0.0407, -0.0029],\n",
       "         [ 0.0526,  0.0109],\n",
       "         [-0.0262, -0.0017]],\n",
       "\n",
       "        [[-0.0308,  0.0062],\n",
       "         [-0.0817,  0.0053],\n",
       "         [-0.0261,  0.0110],\n",
       "         [ 0.0314,  0.0036]]], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(variational_state.vstate_func.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  _     ._   __/__   _ _  _  _ _/_   Recorded: 00:41:44  Samples:  39\n",
      " /_//_/// /_\\ / //_// / //_'/ //     Duration: 0.049     CPU time: 0.050\n",
      "/   _/                      v5.0.1\n",
      "\n",
      "Profile at /tmp/ipykernel_31016/2912553885.py:4\n",
      "\n",
      "0.049 <module>  ../ipykernel_31016/2912553885.py:1\n",
      "├─ 0.048 wrapper  ../../utils.py:39\n",
      "│  └─ 0.048 Variational_State.amplitude_grad  ../../variational_state.py:98\n",
      "│     ├─ 0.035 fTNModel._wrapped_call_impl  torch/nn/modules/module.py:1735\n",
      "│     │  └─ 0.035 fTNModel._call_impl  torch/nn/modules/module.py:1743\n",
      "│     │     └─ 0.035 fTNModel.forward  ../tn_model.py:94\n",
      "│     │        └─ 0.035 fTNModel.amplitude  ../ipykernel_31016/3828677844.py:122\n",
      "│     │           ├─ 0.022 PEPS.contract  quimb/tensor/tensor_core.py:8934\n",
      "│     │           │     [43 frames hidden]  functools, quimb, cotengra, symmray, ...\n",
      "│     │           ├─ 0.007 fPEPS.get_amp  ../../fermion_utils.py:158\n",
      "│     │           │  └─ 0.007 fPEPS.get_amp_efficient  ../../fermion_utils.py:185\n",
      "│     │           │     ├─ 0.003 do  autoray/autoray.py:30\n",
      "│     │           │     │     [3 frames hidden]  autoray, torch\n",
      "│     │           │     ├─ 0.001 Tensor.modify  quimb/tensor/tensor_core.py:1653\n",
      "│     │           │     │     [4 frames hidden]  quimb, symmray\n",
      "│     │           │     ├─ 0.001 Z2FermionicArray.phase_sync  symmray/fermionic_core.py:422\n",
      "│     │           │     ├─ 0.001 PEPS.__init__  quimb/tensor/tensor_2d.py:4831\n",
      "│     │           │     │  └─ 0.001 PEPS.__init__  quimb/tensor/tensor_core.py:3914\n",
      "│     │           │     └─ 0.001 Z2FermionicArray.blocks  symmray/block_core.py:31\n",
      "│     │           ├─ 0.004 <dictcomp>  ../ipykernel_31016/3828677844.py:124\n",
      "│     │           │  └─ 0.004 <dictcomp>  ../ipykernel_31016/3828677844.py:125\n",
      "│     │           │     ├─ 0.003 literal_eval  ast.py:54\n",
      "│     │           │     │     [3 frames hidden]  ast, <built-in>\n",
      "│     │           │     └─ 0.001 <genexpr>  torch/nn/modules/container.py:893\n",
      "│     │           │        └─ 0.001 ParameterDict.__getitem__  torch/nn/modules/container.py:789\n",
      "│     │           ├─ 0.001 Tensor.__iter__  torch/_tensor.py:1144\n",
      "│     │           │  └─ 0.001 Tensor.unbind  <built-in>\n",
      "│     │           └─ 0.001 unpack  quimb/tensor/interface.py:50\n",
      "│     │              └─ 0.001 fPEPS.copy  quimb/tensor/tensor_core.py:4065\n",
      "│     │                 └─ 0.001 fPEPS.__init__  ../../fermion_utils.py:78\n",
      "│     │                    └─ 0.001 fPEPS.__init__  quimb/tensor/tensor_2d.py:4831\n",
      "│     │                          [3 frames hidden]  quimb\n",
      "│     ├─ 0.012 Tensor.backward  torch/_tensor.py:570\n",
      "│     │     [2 frames hidden]  torch\n",
      "│     │        0.012 _EngineBase.run_backward  <built-in>\n",
      "│     └─ 0.001 Variational_State.reset  ../../variational_state.py:62\n",
      "│        └─ 0.001 fTNModel.clear_grad  ../tn_model.py:77\n",
      "│           └─ 0.001 fTNModel.parameters  torch/nn/modules/module.py:2608\n",
      "│                 [2 frames hidden]  torch\n",
      "└─ 0.001 Profiler.__exit__  pyinstrument/profiler.py:246\n",
      "      [2 frames hidden]  pyinstrument\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rand_number = np.random.randint(0, 1000)\n",
    "X = [H.hilbert.random_state(11+rand_number), H.hilbert.random_state(22+rand_number)]\n",
    "X = torch.tensor(X, dtype=dtype)\n",
    "with pyinstrument.Profiler() as prof:\n",
    "    for x in X:\n",
    "        variational_state.amplitude_grad(x)\n",
    "prof.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from vmc_torch.experiment.tn_model import wavefunctionModel, fMPSModel\n",
    "\n",
    "class fMPSModel_GPU(wavefunctionModel):\n",
    "    def __init__(self, ftn, dtype=torch.float32):\n",
    "        super().__init__()\n",
    "        self.param_dtype = dtype\n",
    "        # extract the raw arrays and a skeleton of the TN\n",
    "        params, self.skeleton = qtn.pack(ftn)\n",
    "\n",
    "        # Flatten the dictionary structure and assign each parameter as a part of a ModuleDict\n",
    "        self.torch_tn_params = nn.ModuleDict({\n",
    "            str(tid): nn.ParameterDict({\n",
    "                str(sector): nn.Parameter(data)\n",
    "                for sector, data in blk_array.items()\n",
    "            })\n",
    "            for tid, blk_array in params.items()\n",
    "        })\n",
    "\n",
    "        # Get symmetry\n",
    "        self.symmetry = ftn.arrays[0].symmetry\n",
    "\n",
    "        # Store the shapes of the parameters\n",
    "        self.param_shapes = [param.shape for param in self.parameters()]\n",
    "\n",
    "        self.model_structure = {\n",
    "            'fMPS (exact contraction)':{'D': ftn.max_bond(), 'L': ftn.L, 'symmetry': self.symmetry, 'cyclic': ftn.cyclic, 'skeleton': self.skeleton},\n",
    "        }\n",
    "    def amplitude(self, x):\n",
    "        # Reconstruct the original parameter structure (by unpacking from the flattened dict)\n",
    "        params = {\n",
    "            int(tid): {\n",
    "                ast.literal_eval(sector): data\n",
    "                for sector, data in blk_array.items()\n",
    "            }\n",
    "            for tid, blk_array in self.torch_tn_params.items()\n",
    "        }\n",
    "        # Reconstruct the TN with the new parameters\n",
    "        psi = qtn.unpack(params, self.skeleton)\n",
    "        # `x` is expected to be batched as (batch_size, input_dim)\n",
    "        \n",
    "        # Ensure x is a tensor of the correct dtype and move to GPU\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.tensor(x, dtype=self.param_dtype)\n",
    "        elif x.dtype != self.param_dtype:\n",
    "            x = x.to(self.param_dtype)\n",
    "        \n",
    "        # Move x to GPU and enable gradient computation\n",
    "        x = x.to('cuda')\n",
    "\n",
    "        # Get model parameters list\n",
    "        params_list = list(self.parameters())\n",
    "\n",
    "        # Loop through the batch and compute amplitude for each sample\n",
    "        batch_amps = []\n",
    "        for x_i in x:\n",
    "            # Get the amplitude\n",
    "            with torch.no_grad():\n",
    "                amp = psi.get_amp(x_i, conj=True)\n",
    "                amp_val = amp.contract()\n",
    "            if amp_val == 0.0:\n",
    "                amp_val = torch.tensor(0.0, device='cuda')\n",
    "            batch_amps.append(amp_val)\n",
    "        \n",
    "        # Stack the amplitudes into a tensor\n",
    "        batch_amps = torch.stack(batch_amps).to('cuda')\n",
    "        return batch_amps\n",
    "\n",
    "    def amplitude_grad(self, x):\n",
    "        # Reconstruct the original parameter structure (by unpacking from the flattened dict)\n",
    "        params = {\n",
    "            int(tid): {\n",
    "                ast.literal_eval(sector): data\n",
    "                for sector, data in blk_array.items()\n",
    "            }\n",
    "            for tid, blk_array in self.torch_tn_params.items()\n",
    "        }\n",
    "        # Reconstruct the TN with the new parameters\n",
    "        psi = qtn.unpack(params, self.skeleton)\n",
    "        # `x` is expected to be batched as (batch_size, input_dim)\n",
    "        \n",
    "        # Ensure x is a tensor of the correct dtype and move to GPU\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = torch.tensor(x, dtype=self.param_dtype)\n",
    "        elif x.dtype != self.param_dtype:\n",
    "            x = x.to(self.param_dtype)\n",
    "        \n",
    "        # # Move x to GPU and enable gradient computation\n",
    "        # x = x.to('cuda')\n",
    "\n",
    "        # Get model parameters list\n",
    "        params_list = list(self.parameters())\n",
    "\n",
    "        # Loop through the batch and compute amplitude for each sample\n",
    "        batch_amps = []\n",
    "        for x_i in x:\n",
    "            # Get the amplitude\n",
    "            amp = psi.get_amp(x_i, conj=True)\n",
    "            amp_val = amp.contract()\n",
    "            if amp_val == 0.0:\n",
    "                amp_val = torch.tensor(0.0, device='cuda')\n",
    "            batch_amps.append(amp_val)\n",
    "\n",
    "        # Stack the amplitudes into a tensor\n",
    "        batch_amps = torch.stack(batch_amps).to('cuda')\n",
    "\n",
    "        # Compute gradients with respect to the parameters\n",
    "        gradients = []\n",
    "        for amp in batch_amps:\n",
    "            grad = torch.autograd.grad(amp, self.parameters(), retain_graph=True, allow_unused=True)\n",
    "            flatten_grad = []\n",
    "            for i in range(len(grad)):\n",
    "                if grad[i] is None:\n",
    "                    flatten_grad.append(torch.zeros_like(params_list[i]))\n",
    "                else:\n",
    "                    flatten_grad.append(grad[i])\n",
    "            gradients.append(torch.cat([g.flatten() for g in flatten_grad]))\n",
    "        # Stack the gradients into a tensor\n",
    "        gradients = torch.stack(gradients)\n",
    "\n",
    "        return batch_amps, gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  _     ._   __/__   _ _  _  _ _/_   Recorded: 22:43:56  Samples:  43\n",
      " /_//_/// /_\\ / //_// / //_'/ //     Duration: 0.056     CPU time: 0.056\n",
      "/   _/                      v4.7.3\n",
      "\n",
      "Profile at /tmp/ipykernel_12453/2548696919.py:6\n",
      "\n",
      "\u001b[31m0.055\u001b[0m \u001b[48;5;24m\u001b[38;5;15m<module>\u001b[0m  \u001b[2m../../../../../tmp/ipykernel_12453/2548696919.py:6\u001b[0m\n",
      "└─ \u001b[31m0.055\u001b[0m \u001b[48;5;24m\u001b[38;5;15mfMPSModel_GPU.amplitude_grad\u001b[0m  \u001b[2m../../../../../tmp/ipykernel_12453/269258344.py:69\u001b[0m\n",
      "   ├─ \u001b[33m0.032\u001b[0m \u001b[48;5;24m\u001b[38;5;15mfMPS.get_amp\u001b[0m  \u001b[2mvmc_torch/fermion_utils.py:471\u001b[0m\n",
      "   │  ├─ \u001b[33m0.027\u001b[0m \u001b[48;5;24m\u001b[38;5;15mTensorNetwork.contract\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:8438\u001b[0m\n",
      "   │  │  └─ \u001b[33m0.027\u001b[0m \u001b[48;5;24m\u001b[38;5;15mTensorNetwork.contract_tags\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:8328\u001b[0m\n",
      "   │  │     ├─ \u001b[33m0.025\u001b[0m wrapper\u001b[0m  \u001b[2mfunctools.py:883\u001b[0m\n",
      "   │  │     │  └─ \u001b[33m0.025\u001b[0m \u001b[48;5;24m\u001b[38;5;15mtensor_contract\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:207\u001b[0m\n",
      "   │  │     │     └─ \u001b[33m0.025\u001b[0m \u001b[48;5;24m\u001b[38;5;15marray_contract\u001b[0m  \u001b[2mquimb/tensor/contraction.py:273\u001b[0m\n",
      "   │  │     │        └─ \u001b[33m0.025\u001b[0m array_contract\u001b[0m  \u001b[2mcotengra/interface.py:735\u001b[0m\n",
      "   │  │     │              [1 frames hidden]  \u001b[2mcotengra\u001b[0m\n",
      "   │  │     │                 \u001b[33m0.025\u001b[0m wrapper\u001b[0m  \u001b[2mfunctools.py:883\u001b[0m\n",
      "   │  │     │                 └─ \u001b[33m0.025\u001b[0m \u001b[48;5;24m\u001b[38;5;15mtensordot_fermionic\u001b[0m  \u001b[2msymmray/fermionic_core.py:762\u001b[0m\n",
      "   │  │     │                    ├─ \u001b[33m0.024\u001b[0m \u001b[48;5;24m\u001b[38;5;15mtensordot_abelian\u001b[0m  \u001b[2msymmray/abelian_core.py:2347\u001b[0m\n",
      "   │  │     │                    │  └─ \u001b[33m0.024\u001b[0m \u001b[48;5;24m\u001b[38;5;15m_tensordot_via_fused\u001b[0m  \u001b[2msymmray/abelian_core.py:2289\u001b[0m\n",
      "   │  │     │                    │     ├─ \u001b[33m0.022\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZ2FermionicArray.drop_missing_blocks\u001b[0m  \u001b[2msymmray/abelian_core.py:1091\u001b[0m\n",
      "   │  │     │                    │     │  ├─ \u001b[33m0.019\u001b[0m [self]\u001b[0m  \u001b[2msymmray/abelian_core.py\u001b[0m\n",
      "   │  │     │                    │     │  └─ \u001b[32m0.003\u001b[0m _VariableFunctionsClass.all\u001b[0m  \u001b[2m<built-in>\u001b[0m\n",
      "   │  │     │                    │     └─ \u001b[92m\u001b[2m0.002\u001b[0m \u001b[48;5;24m\u001b[38;5;15m_tensordot_blockwise\u001b[0m  \u001b[2msymmray/abelian_core.py:2137\u001b[0m\n",
      "   │  │     │                    │        ├─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15m<genexpr>\u001b[0m  \u001b[2msymmray/abelian_core.py:2194\u001b[0m\n",
      "   │  │     │                    │        │  └─ \u001b[92m\u001b[2m0.001\u001b[0m numpy_like\u001b[0m  \u001b[2mautoray/autoray.py:1967\u001b[0m\n",
      "   │  │     │                    │        │        [2 frames hidden]  \u001b[2mtorch, <built-in>\u001b[0m\n",
      "   │  │     │                    │        └─ \u001b[92m\u001b[2m0.001\u001b[0m [self]\u001b[0m  \u001b[2msymmray/abelian_core.py\u001b[0m\n",
      "   │  │     │                    └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZ2FermionicArray.transpose\u001b[0m  \u001b[2msymmray/fermionic_core.py:261\u001b[0m\n",
      "   │  │     │                       └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZ2FermionicArray.transpose\u001b[0m  \u001b[2msymmray/abelian_core.py:1518\u001b[0m\n",
      "   │  │     │                          └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15m<dictcomp>\u001b[0m  \u001b[2msymmray/abelian_core.py:1530\u001b[0m\n",
      "   │  │     │                             └─ \u001b[92m\u001b[2m0.001\u001b[0m torch_transpose\u001b[0m  \u001b[2mautoray/autoray.py:1907\u001b[0m\n",
      "   │  │     │                                   [1 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
      "   │  │     ├─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mTensorNetwork.partition_tensors\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:5087\u001b[0m\n",
      "   │  │     │  └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mTensorNetwork.pop_tensor\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:4070\u001b[0m\n",
      "   │  │     │     └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mTensor.inds\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:1492\u001b[0m\n",
      "   │  │     └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mTensorNetwork.add_tensor\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:3971\u001b[0m\n",
      "   │  │        └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mTensor.tags\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:1496\u001b[0m\n",
      "   │  ├─ \u001b[32m0.005\u001b[0m \u001b[48;5;24m\u001b[38;5;15mfMPS.product_bra_state\u001b[0m  \u001b[2mvmc_torch/fermion_utils.py:405\u001b[0m\n",
      "   │  │  ├─ \u001b[92m\u001b[2m0.002\u001b[0m [self]\u001b[0m  \u001b[2mvmc_torch/fermion_utils.py\u001b[0m\n",
      "   │  │  ├─ \u001b[92m\u001b[2m0.001\u001b[0m do\u001b[0m  \u001b[2mautoray/autoray.py:30\u001b[0m\n",
      "   │  │  │     [1 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
      "   │  │  └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mTensor.__init__\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:1378\u001b[0m\n",
      "   │  │     └─ \u001b[92m\u001b[2m0.001\u001b[0m do\u001b[0m  \u001b[2mautoray/autoray.py:30\u001b[0m\n",
      "   │  │           [3 frames hidden]  \u001b[2mautoray\u001b[0m\n",
      "   │  └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mTensorNetwork.conj\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:4263\u001b[0m\n",
      "   │     └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mTensor.conj\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:1912\u001b[0m\n",
      "   │        └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mTensor.modify\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:1549\u001b[0m\n",
      "   │           └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mTensor._apply_function\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:1546\u001b[0m\n",
      "   │              └─ \u001b[92m\u001b[2m0.001\u001b[0m conj\u001b[0m  \u001b[2mautoray/autoray.py:1049\u001b[0m\n",
      "   │                    [0 frames hidden]  \u001b[2m\u001b[0m\n",
      "   │                       \u001b[92m\u001b[2m0.001\u001b[0m do\u001b[0m  \u001b[2mautoray/autoray.py:30\u001b[0m\n",
      "   │                       └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mconj\u001b[0m  \u001b[2msymmray/interface.py:8\u001b[0m\n",
      "   │                          └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mFermionicArray.conj\u001b[0m  \u001b[2msymmray/fermionic_core.py:451\u001b[0m\n",
      "   │                             └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mFermionicArray.parity\u001b[0m  \u001b[2msymmray/fermionic_core.py:153\u001b[0m\n",
      "   │                                └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mFermionicArray.symmetry\u001b[0m  \u001b[2msymmray/abelian_core.py:963\u001b[0m\n",
      "   ├─ \u001b[33m0.016\u001b[0m \u001b[48;5;24m\u001b[38;5;15mMatrixProductState.contract\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:8438\u001b[0m\n",
      "   │  └─ \u001b[33m0.016\u001b[0m \u001b[48;5;24m\u001b[38;5;15mMatrixProductState.contract_structured\u001b[0m  \u001b[2mquimb/tensor/tensor_1d.py:510\u001b[0m\n",
      "   │     └─ \u001b[33m0.016\u001b[0m \u001b[48;5;24m\u001b[38;5;15mMatrixProductState.contract_cumulative\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:8552\u001b[0m\n",
      "   │        └─ \u001b[33m0.016\u001b[0m \u001b[48;5;24m\u001b[38;5;15mMatrixProductState.contract_tags\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:8328\u001b[0m\n",
      "   │           └─ \u001b[33m0.016\u001b[0m wrapper\u001b[0m  \u001b[2mfunctools.py:883\u001b[0m\n",
      "   │              └─ \u001b[33m0.016\u001b[0m \u001b[48;5;24m\u001b[38;5;15mtensor_contract\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:207\u001b[0m\n",
      "   │                 └─ \u001b[33m0.016\u001b[0m \u001b[48;5;24m\u001b[38;5;15marray_contract\u001b[0m  \u001b[2mquimb/tensor/contraction.py:273\u001b[0m\n",
      "   │                    └─ \u001b[33m0.016\u001b[0m array_contract\u001b[0m  \u001b[2mcotengra/interface.py:735\u001b[0m\n",
      "   │                          [1 frames hidden]  \u001b[2mcotengra\u001b[0m\n",
      "   │                             \u001b[33m0.016\u001b[0m wrapper\u001b[0m  \u001b[2mfunctools.py:883\u001b[0m\n",
      "   │                             └─ \u001b[33m0.016\u001b[0m \u001b[48;5;24m\u001b[38;5;15mtensordot_fermionic\u001b[0m  \u001b[2msymmray/fermionic_core.py:762\u001b[0m\n",
      "   │                                ├─ \u001b[33m0.013\u001b[0m \u001b[48;5;24m\u001b[38;5;15mtensordot_abelian\u001b[0m  \u001b[2msymmray/abelian_core.py:2347\u001b[0m\n",
      "   │                                │  └─ \u001b[33m0.013\u001b[0m \u001b[48;5;24m\u001b[38;5;15m_tensordot_via_fused\u001b[0m  \u001b[2msymmray/abelian_core.py:2289\u001b[0m\n",
      "   │                                │     ├─ \u001b[32m0.009\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZ2FermionicArray.drop_missing_blocks\u001b[0m  \u001b[2msymmray/abelian_core.py:1091\u001b[0m\n",
      "   │                                │     │  ├─ \u001b[32m0.008\u001b[0m [self]\u001b[0m  \u001b[2msymmray/abelian_core.py\u001b[0m\n",
      "   │                                │     │  └─ \u001b[92m\u001b[2m0.001\u001b[0m _VariableFunctionsClass.all\u001b[0m  \u001b[2m<built-in>\u001b[0m\n",
      "   │                                │     ├─ \u001b[92m\u001b[2m0.002\u001b[0m \u001b[48;5;24m\u001b[38;5;15m_tensordot_blockwise\u001b[0m  \u001b[2msymmray/abelian_core.py:2137\u001b[0m\n",
      "   │                                │     │  ├─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15m<genexpr>\u001b[0m  \u001b[2msymmray/abelian_core.py:2194\u001b[0m\n",
      "   │                                │     │  │  └─ \u001b[92m\u001b[2m0.001\u001b[0m numpy_like\u001b[0m  \u001b[2mautoray/autoray.py:1967\u001b[0m\n",
      "   │                                │     │  │        [2 frames hidden]  \u001b[2mtorch, <built-in>\u001b[0m\n",
      "   │                                │     │  └─ \u001b[92m\u001b[2m0.001\u001b[0m [self]\u001b[0m  \u001b[2msymmray/abelian_core.py\u001b[0m\n",
      "   │                                │     └─ \u001b[92m\u001b[2m0.002\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZ2FermionicArray.fuse\u001b[0m  \u001b[2msymmray/abelian_core.py:1775\u001b[0m\n",
      "   │                                │        └─ \u001b[92m\u001b[2m0.002\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZ2FermionicArray._fuse_core\u001b[0m  \u001b[2msymmray/abelian_core.py:1663\u001b[0m\n",
      "   │                                │           └─ \u001b[92m\u001b[2m0.002\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZ2FermionicArray.cached_fuse_block_info\u001b[0m  \u001b[2msymmray/abelian_core.py:821\u001b[0m\n",
      "   │                                │              └─ \u001b[92m\u001b[2m0.002\u001b[0m \u001b[48;5;24m\u001b[38;5;15mhasher\u001b[0m  \u001b[2msymmray/abelian_core.py:21\u001b[0m\n",
      "   │                                │                 └─ \u001b[92m\u001b[2m0.002\u001b[0m dumps\u001b[0m  \u001b[2m<built-in>\u001b[0m\n",
      "   │                                ├─ \u001b[92m\u001b[2m0.002\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZ2FermionicArray.phase_sync\u001b[0m  \u001b[2msymmray/fermionic_core.py:422\u001b[0m\n",
      "   │                                └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZ2FermionicArray.transpose\u001b[0m  \u001b[2msymmray/fermionic_core.py:261\u001b[0m\n",
      "   │                                   └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZ2FermionicArray.transpose\u001b[0m  \u001b[2msymmray/abelian_core.py:1518\u001b[0m\n",
      "   └─ \u001b[32m0.007\u001b[0m grad\u001b[0m  \u001b[2mtorch/autograd/__init__.py:358\u001b[0m\n",
      "         [2 frames hidden]  \u001b[2mtorch, <built-in>\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import pyinstrument\n",
    "random_config = [H.hilbert.random_state(key=jax.random.PRNGKey(1)), H.hilbert.random_state(key=jax.random.PRNGKey(2))]\n",
    "random_config = torch.tensor(random_config, dtype=dtype)\n",
    "random_config_gpu = random_config.to(device)\n",
    "with pyinstrument.Profiler() as prof:\n",
    "    model.amplitude_grad(random_config_gpu)\n",
    "print(prof.output_text(unicode=True, color=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  _     ._   __/__   _ _  _  _ _/_   Recorded: 22:44:01  Samples:  20\n",
      " /_//_/// /_\\ / //_// / //_'/ //     Duration: 0.023     CPU time: 0.023\n",
      "/   _/                      v4.7.3\n",
      "\n",
      "Profile at /tmp/ipykernel_12453/3278166090.py:1\n",
      "\n",
      "\u001b[31m0.022\u001b[0m \u001b[48;5;24m\u001b[38;5;15m<module>\u001b[0m  \u001b[2m../../../../../tmp/ipykernel_12453/3278166090.py:1\u001b[0m\n",
      "├─ \u001b[31m0.018\u001b[0m \u001b[48;5;24m\u001b[38;5;15mfMPSModel.amplitude\u001b[0m  \u001b[2m../tn_model.py:566\u001b[0m\n",
      "│  ├─ \u001b[33m0.012\u001b[0m \u001b[48;5;24m\u001b[38;5;15mfMPS.get_amp\u001b[0m  \u001b[2mvmc_torch/fermion_utils.py:471\u001b[0m\n",
      "│  │  ├─ \u001b[33m0.009\u001b[0m \u001b[48;5;24m\u001b[38;5;15mTensorNetwork.contract\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:8438\u001b[0m\n",
      "│  │  │  └─ \u001b[33m0.009\u001b[0m \u001b[48;5;24m\u001b[38;5;15mTensorNetwork.contract_tags\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:8328\u001b[0m\n",
      "│  │  │     └─ \u001b[33m0.009\u001b[0m wrapper\u001b[0m  \u001b[2mfunctools.py:883\u001b[0m\n",
      "│  │  │        └─ \u001b[33m0.009\u001b[0m \u001b[48;5;24m\u001b[38;5;15mtensor_contract\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:207\u001b[0m\n",
      "│  │  │           ├─ \u001b[33m0.008\u001b[0m \u001b[48;5;24m\u001b[38;5;15marray_contract\u001b[0m  \u001b[2mquimb/tensor/contraction.py:273\u001b[0m\n",
      "│  │  │           │  └─ \u001b[33m0.008\u001b[0m array_contract\u001b[0m  \u001b[2mcotengra/interface.py:735\u001b[0m\n",
      "│  │  │           │        [5 frames hidden]  \u001b[2mcotengra, autoray, importlib\u001b[0m\n",
      "│  │  │           │           \u001b[33m0.006\u001b[0m wrapper\u001b[0m  \u001b[2mfunctools.py:883\u001b[0m\n",
      "│  │  │           │           └─ \u001b[33m0.006\u001b[0m \u001b[48;5;24m\u001b[38;5;15mtensordot_fermionic\u001b[0m  \u001b[2msymmray/fermionic_core.py:762\u001b[0m\n",
      "│  │  │           │              ├─ \u001b[33m0.005\u001b[0m \u001b[48;5;24m\u001b[38;5;15mtensordot_abelian\u001b[0m  \u001b[2msymmray/abelian_core.py:2347\u001b[0m\n",
      "│  │  │           │              │  └─ \u001b[33m0.005\u001b[0m \u001b[48;5;24m\u001b[38;5;15m_tensordot_via_fused\u001b[0m  \u001b[2msymmray/abelian_core.py:2289\u001b[0m\n",
      "│  │  │           │              │     ├─ \u001b[32m0.002\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZ2FermionicArray.fuse\u001b[0m  \u001b[2msymmray/abelian_core.py:1775\u001b[0m\n",
      "│  │  │           │              │     │  └─ \u001b[32m0.002\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZ2FermionicArray._fuse_core\u001b[0m  \u001b[2msymmray/abelian_core.py:1663\u001b[0m\n",
      "│  │  │           │              │     │     ├─ \u001b[92m\u001b[2m0.001\u001b[0m _VariableFunctionsClass.reshape\u001b[0m  \u001b[2m<built-in>\u001b[0m\n",
      "│  │  │           │              │     │     └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZ2FermionicArray.cached_fuse_block_info\u001b[0m  \u001b[2msymmray/abelian_core.py:821\u001b[0m\n",
      "│  │  │           │              │     ├─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mdrop_misaligned_sectors\u001b[0m  \u001b[2msymmray/abelian_core.py:2214\u001b[0m\n",
      "│  │  │           │              │     │  └─ \u001b[92m\u001b[2m0.001\u001b[0m dict.items\u001b[0m  \u001b[2m<built-in>\u001b[0m\n",
      "│  │  │           │              │     ├─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZ2FermionicArray.unfuse\u001b[0m  \u001b[2msymmray/abelian_core.py:1828\u001b[0m\n",
      "│  │  │           │              │     │  └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZ2FermionicArray.backend\u001b[0m  \u001b[2msymmray/block_core.py:60\u001b[0m\n",
      "│  │  │           │              │     │     └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZ2FermionicArray.get_any_array\u001b[0m  \u001b[2msymmray/block_core.py:49\u001b[0m\n",
      "│  │  │           │              │     └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZ2FermionicArray.drop_missing_blocks\u001b[0m  \u001b[2msymmray/abelian_core.py:1091\u001b[0m\n",
      "│  │  │           │              │        └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZ2FermionicArray.blocks\u001b[0m  \u001b[2msymmray/block_core.py:31\u001b[0m\n",
      "│  │  │           │              └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZ2FermionicArray.transpose\u001b[0m  \u001b[2msymmray/fermionic_core.py:261\u001b[0m\n",
      "│  │  │           │                 └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZ2FermionicArray.transpose\u001b[0m  \u001b[2msymmray/abelian_core.py:1518\u001b[0m\n",
      "│  │  │           │                    └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15m<dictcomp>\u001b[0m  \u001b[2msymmray/abelian_core.py:1530\u001b[0m\n",
      "│  │  │           │                       └─ \u001b[92m\u001b[2m0.001\u001b[0m torch_transpose\u001b[0m  \u001b[2mautoray/autoray.py:1907\u001b[0m\n",
      "│  │  │           │                             [1 frames hidden]  \u001b[2m<built-in>\u001b[0m\n",
      "│  │  │           └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mTensor.__init__\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:1378\u001b[0m\n",
      "│  │  │              └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mTensor._set_data\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:1406\u001b[0m\n",
      "│  │  │                 └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15masarray\u001b[0m  \u001b[2mquimb/tensor/array_ops.py:21\u001b[0m\n",
      "│  │  │                    └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZ2FermionicArray.shape\u001b[0m  \u001b[2msymmray/abelian_core.py:993\u001b[0m\n",
      "│  │  │                       └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15m<genexpr>\u001b[0m  \u001b[2msymmray/abelian_core.py:996\u001b[0m\n",
      "│  │  ├─ \u001b[32m0.002\u001b[0m \u001b[48;5;24m\u001b[38;5;15mfMPS.product_bra_state\u001b[0m  \u001b[2mvmc_torch/fermion_utils.py:405\u001b[0m\n",
      "│  │  │  ├─ \u001b[92m\u001b[2m0.001\u001b[0m [self]\u001b[0m  \u001b[2mvmc_torch/fermion_utils.py\u001b[0m\n",
      "│  │  │  └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZ2FermionicArray.dtype\u001b[0m  \u001b[2msymmray/block_core.py:55\u001b[0m\n",
      "│  │  │     └─ \u001b[92m\u001b[2m0.001\u001b[0m get_dtype_name\u001b[0m  \u001b[2mautoray/autoray.py:1096\u001b[0m\n",
      "│  │  │           [2 frames hidden]  \u001b[2mautoray\u001b[0m\n",
      "│  │  └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mfMPS.__or__\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:3794\u001b[0m\n",
      "│  │     └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mfMPS.combine\u001b[0m  \u001b[2mquimb/tensor/tensor_1d.py:400\u001b[0m\n",
      "│  │        └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mfMPS.combine\u001b[0m  \u001b[2mquimb/tensor/tensor_arbgeom.py:450\u001b[0m\n",
      "│  │           └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mfMPS.combine\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:3761\u001b[0m\n",
      "│  ├─ \u001b[33m0.005\u001b[0m \u001b[48;5;24m\u001b[38;5;15mMatrixProductState.contract\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:8438\u001b[0m\n",
      "│  │  └─ \u001b[33m0.005\u001b[0m \u001b[48;5;24m\u001b[38;5;15mMatrixProductState.contract_structured\u001b[0m  \u001b[2mquimb/tensor/tensor_1d.py:510\u001b[0m\n",
      "│  │     └─ \u001b[33m0.005\u001b[0m \u001b[48;5;24m\u001b[38;5;15mMatrixProductState.contract_cumulative\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:8552\u001b[0m\n",
      "│  │        └─ \u001b[33m0.005\u001b[0m \u001b[48;5;24m\u001b[38;5;15mMatrixProductState.contract_tags\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:8328\u001b[0m\n",
      "│  │           └─ \u001b[33m0.005\u001b[0m wrapper\u001b[0m  \u001b[2mfunctools.py:883\u001b[0m\n",
      "│  │              └─ \u001b[33m0.005\u001b[0m \u001b[48;5;24m\u001b[38;5;15mtensor_contract\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:207\u001b[0m\n",
      "│  │                 └─ \u001b[33m0.005\u001b[0m \u001b[48;5;24m\u001b[38;5;15marray_contract\u001b[0m  \u001b[2mquimb/tensor/contraction.py:273\u001b[0m\n",
      "│  │                    └─ \u001b[33m0.005\u001b[0m array_contract\u001b[0m  \u001b[2mcotengra/interface.py:735\u001b[0m\n",
      "│  │                          [1 frames hidden]  \u001b[2mcotengra\u001b[0m\n",
      "│  │                             \u001b[33m0.005\u001b[0m wrapper\u001b[0m  \u001b[2mfunctools.py:883\u001b[0m\n",
      "│  │                             └─ \u001b[33m0.005\u001b[0m \u001b[48;5;24m\u001b[38;5;15mtensordot_fermionic\u001b[0m  \u001b[2msymmray/fermionic_core.py:762\u001b[0m\n",
      "│  │                                ├─ \u001b[32m0.004\u001b[0m \u001b[48;5;24m\u001b[38;5;15mtensordot_abelian\u001b[0m  \u001b[2msymmray/abelian_core.py:2347\u001b[0m\n",
      "│  │                                │  └─ \u001b[32m0.004\u001b[0m \u001b[48;5;24m\u001b[38;5;15m_tensordot_via_fused\u001b[0m  \u001b[2msymmray/abelian_core.py:2289\u001b[0m\n",
      "│  │                                │     ├─ \u001b[32m0.002\u001b[0m \u001b[48;5;24m\u001b[38;5;15m_tensordot_blockwise\u001b[0m  \u001b[2msymmray/abelian_core.py:2137\u001b[0m\n",
      "│  │                                │     │  ├─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15m<genexpr>\u001b[0m  \u001b[2msymmray/abelian_core.py:2194\u001b[0m\n",
      "│  │                                │     │  │  └─ \u001b[92m\u001b[2m0.001\u001b[0m numpy_like\u001b[0m  \u001b[2mautoray/autoray.py:1967\u001b[0m\n",
      "│  │                                │     │  │        [2 frames hidden]  \u001b[2mtorch, <built-in>\u001b[0m\n",
      "│  │                                │     │  └─ \u001b[92m\u001b[2m0.001\u001b[0m [self]\u001b[0m  \u001b[2msymmray/abelian_core.py\u001b[0m\n",
      "│  │                                │     ├─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZ2FermionicArray.drop_missing_blocks\u001b[0m  \u001b[2msymmray/abelian_core.py:1091\u001b[0m\n",
      "│  │                                │     │  └─ \u001b[92m\u001b[2m0.001\u001b[0m _VariableFunctionsClass.all\u001b[0m  \u001b[2m<built-in>\u001b[0m\n",
      "│  │                                │     └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZ2FermionicArray.fuse\u001b[0m  \u001b[2msymmray/abelian_core.py:1775\u001b[0m\n",
      "│  │                                │        └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZ2FermionicArray._fuse_core\u001b[0m  \u001b[2msymmray/abelian_core.py:1663\u001b[0m\n",
      "│  │                                │           └─ \u001b[92m\u001b[2m0.001\u001b[0m _VariableFunctionsClass.reshape\u001b[0m  \u001b[2m<built-in>\u001b[0m\n",
      "│  │                                └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZ2FermionicArray.phase_flip\u001b[0m  \u001b[2msymmray/fermionic_core.py:311\u001b[0m\n",
      "│  │                                   └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mZ2FermionicArray.sectors\u001b[0m  \u001b[2msymmray/block_core.py:70\u001b[0m\n",
      "│  └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15munpack\u001b[0m  \u001b[2mquimb/tensor/interface.py:50\u001b[0m\n",
      "│     └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mfMPS.copy\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:3884\u001b[0m\n",
      "│        └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mfMPS.__init__\u001b[0m  \u001b[2mvmc_torch/fermion_utils.py:388\u001b[0m\n",
      "│           └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mfMPS.phys_dim\u001b[0m  \u001b[2mquimb/tensor/tensor_arbgeom.py:891\u001b[0m\n",
      "│              └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mfMPS.ind_size\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:9115\u001b[0m\n",
      "│                 └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mTensor.ind_size\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:1970\u001b[0m\n",
      "│                    └─ \u001b[92m\u001b[2m0.001\u001b[0m \u001b[48;5;24m\u001b[38;5;15mTensor.shape\u001b[0m  \u001b[2mquimb/tensor/tensor_core.py:1925\u001b[0m\n",
      "│                       └─ \u001b[92m\u001b[2m0.001\u001b[0m Composed.__call__\u001b[0m  \u001b[2mautoray/autoray.py:921\u001b[0m\n",
      "│                             [3 frames hidden]  \u001b[2mautoray\u001b[0m\n",
      "└─ \u001b[32m0.004\u001b[0m Tensor.backward\u001b[0m  \u001b[2mtorch/_tensor.py:525\u001b[0m\n",
      "      [3 frames hidden]  \u001b[2mtorch, <built-in>\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with pyinstrument.Profiler() as prof:\n",
    "    for config in random_config:\n",
    "        if config.ndim == 1:\n",
    "            config = config.unsqueeze(0)\n",
    "        amp = model1.amplitude(config)\n",
    "        amp.backward()\n",
    "        grad = model1.params_grad_to_vec()\n",
    "print(prof.output_text(unicode=True, color=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpsds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
